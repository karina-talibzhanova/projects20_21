## Staff Proposer: Eleni Akrida
### Theme EA-1: Connectivity of interval temporal networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | An interval temporal network is a network whose edges are active for one or more time intervals and inactive the rest of the time. Work has been done previously on instantaneous connectivity of interval temporal networks, where the network is considered to be connected during a period of time [x,y], if it is connected for all time instances within the continuous time interval [x,y]. This project will look at the implementation of existing algorithms for verifying connectivity of interval temporal networks. We will also examine possible development of approaches to preserve connectivity of an interval temporal network over time (by maintaining a “bank” of extra edges, available during certain time intervals, which can reconnect the network in case it becomes disconnected).  |
| Reference URLs         |  https://www.worldscientific.com/doi/pdf/10.1142/S0129626419500099 |
| Anticipated Outcomes   |  Implementation and evaluation of existing algorithms with possible development of new approaches. |
| Requirements           | An interest and background knowledge in graph theory and graph algorithms  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | temporal graph, graph connectivity, algorithm  |
### Theme EA-2: Approximation algorithms for the minimum temporal vertex cover problem
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Temporal graphs are graphs whose edges appear and disappear over time, where time is viewed in discrete steps, i.e. t=1,2,3, etc. They can model various real-life dynamic networks, such as social, biological, transportation. The aim of the (Minimum) Temporal Vertex Cover problem is to cover every edge at least once during the lifetime of the temporal graph, where an edge can only be covered by one of its endpoints at a time step when it is active. A more pragmatic variation of the problem, called (Minimum) Sliding Window Temporal Vertex Cover, we are also given a natural number ∆, and our aim is to cover every edge at least once in every ∆ consecutive time steps. These two problems are extensions of the classical (i.e. static) Minimum Vertex Cover problem to temporal graphs, and have been shown to be computationally hard for arbitrary temporal graphs. The purpose of this project is to look at known approximation algorithms for the two problems and also focus on special classes of input graphs in an effort to derive better ratios.  |
| Reference URLs         | https://drops.dagstuhl.de/opus/volltexte/2018/9152/pdf/LIPIcs-ICALP-2018-148.pdf  |
| Anticipated Outcomes   |  Implementation and evaluation of existing algorithms with possible development of new approaches. |
| Requirements           | An interest in temporal graphs and background knowledge in graph theory and graph algorithms  |
| Max Number of Students | 5  |
| Project Type           | L3, L4  |
| Keywords               | temporal graph, vertex cover, algorithm, approximation algorithm  |
### Theme EA-3: Algorithms for maximum colourful subgraphs in vertex-coloured graphs
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Vertex-coloured graphs can be used to represent connections and interactions between groups of entities of a network (e.g. species in a biological network) where different groups have different colours. Given a vertex-coloured graph, one can ask the question of finding a subgraph of particular structure (e.g. cycle, path, connected component) with the most diverse population, i.e. containing the maximum number of colours in its vertices, amongst all other subgraphs with the same structure. This is the ‘Maximum Colourful Subgraph’ problem. Note that in this context of vertex colouring, two adjacent vertices may have the same colour. The aim of this project is to implement existing algorithms for finding maximum colourful subgraphs in coloured graphs, compare their experimental performance with the theoretically predicted one, and investigate possible improvements or new algorithms for special classes of input graphs. |
| Reference URLs         | https://www.ibisc.univ-evry.fr/~thang/Papers/tropical-cycles.pdf  |
| Anticipated Outcomes   | Implementation and evaluation of existing algorithms with possible further development.  |
| Requirements           |  An interest and background knowledge in graph theory and graph algorithms |
| Max Number of Students | 5  |
| Project Type           | L3, L4  |
| Keywords               | graph, vertex-coloured, algorithm, heuristic  |
### Theme EA-4: Evaluating algorithms for Colouring Random Intersection Graphs
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  A proper colouring of a graph is an assignment of integers (called colours) to the vertices of the graph such that no two adjacent vertices receive the same colour. A random intersection graph is constructed by assigning each node a set of labels in some random manner and then putting an edge between any two nodes that share labels. On one hand, graph colouring is a popular research topic partly due to its plethora of open problems, and its various application areas. On the other hand, random intersection graphs may model several real-life applications and networks quite accurately. This project will look at algorithms for colouring Random Intersection Graphs. |
| Reference URLs         |  https://livrepository.liverpool.ac.uk/3005508/1/RIGs.pdf |
| Anticipated Outcomes   | Implementation and evaluation of existing algorithms with possible further development.  |
| Requirements           |  An interest and background knowledge in graph theory and graph algorithms |
| Max Number of Students |  5 |
| Project Type           | L3, L4  |
| Keywords               |  graph, random intersection graphs, colouring, algorithm, heuristic |
### Theme EA-5: Exact and approximation algorithms for exploration of temporal stars
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Exploration of temporal stars (i.e. star graphs whose edges appear and disappear over time) can model travelling salesman scenarios where the salesman has to follow particular timetables for his routes and always returns to the origin after visiting a new vertex. The aim of the project is to look at existing exact and approximation algorithms, their implementation and evaluation of their performance compared to the theoretically predicted performance. Special cases will also be considered to examine possible improvement of already known algorithms.  |
| Reference URLs         | https://arxiv.org/pdf/1805.04713.pdf  |
| Anticipated Outcomes   | Implementation and evaluation of existing algorithms with possible development of new approaches.  |
| Requirements           | An interest and background knowledge in graph theory and graph algorithms  |
| Max Number of Students |  5 |
| Project Type           | L3, L4  |
| Keywords               | temporal graph, graph exploration, approximation algorithm  |

## Staff Proposer: Noura Al-Moubayed
### <span style="color:red;">Theme NAM-1: Question Answering System for Cancer Patients Support</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The project will focus on build Question Answering system based on advances in natural language processing to support cancer patients during and after their therapy. The Student is expected to collect Cancer related data and use it to train QA system using state of the art natural language processing techniques. If successful, the student will have the ability to use our social robot interface to demo the developed system. The project is flexible and is open for the students to suggest their own data. For examples QA on movies instead of cancer related questions.  |
| Reference URLs         | https://www.sciencedirect.com/science/article/abs/pii/S0306457315000515 https://cs224d.stanford.edu/reports/StrohMathur.pdfv https://link.springer.com/chapter/10.1007/978-3-030-29513-4_31  |
| Anticipated Outcomes   | Knowledge on how to develop end to end solutions using advanced machine learning. Knowledge on data collection, preprocessing, and cleaning. Learn the different types of models to learn from sexual data. Learn the state of the art QA systems and how to retrain them using the collected data.  |
| Requirements           | Excellent programming skills in Python. Good Mathematics knowledge  |
| Max Number of Students | 3  |
| Project Type           | L4  |
| Keywords               |  natural language processing, deep learning, question answering |
### <span style="color:red;">Theme NAM-2: Toxic Language Detection using Machine Learning</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Social media, blogs, and online news platforms allow users to share their opinions on arbitrary content with a broad audience. Among U.S. American news commenters, the majority (%56) wants to express an emotion or opinion. This reason is followed by wanting to add information (%38), to correct inaccuracies or misinformation (%35) or to take part in a debate (%31). Toxic comments are a major problem for these platforms. The motivation for this project is the overwhelming number of comments posted online, which needs moderation to remain engaging. The project aims at tackling the problem of online toxic language detection and understanding what makes a particular comment toxic to help social media platforms stay safe for people to use and to help in moderating the exponentially growing content. The project will use standard natural language techniques in addition to advanced machine learning to solve the proposed problem using publicly available datasets.  |
| Reference URLs         | https://www.aclweb.org/anthology/W18-5105.pdf https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/reports/6856482.pdf https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge  |
| Anticipated Outcomes   | developing a novel toxic Language detection system  |
| Requirements           | 	Good mathematical background Strong interest in natural language processing  |
| Max Number of Students | 3  |
| Project Type           |  L4 |
| Keywords               |  	Natural Language Processing, Machine Learning, Deep Learning, Toxic Language, Sentiment Classification. |

## Staff Proposer: Neelanjan Bhowmik
### Theme NB-1: How to Train X-Ray Imagery: Object Segmentation in X-Ray Image Using Deep Convolutional Neural Network
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | X-ray baggage security screening is widely used to maintain aviation and transport security, itself posing a significant image-based screening task for human operators reviewing compact, cluttered and highly varying baggage contents within limited time-scales. With both increased passenger throughput in the global travel network and an increasing focus on wider aspects of extended border security (e.g. freight, shipping postal), this poses both a challenging and timely automated object detection task. Of particular interest is the focus on automated security X-ray analysis for particular classes of object such as electronics, electrical items and bottles using supervised convolutional neural networks (CNN). However, the use of the CNN approach requires large amounts of labelled data (which is done manually) to facilitate a complex end-to-end feature extraction and instance segmentation process. With the hasty growth of the X-ray imagery, it is imperative to develop an effectual object instance segmentation mechanism. This project aims to investigate the automatic object instance segmentation by using convolutional neural network architecture within the context of X-Ray Imagery. The use of CNN frameworks such as, Mask R-CNN, which efficiently detects object segment and generates mask (e.g., exact/near the approximate shape of object/polygon) for each instance, is one of the CNN based approaches. This work primarily explores the following objective: development of automatic object segmentation framework using deep CNN architecture.  |
| Reference URLs         | Mask R-CNN (https://arxiv.org/abs/1703.06870), Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (https://arxiv.org/abs/1506.01497), YOLACT: Real-time Instance Segmentation (https://arxiv.org/abs/1904.02689), Using deep Convolutional Neural Network architectures for object classification and detection within X-ray baggage security imagery (https://ieeexplore.ieee.org/document/8306909)  |
| Anticipated Outcomes   | A working software demonstrator, open source contribution and technical evaluation of state of the art in object instance segmentation using deep CNN architectures.  |
| Requirements           | Students must have taken or be taking Image Processing (L2), Computer Vision (L3 + L4) and ideally Machine Learning / Deep Learning (L3/:4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. Familiarity with OpenCV, modern machine learning tools, pytorch and the Linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           |  L3, L4 |
| Keywords               | computer vision, image processing, machine learning, deep learning, convolutional neural networks, object detection, object segmentation  |
### Theme NB-2: Going Higher and Deeper: A Comparison of Deep Convolutional Neural Network Architectures for Object Detction
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Due to object detection’s close relationship with image understanding, it has attracted much research attention in recent years. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. The deep convolutional neural network (CNN) models behave differently in network architecture, training strategy, and optimization function. This work aims to investigate the performance of different deep CNN based object detection architectures, such as Yolo, Faster-RCNN, RetinaNet, SSD, etc., on different image dataset. The potential application domain will be: visible image database (e.g. COCO dataset) and non-visible image database (e.g. FLIR Thermal dataset) for performance comparison. Additionally, we investigate the effect of the volume of the training data on model performance (data vs performance).  |
| Reference URLs         | YOLOv3: An Incremental Improvement (https://arxiv.org/abs/1804.02767), Mask R-CNN (https://arxiv.org/abs/1703.06870), Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (https://arxiv.org/abs/1506.01497), SSD: Single Shot MultiBox Detector (https://arxiv.org/abs/1512.02325)  |
| Anticipated Outcomes   | A working software demonstrator, open source contribution and technical evaluation of state of the art in object detection models using deep CNN architectures.  |
| Requirements           | Students must have taken or be taking Image Processing (L2), Computer Vision (L3 + L4) and ideally Machine Learning / Deep Learning (L3/:4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. Familiarity with OpenCV, modern machine learning tools, pytorch and the Linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               |  computer vision, image processing, machine learning, deep learning, convolutional neural networks, object detection |
### Theme NB-3: Inter-domain Image Retrieval Using Deep Convolutional Neural Network
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Image retrieval is a fundamental problem in computer vision: given a query image, can you find similar images in a large database? With the growing acquisition of digital contents in various domains, inter-domain image matching is a topical and challenging research topic in computer vision. To begin with, what is inter-domain image retrieval: retrieval of visually similar images where the query images are different in characteristics from the database images. In other words, the query images belong to one domain, such as old photographs, painting, postcards, sketches, etc. and the querying image database is from a different domain, such as street view, a camera captured images, digitally scanned images, etc. This project aims to investigate the use of deep learning models (convolutional neural networks) to learn the attributes of the inter-domain images. There are several works can be found in the literature of image retrieval. However, most of them deal with image matching between similar characteristics or within the database. Unfortunately, image matching between different characteristics with similar contents is quite challenging. The transfer learning or domain adoption could be one of the possibilities to learn the image features across the genre. This work primarily explores following two objectives: first, matching between inter-domain digital contents and second, linking between images of landmarks, places, maps, etc. with the geo-referenced database, such as Google-Landmarks dataset, which involves challenges in both database and a query such as background clutter, partial occlusion, multiple landmarks, etc. |
| Reference URLs         | Cross-domain image localization by adaptive feature fusion (https://ieeexplore.ieee.org/document/7924572), Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking (https://arxiv.org/abs/1803.11285), Deep Learning for Content-Based Image Retrieval: A Comprehensive Study (https://dl.acm.org/doi/pdf/10.1145/2647868.2654948), Deep Supervised Hashing for Fast Image Retrieval (https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf)  |
| Anticipated Outcomes   |  A working software demonstrator and technical evaluation of state of the art in inter-domain image matching using deep learning models aimed towards linking multimedia contents and geo-referenced databases. |
| Requirements           | Students must have taken or be taking Image Processing (L2), Computer Vision (L3 + L4) and ideally Machine Learning / Deep Learning (L3/:4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. Familiarity with OpenCV, modern machine learning tools, pytorch and the Linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               |  computer vision, image processing, machine learning, deep learning, convolutional neural networks, image retrieval |
### Theme NB-4: Check-in in Eiffel Tower: Landmark Recognition Using Deep Convolutional Neural Network
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Did you ever go through your vacation photos and ask yourself: What is the name of this temple I visited in China? Who created this monument I saw in France? Landmark recognition can help! Image retrieval is a fundamental problem in computer vision: given a query image, can you find similar images in a large database? This is especially important for query images containing landmarks, which accounts for a large portion of what people like to photograph. This project aims to investigate the use of deep convolutional neural network architecture to learn the discriminative global and local CNN features to deal with general and cross-domain examples for image recognition. The transfer learning or domain adoption could be one of the possibilities to learn the image features across the domain. In this work, we plan to use Google Landmarks dataset, which is the largest worldwide dataset for recognition of human-made and natural landmarks for landmark recognition. This involves challenges in both database and a query such as background clutter, partial occlusion, etc.  |
| Reference URLs         | Google landmarks (https://ai.googleblog.com/2019/05/announcing-google-landmarks-v2-improved.html), Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking (https://arxiv.org/abs/1803.11285), Deep Learning for Content-Based Image Retrieval: A Comprehensive Study (https://dl.acm.org/doi/pdf/10.1145/2647868.2654948), Cross-domain image localization by adaptive feature fusion (https://ieeexplore.ieee.org/document/7924572)  |
| Anticipated Outcomes   | A working software demonstrator and technical evaluation of state of the art in image recognition using deep CNN architecture aimed towards recognizing landmarks.  |
| Requirements           | Students must have taken or be taking Image Processing (L2), Computer Vision (L3 + L4) and ideally Machine Learning / Deep Learning (L3/:4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. Familiarity with OpenCV, modern machine learning tools, pytorch and the Linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | computer vision, image processing, machine learning, deep learning, convolutional neural networks, image retrieval, landmark recognition  |

## Staff Proposer: Magnus Bordewich
### Theme MB-1: Implementing and Testing Phylogenetic Reconstruction Algorithms
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | This project would involve implementing and testing algorithms for building evolutionary trees based upon DNA or other suitable data. <br><br>A central task in evolutionary biology is inferring the ancestral history of a collection of present-day species based on their inherited characteristics. This inference is usually represented by a phylogenetic (evolutionary) tree. One widely-used approach is to use a measure of distance between species, such as the time since separation from the most recent common ancestor, to infer the structure of ancestral relationships. Such approaches are called distance-based methods, and include the popular method of Neighbour-Joining [1].<br><br>Although one typically thinks of evolution as being a tree-like process, it is now well recognised that for many collections of taxa the ancestral history is non-tree-like and is more accurately represented by a phylogenetic network rather than a phylogenetic tree. This is because of reticulate (non-tree-like) processes in evolution such as hybridisation and horizontal gene transfer. This project would involve implementing and testing a recently proposed algorithm for efficiently reconstructing an edge-weighted tree-child network from inter-taxa distances [2], and presenting the output in Newick format [3].  |
| Reference URLs         | [1] Neighbour Joining https://en.wikipedia.org/wiki/Neighbor_joining<br>[2] Recovering normal networks from shortest inter-taxa distance information (2018) https://doi.org/10.1007/s00285-018-1218-x<br>[3] Extended Newick Format https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-532  |
| Anticipated Outcomes   | A working algorithm that can read in a matrix of distance data and present a network displaying that data appropriately.<br>Analysis of the performance and efficiency of the algorithm based upon empirical data.  |
| Requirements           |   |
| Max Number of Students | 2  |
| Project Type           |  L3, L4 |
| Keywords               | 	Bioinformatics, Algorithms  |
### Theme MB-2: Elliptic Curve Cryptography
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Elliptic Curve Cryptography is the modern standard for efficient key exchange. This project will involve implementing and testing an Elliptic Curve Cryptosystem. At an advanced level the project could compare the efficiency of ECC with RSA cryptography, explore generation of curves and suitable intial points, explore attacks on ECC and compare with the security of RSA at similar key sizes, or implement and test calculations secure against timing attacks (e.g. Mongomery multiplication).  |
| Reference URLs         | Guide to Elliptic Curve Cryptography. Hankerson, Menezes and Vanstone.<br>https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.394.3037&rep=rep1&type=pdf<br>Elliptic Curves and Cryptography, Jurisic and Menezes.<br>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.132.3788&rep=rep1&type=pdf  |
| Anticipated Outcomes   | A working elliptic curve crypto system. Empirical testing of the system.  |
| Requirements           |   |
| Max Number of Students |  3 |
| Project Type           | L3, L4  |
| Keywords               | Cryptography, security  |
### Theme MB-3: Embedding trees in networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |	Evolutionary trees, also called phylogenetic trees, are used in biology to represent the ancestral history of a collection of present-day species. However, evolution is not always tree-like because of reticulation events such as hybridizations and lateral gene transfers. Consequently, rooted acyclic digraphs, in which there is exactly one vertex that has in-degree zero and where the vertices of out-degree zero represent the present-day species, are being used to model reticulate evolution. A fundamental problem that arises is to take a collection of leaf labelled trees and fit them into a phylogenetic network under various constraints, e.g. you may wish to minimise the number of hybridisations in the resulting network or to fit them onto a network from a particular class such as temporal networks.<br><br>This project would involve implementing and testing algorithms that take two or more phylogenetic trees as input and return a network of a specified type which embeds those trees, or determines that no such network exists. Several suitable algorithms have been recently proposed which could be implemented and tested, but there are also opportunities to develop novel algorithms for new cases.   |
| Reference URLs         | A Reduction Algorithm for Computing the Hybridization Number of Two Trees. Bordewich, M., Linz, S., St. John, K. and Semple, C.<br>https://community.dur.ac.uk/m.j.r.bordewich/papers/Bordewich2007-b.pdf<br>Any two binary phylogenetic trees can be displayed by a normal phylogenetic network. Bordewich and Semple. Manuscript available on request.  |
| Anticipated Outcomes   |  An algorithm that takes two or more phylogenetic trees as input and returns a network of a specified type embedding the input. |
| Requirements           |   |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | 	Phylogenetics, Algorithms, Bioinformatics  |
### Theme MB-4: Enigma and BOMBE simulation
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	This project is about understanding the operation of both a German Enigma machine (easy) and the Turing BOMBE (more complex) and developing a simulator for each. These could then be used to first encrypt some messages, and then attempt to crack them using the BOMBE. Advanced deliverables would include expanding the scope or size of the BOMBE simulation to make use of the power of modern computers, parallelising the operation of the BOMBE to make cracking more efficient, or incorporating additional information about the ciphertext into the computation, e.g. guesses as to parts of the plaintext.  |
| Reference URLs         |  The BOMBE - a remarkable logic machine, Donald W. Davies, Cryptologia<br>https://www.tandfonline.com/doi/abs/10.1080/0161-119991887793<br>The Code Book, Simon Singh<br>https://simonsingh.net/books/the-code-book/the-book/ |
| Anticipated Outcomes   |A working simulation of both the Enigma machine and the Turing BOMBE. Empirical testing and analysis of performance.   |
| Requirements           |   |
| Max Number of Students |  3 |
| Project Type           |  L3, L4 |
| Keywords               |  Cryptography, security |
### Theme MB-5: Anomaly detection via kernel density estimators
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  	The aim of this project is to implement and then improve a recently developed anomaly detection algorithm. The algorithm involves first training a standard neural network for object recognition, and then taking the values from one of the hidden layers of this network as a feature vector representing the input image. These feature vectors are then used with kernel density outlier detection to detect anomalies in a set of images. |
| Reference URLs         | Region Based Anomaly Detection with Real-Time Training and Analysis. Philip Adey, Oliver Hamilton, Magnus Bordewich, Toby Breckon.<br>http://breckon.eu/toby/publications/papers/adey19anomaly.pdf  |
| Anticipated Outcomes   | A working anomaly detection algorithm.<br>Empirical testing and evaluation.  |
| Requirements           |   |
| Max Number of Students |  2 |
| Project Type           | L3, L4  |
| Keywords               | Neural network, anomaly detection, AI, deep learning   |
### Theme MB-6: Reinforcement Learning
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | This project involves developing a reinforcement learning algorithm to learn to perform successfully in some environment. Suitable environments include traditional games (such as backgammon) or computer based games or environments such as those found at OpenAI Gym. The learning algorithm could be Q-learning or a deep reinforcement learning algorithm depending on the environment, or the project could involve a comparison between the two approaches.  |
| Reference URLs         | 	OpenAI Gym https://gym.openai.com<br>An Introduction to Deep Reinforcement Learning https://arxiv.org/pdf/1811.12560.pdf<br>Reinforcement Learning: An Introduction Sutton and Barto https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf  |
| Anticipated Outcomes   | A working reinforcement learning system that can successfully operate in its environment.  |
| Requirements           |   |
| Max Number of Students |  3 |
| Project Type           |  L3, L4 |
| Keywords               |  Machine Learning, Reinforcement learning |

## Staff Proposer: Steven Bradley
### Theme SPB-1: Generative Adversarial Networks for Sound Synthesis
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	Digital audio synthesis has been increasingly prevalent since the 1980s, but there is still a divide between the sound of a synthesiser and that of an acoustic instrument. Some types of instrument (e.g. pianos) have digital implementations with good fidelity, but many (e.g. violins and trumpets) do not. In recent years Generative Adversarial Networks (GANs) have been developed used successfully for generative visual art, producing artworks of impressive realism. Some work has recently been carried out into using GANs for audio synthesis, but with varying levels of success. Working with raw sample level data has not been very successful, and there is scope for looking at feature engineering through the use of compressed audio formats (e.g. MP3) and a range of deep learning techniques e.g. convolutional neural networks (CNNs). Lastly, synthesis of individual notes could be extended to entire musical phrases, based on a prescribed melody line, which has a visual analogue in picture colouring  |
| Reference URLs         | Adversarial Audio Synthesis https://arxiv.org/abs/1802.04208 GANSynth: Adversarial Neural Audio Synthesis https://arxiv.org/abs/1902.08710 Colorization Using ConvNet and GAN http://cs231n.stanford.edu/reports/2017/pdfs/302.pdf  |
| Anticipated Outcomes   | Basic: reproduction of existing results in GANs for audio synthesis and extension to training of new instrument types Intermediate: comparison of different audio compression methods as feature extraction for training deep neural networks Advanced: synthesis of musical phrases  |
| Requirements           | Software Methodologies Deep learning and reinforcement learning  |
| Max Number of Students | 2  |
| Project Type           |  L3, L4 |
| Keywords               | neural networks  |
### Theme SPB-2: Dancing robots
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The department has several humanoid nao robots. This project involves getting the robots to mimc human dancing by identifying human poses through computer vision, and then integrating them into a series of moves.  |
| Reference URLs         | Toward a Dancing Robot With Listening Capability: Keypose-Based Integration of Lower-, Middle-, and Upper-Body Motions for Varying Music Tempos  |
| Anticipated Outcomes   | Deliverables could involve extracting a whole dance move and/or generating a dance routine to fit a piece of audio.  |
| Requirements           | Computing Methodologies, Computer vision  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               |   |
### Theme SPB-3: Internet of Things for Accessible and Adaptive Musical Instruments
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Learning to play a traditional musical instruments can require a lot of practice over many years, and relies on particular kinds of dexterity and strength. The well-being advantages of making music are well-documented, but many many musical instruments are inaccessible to people who have particular conditions. There is quite a long history of developing specifically adapted or tailored musical instruments, but these are often specific and non-adaptable. Internet-of-Things frameworks such as node-red provide a platform for quickly integrating different kinds of sensor and control hardware so have the potential to act as a tool for designing and re-using accessible musical instruments.  |
| Reference URLs         | Sound Control: Supporting Custom Musical Interface Design for Children with Disabilities https://www.doc.gold.ac.uk/~mas01rf/publications/Parke-WolfeScurtoFiebrink_NIME2019.pdf Accessible Digital Musical Instruments - A Survey of Inclusive Instruments Presented at the NIME, SMC and ICMC Conferences https://www.researchgate.net/publication/327187266_Accessible_Digital_Musical_Instruments_-_A_Survey_of_Inclusive_Instruments_Presented_at_the_NIME_SMC_and_ICMC_Conferences  |
| Anticipated Outcomes   |  There are many possible combinations of approaches, looking at a range of sensors e.g. mobile phones, tablets, microcontrollers (e.g. microbits) and specially designed hardware. Similarly the sounds could be digitally synthesised or created with physical actuators. These could be developed independently, or possibly working with children at a local special school. |
| Requirements           |   |
| Max Number of Students |  2 |
| Project Type           | L3, L4  |
| Keywords               |   |

## Staff Proposer: Toby Breckon
### Theme TB-1: On-line Optimization of Live Thermal Camera Imagery via Deep Learning and/or Reinforcement Learning
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The use of thermal imagery currently poses significant advantages for 24/7 day/night surveillance in terms of the visibility of human, animal and vehicle targets under all environmental conditions. There use in automated surveillance tasks is however often blighted by the variability of the image characteristics under differing illumination/thermal conditions. This variability originates from the use of in-built automatic image enhancement targeted towards optimal visibility for a human operator (not a mathematical algorithm). This can cause significant problems with the use of background modeling techniques that are often the first stage of processing in any target detection and tracking based application. Unfortunately, simply de-activating such automatic image enhancement appears to have a negative impact on target visibility under changing environmental conditions.<br><br>This project aims to investigate either of (a) the development of a closed loop, image illumination/variability control by providing a direct input back into the USB/serial-line control of the camera such that the parameters of the automatic image enhancement can be adjusted to maintain gradual adjustments (i.e. stable) rather than rapid changes in the characteristics of the image (potentially using a reinforcement learning approach or otherwise); or (b) recent advances in deep convolutional neural networks for thermal image enhancement (see first two references). This should in turn minimize the impact of such changes on the effectiveness of background modeling in turn improving the viability of a number of target tracking approaches for use under all conditions which can form part of the evaluation criteria (similar to [Loveday/Breckon, 2018]).<br><br>This project would make use of existing all-weather thermal camera sensing units currently used on an existing research programme within the Durham research team [and may involve a degree of configuration to support off-site remote access the camera hardware (http://usbip.sourceforge.net/ / serial to IP)]. It would build and support upon a range of existing thermal image detection, tracking and classification approaches within the Durham team. A demo of prior related work (on vehicles) at Durham is available here - [demo]  |
| Reference URLs         | Choi, Yukyung, et al. "Thermal image enhancement using convolutional neural network." 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2016.<br>Lee, Kyungjae, et al. "Brightness-based convolutional neural network for thermal image enhancement." IEEE Access 5 (2017): 26867-26879.<br>On the Impact of Parallax Free Colour and Infrared Image Co-Registration to Fused Illumination Invariant Adaptive Background Modelling(M. Loveday, T.P. Breckon), In Proc. Computer Vision and Pattern Recognition Workshops, IEEE, pp. 1267-1276, 2018. [demo]  |
| Anticipated Outcomes   |  a working software demonstrator and technical evaluation of the state of the art in adaptive closed loop control and optimization aimed towards the technical requirements of the image enhancement control task upon specific thermal camera hardware. As with earlier L4 student work on this topic in the department (Loveday, 2017/18), this work could be extended to publishable research contributions if done well. |
| Requirements           | Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevent Machine Learning / Deep Learning modules (L2/L3/L4) and be comfortable with (or able to readily pickup) C/C++ to be able to leverage existing implementations. A familiarity with OpenCV, communications & networking and the Linux operating system is of benefit. If 2 students are selected for this project, 1 student project will concentrate on option (a) based approaches whilst the other concentrates on option (b) approaches (this will be by agreement with the project supervisor and the students selected at the project kick-off meeting).  |
| Max Number of Students |  2 |
| Project Type           | L3, L4  |
| Keywords               | computer vision, image processing, thermal imaging, tracking, hardware control  |
### Theme TB-2: Automatic Behaviour Understanding for Pedestrians within Infrared (Thermal) Video surveillance via On-line Body Pose Estimation
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Thermal imagery currently poses significant advantages for 24/7 day/night surveillance in terms of the visibility of human, animal and vehicle targets under all environmental conditions. Notably it gives rise a highly robust long-term pedestrian detection and tracking. However, long-term automatic behaviour analysis (e.g. what is happening ? / what are people doing ? / is this normal for this time of day?) remains a key challenge for the future deployment of thermal sensing as an autonomous sensor technology.<br><br>This project aims to investigate the use of recent advances in Real-time Mult-Person Pose Estimation as the primary enabler to achieving long-duration pedestrian target behaviour monitoring within thermal video imagery. Specifically it would look at adapt existing real-time pose estimation techniques across varying scales (short-range, long-distance) of pedestrians within thermal video, potentially from one or more network connected cameras systems. Furthermore, it would look to consider multiple variants of the underlying deep learning architecture as appropriate. Subsequently, this pose estimation would then be used as a temporally aggregated input to further machine learning based classification for the automatic determination of the behavior of one or more pedestrians within the scene. Advanced options could also consider aspects of target tracking and the challenge of long-duration - behaviour vs. time-of-day/week - behavioural activity understanding.<br><br>This project would make use of existing all-weather thermal camera sensing units currently used on an existing research programme within the Durham research team (from which time-synchronised imagery can already be obtained). It would build and support upon a range of existing thermal image detection, tracking and classification approaches within the Durham team. A demo of prior related work (on vehicles) at Durham is available here - [demo].  |
| Reference URLs         |  Nie, B.X., Xiong, C. and Zhu, S.C., 2015, June. Joint action recognition and pose estimation from video. In Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on (pp. 1293-1301). IEEE. (and articles that cite this work)<br>Cao, Z., Simon, T., Wei, S.E. and Sheikh, Y., 2017, July. Realtime multi-person 2D pose estimation using part affinity fields. In CVPR (Vol. 1, No. 2, p. 7). (demo linked above)<br>Insafutdinov, E., Pishchulin, L., Andres, B., Andriluka, M. and Schiele, B., 2016, Oc |
| Anticipated Outcomes   |  a working software demonstrator and technical evaluation of the state of the art in real-time behaviour understanding with potential to extend to publishable novel contributions in this research area. |
| Requirements           | Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevant Machine Learning / Deep Learning modules (L2/L3/L4) and be comfortable with (or able to readily pickup) python and/or C++ to be able to leverage existing implementations. A familiarity with OpenCV, machine learning frameworks, ROS and the Linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | computer vision, image processing, thermal video, pose estimation, tracking, deep learning  |
### Theme TB-3: HDR imaging applied to information visualization from dual energy X-ray Imagery
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Future airport and border security screening systems will use increased levels of automation to improve performance, increase overall screening coverage and reduce security-related operating costs (which are a substantive part of the operating costs of a modern day airport or freight business).<br><br>"Within transport security, screening personnel are required to manually inspect thousands of baggage items for a range of contraband on a daily basis. In addition to this enormous workload, X-ray baggage imagery can be extremely challenging to interpret. Due to the nature of packed baggage, where objects are tightly packed, X-ray imagery generally contains a very high degree of clutter and inter-object occlusion. Consequently, objects are most often occluded or shown from unusual viewpoints. It has been shown that both human and computer detection rates are severely affected by complexity and clutter and therefore image interpretation in such environments is particularly challenging. Furthermore increasing global travel demands ever increasing turnover rates at security checkpoints allowing screening personnel only limited time to examine each baggage item." [Kundegorski et al., 2016]<br><br>Presently, X-ray transport security imagery is presented using a common false map that maps objects to the material they are made from (plastics, organics, metals, liquids ... etc.). This materials information comes from the use of dual-energy X-ray whereby the use of two X-ray energy levels facilitates the recovery of materials information (effective-Z, which forms the backbone of current explosive detection screening in all global airports). This project explores how this information is presented to the human operator on-screen, and ultimately to future automatic screening algorithms, and how this could be improved using High Dynamic Range (HDR) imaging. The effective-Z information recovered is currently simply mapped to an 8-bit RGB image - how can the presentation of this information be improved using HDR techniques ? (to facilitate improved dynamic range for human review and as an input to automated detection). Subsequent extensions could examine the performance impact of using such a HDR representation for automated threat detection and also an extension into use for 3D visualization of dual-energy computed tomography (CT) volumes via volume rendering approaches (also used for security screening).<br><br>This project would make use of the dual-energy X-ray security scanner facilities and dual-energy computed tomography volume datasets available within the Durham research team - examples of previous automatic detection work by the Durham team are available for both X-ray threat detection (using an earlier technqiue) and also for computed tomography that show current colour-mapping based display.  |
| Reference URLs         | Improved Threat Identification Using Tonemapping of High-Dynamic-Range X-ray Images Glover, J., Hudson, L., and Paulter, N., Journal of Testing and Evaluation, Vol. 46, No. 4, 2018, pp. 1462-1467, https://doi.org/10.1520/JTE20170350. ISSN 0090-3973<br>Rogers, T.W., Jaccard, N., Morton, E.J. and Griffin, L.D., 2017. Automated x-ray image analysis for cargo security: Critical review and future promise. Journal of X-ray science and technology, 25(1), pp.33-56.<br>A Review of Automated Image Understanding within 3D Baggage Computed Tomography Security Screening (A. Mouton, T.P. Breckon), In Journal of X-Ray Science and Technology, IOS Pr  |
| Anticipated Outcomes   | a working software demonstrator and technical evaluation of the state of the art in the use of HDR imaging for the display and interpretation of dual energy X-ray (and CT) images (with potential to extend to publishable novel contributions in this research area).  |
| Requirements           | Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevant Machine Learning / Deep Learning modules (L2/L3/L4) / Computer Graphics (L2/L3/L3, as available) and be comfortable with (or able to readily pickup) Python (or C++) to be able to leverage existing implementations. A familiarity with OpenCV, communications & networking and the Linux operating system is of benefit.  |
| Max Number of Students |  1 |
| Project Type           | L3, L4  |
| Keywords               | computer vision, image processing, false colour, X-ray, Computed Tomography, security, human factors  |
### Theme TB-4: Camera-to-Camera Tracking for Person Re-identification via Deep Learning Architectures within Thermal Imagery
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Although use of thermal imagery currently poses significant advantages for 24/7 day/night surveillance in terms of the visibility of human, animal and vehicle targets under all environmental conditions, a key limitation is the lack of colour detail suitable for many current approaches to the problem of cross-camera person re-identification (i.e. the camera-to-camera tracking of pedestrian targets). Cross-camera person re-identification (Re-ID) is a key research problem within the domain of visual surveillance and a key challenge for the future deployment of thermal sensing as an autonomous sensor technology.<br><br>This project aims to investigate the use of recent advances in the use of deep learning convolutional neural networks (CNN) for the Re-ID within this context - cross-camera person re-identification within pedestrian tracking applied to a multiple camera network comprising far infrared (thermal) cameras. The key investigative question would relate to how effective can the use of recent concepts such as triplet-loss, quadruplet-loss, Siamesse networks and other state of the art approaches can be applied to Re-ID on thermal imagery. Evaluation would look to tackle Re-ID in both a closed world (fixed list of pedestrian targets) and open world (unconstrained list of pedestrian targets) problems and look to provide a side-by-side comparison of multiple approaches within a common framework.<br><br>This project would make use of existing all-weather thermal camera sensing units currently used on an existing research programme within the Durham research team (from which time-synchronised imagery can already be obtained). It would build and support upon a range of existing thermal image detection, tracking and classification approaches within the Durham team including prior work on this topic by a former L3/L4 student. A demo of prior related work (on vehicles) at Durham is available here - [demo]. A key aspect would be the design and evaluation of an \"at scale\" dataset for work on this topic.  |
| Reference URLs         | A Discriminatively Learned CNN Embedding for Person Re-identification] (https://arxiv.org/abs/1611.05666).<br>Person Re-Identification by Multi-Channel Parts-Based CNN With Improved Triplet Loss Function - De Cheng, Yihong Gong, Sanping Zhou, Jinjun Wang, Nanning Zheng; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 1335-1344<br>Xiao, T., Li, H., Ouyang, W. and Wang, X., 2016, June. Learning deep feature representations with domain guided dropout for person re-identification. In Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on (pp. 1249-1258). IEEE. |
| Anticipated Outcomes   | a working software demonstrator and technical evaluation of the state of the art in the use of varying deep learning convolutional neural networks (CNN) for application to Re-ID in infrared (thermal) imagery (which could extend to publishable research contributions if done well).  |
| Requirements           |Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevant Machine Learning / Deep Learning modules (L2/L3/L4) and be comfortable with (or able to readily pickup) C/C++, in addition to Python, to be able to leverage existing implementations. A familiarity with OpenCV, communications & networking and the Linux operating system is of benefit.|
| Max Number of Students | 1  |
| Project Type           |  L3, L4 |
| Keywords               | computer vision, image processing, tracking, thermal imaging, automated surveillance, object detection, CNN, Re-id, deep neural networks  |
### Theme TB-5: Drive-by Rain Removal For Autonomous Road Vehicle Sensing Using Deep Learning Approaches
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The presence of raindrop induced image distortion has a significant negative impact on the performance of a wide range of all-weather visual sensing applications including within the increasingly import context of vehicle autonomy. A key part of this problem is robust rain drop detection such that the potential for performance degradation in effected image regions can be identified and a relative “trust model” of image information can be constructed (i.e. if there is a rain drop in this image region, perhaps trust the stereo depth and obstacle detection bit less here - ?!). Within the context of future autonomous road vehicles, the impact of weather related sensor degradation is a major barrier to widespread uptake of low-cost sensing solutions beyond regions with suitable climate conditions.<br><br>Prior work in the field has looked to address this problem using a number of approaches – notably with the Durham research team recent work focusing soley on detection has used localised shape, saliency and texture information from the image within a bag of visual words classification pipeline (Webster, 2015) and more recently exploring the use of first generation deep convolutional neural network (CNN) classification techniques combined with varying initial detection strategies (Guo, 2018). This project looks to extend the work by other research teams (Yang, 2017 / Fu, 2017) on combined detection and removal approaches - albeit from static scene images.<br><br>Specifically, this project would look to adapt the static scene approaches of (Yang, 2017 / Fu, 2017) to a dynamic camera scenario such that the distortion effects of rain can be jointly detected and removed from an on-vehicle camera video feed in real-time as the vehicle is in motion (\"as you drive down the road\"). This could be potentially be carried out by exploring the use of various temporal extensions to common CNN models (e.g. Temporal Convolutional Networks, RNN, LTSM models) (project student #1). An alterative would be to pose this as a style transfer and domain adaptation problem with reference to other work in the Durham research team (Atapour-Abarghouei, 2018) - (project student #2). Furthermore, the challenge in constructing large quantities of paired raining / not raining image sequences can potentially be overcome using positional GPS matching or using a similarity network model (Veut, 2017) to perform image pairing under varying conditions (across the growing number of large datasets:- Mapillary, long list ...).<br><br>Further extensions could look at the potential for raindrop detection within the context of stereo vision which is commonplace within current vehicle autonomy demonstrator vehicles – i.e. the detection, via deep learning or other means, of invalid disparity estimates originating from rain related mage degradation allowing the vehicle sensing system to similar adjust its “trust model” of 3D image information. This project could make use of the all-weather multiple on-vehicle camera sensing units currently used on an existing research programme within the Durham research team.  |
| Reference URLs         | Yang, W., Tan, R.T., Feng, J., Liu, J., Guo, Z. and Yan, S., 2017, July. Deep joint rain detection and removal from a single image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 1357-1366).<br>Fu, X., Huang, J., Zeng, D., Huang, Y., Ding, X. and Paisley, J., 2017, July. Removing rain from single images via a deep detail network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).<br>Veit, A., Belongie, S. and Karaletsos, T., 2017. Conditional similarity networks. Computer Vision and Pattern Recognition (CVPR 2017).  |
| Anticipated Outcomes   |  a working software demonstrator and technical evaluation of the state of the art in real-time raindrop removal using an adaptation of various deep learning approaches (which could extend to publishable research contributions if done well). |
| Requirements           |  Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevant Machine Learning / Deep Learning modules (L2/L3/L4) and be comfortable with (or able to readily pickup) C/C++, in addition to python, to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the Linux operating system is of benefit. |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               |  computer vision, image processing, machine learning, temporal networks, deep learning, image distortion, driver-less vehicles |
### Theme TB-6: GPU-Based Scene Flow Recovery using Dense Gradient-based Features (DeGraF) for Future Autonomous Road Vehicles
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The calculation of scene flow from an on-board vehicle camera offers a key insight into both the structure of the world around the vehicle and the relative behavior of dynamic objects (people, vehicles, pedestrians) within the environment. A key constraint within on-board vehicle sensing systems for future autonomous vehicles is both cost and processing requirements (e.g. a full roof-top laser scanner setup costs more than a family car, on-board processing can drain electric/hybrid batteries quickly). The use of scene flow as a sensing approach facilitates the use of a single (low cost) camera setup on-board to recover rich information about the scene.<br><br>"The estimation of dense 3D motion fields, widely termed scene flow, is currently gaining increasing attention. Dense motion vectors yield insights into the geometric layout of a scene as well as its decomposition into individually moving objects. Important applications include mobile robotics and autonomous driving where 3D object motion is a fundamental input to high-level tasks such as scene understanding, obstacle avoidance or path planning." [Menze et al., 2015]<br><br>This project aims to investigate recent advances in the Durham research team using Dense Gradient-based Features (DeGraF), that show promising results in terms of low computational requirements and high levels of feature invariance (2016) and subsequently their ability to perform robust optic flow calculation (2018). Prior research work (2018) on this topic showed a successful trade-off between the density of DeGraF features used for this task (and hence accuracy) and computational performance for CPU based optic flow calculation and suggested a future GPU based implementation would offer additional performance tradep-off benefits. The project would involve the re-implementation of the DeGraF feature work on the GPU (possibly as a future open source contribution to the OpenCV library), development of a scene flow estimation approach based on the use of DeGraF features and then the evaluation of this approach against both existing datasets and leading approaches in the field (see KITTI scene flow evaluation) and if possible additional real-time (live) evaluation on a Durham test platform (ground robot or road vehicle). A demo of prior related work from the Durham team is available here - [demo]  |
| Reference URLs         | Dense Gradient-based Features (DeGraF) for Computationally Efficient and Invariant Feature Extraction in Real-time Applications (I. Katramados, T.P. Breckon), In Proc. International Conference on Image Processing, IEEE, pp. 300-304, 2016. [demo] [pdf] [doi]<br>DeGraF-Flow: Extending DeGraF Features for accurate and efficient sparse-to-dense optical flow estimation (F. Stephenso, I. Katramados, T.P. Breckon), (under review) 2019 [arXiv]  |
| Anticipated Outcomes   | a working software demonstrator and technical evaluation of the state of the art in real-time scene flow using a GPU based implementation of Dense Gradient-based Features (DeGraF) (which could extend to publishable research contributions if done well).  |
| Requirements           | Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevant Machine Learning / Deep Learning modules (L2/L3/L4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with GPU programming, OpenCV and the Linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           |  L3, L4 |
| Keywords               | 	computer vision, image processing, robotics, driverless vehicles, GPU, GPGPU  |
### Theme TB-7: Real-time Fire Detection and Localization within Video Imagery using Contemporary Advances in Deep Neural Networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The increased use of widespread CCTV style monitoring in urban areas and industrial sites leads to the possibility that such systems could be used for the automatic detection of fire (i.e. flames) or the traces or fire (smoke) as a secondary detection system in addition to traditional fire alarm systems. Furthermore, an additional application would be both the identification and tracking of fire for the use on remotely deployed fire-fighting robots (ground or aerial).<br><br>This project aims to extend the current state of the art image based fire detection building on the work of [Dunnings, Breckon, 2018] and [Samarth, Breckon 2019] by considering possibly aspects of deeper contemporary architectures, the potential use of recent advances in auto-ML optimization approaches and/or the use of temporal aspects such as recurrent convolutional neural networks, Long-term Short-term Memory (LSTM) architectures or similar for this task. Key analysis would involve establishing the failure cases and limitations of existing techniques (see references) and specifically establishing new deep learning based approaches to overcome these issues. An additional potential approach would be to investigate the joint super-pixel segmentation and classification of imagery for this task (see [Dunnings, Breckon, 2018]/ [Samarth, Breckon 2019]) using a single end-to-end deep neural network approach.<br><br>Performance can be statistically evaluated over a range of established test imagery used in prior work and available publicly in addition to a growing range of on-line sources.  |
| Reference URLs         | Experimentally Defined Convolutional Neural Network Architecture Variants for Non-temporal Real-time Fire Detection (A. Dunnings, T.P. Breckon), In Proc. International Conference on Image Processing, IEEE, pp. 1558-1562, 2018. [demo] [pdf] [software] [dataset]<br>Experimental Exploration of Compact Convolutional Neural Network Architectures for Non-temporal Real-time Fire Detection (G. Samarth, N. Bhowmik, T.P. Breckon), In Proc. Int. Conf. on Machine Learning Applications, IEEE,  |
| Anticipated Outcomes   | a working software demonstrator and technical evaluation of state of the art in image based fire detection using the either temporal or non-temporal based approaches from the contemporary deep machine learning literature. As with earlier L3 student work on this topic in the department (Dunnings, 2017/18), this work could be extended to publishable research contributions if done well.  |
| Requirements           | Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevant Machine Learning / Deep Learning modules (L2/L3/L4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the Linux operating system is of benefit. If 2 students are selected for this project, 1 student project will concentrate on temporal based approaches whilst the other concentrates on non-temporal approaches (this will be by mutual agreement with the project supervisor and the students selected at the project kick-off meeting).  |
| Max Number of Students |  2 |
| Project Type           |  L3, L4 |
| Keywords               | 	computer vision, image processing, machine learning , real-time  |
### Theme TB-8: Multi-view Object Detection via Deep Neural Networks in X-ray Security Images for Future Airport and Border Security Applications
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Future airport and border security screening systems will use increased levels of automation to improve performance, increase overall screening coverage and reduce security-related operating costs (which are a substantive part of the operating costs of a modern day airport or freight business).<br><br>"Within transport security, screening personnel are required to manually inspect thousands of baggage items for a range of contraband on a daily basis. In addition to this enormous workload, X-ray baggage imagery can be extremely challenging to interpret. Due to the nature of packed baggage, where objects are tightly packed, X-ray imagery generally contains a very high degree of clutter and inter-object occlusion. Consequently, objects are most often occluded or shown from unusual viewpoints. It has been shown that both human and computer detection rates are severely affected by complexity and clutter and therefore image interpretation in such environments is particularly challenging. Furthermore increasing global travel demands ever increasing turnover rates at security checkpoints allowing screening personnel only limited time to examine each baggage item." [Kundegorski et al., 2016]<br><br>This project aims to investigate recent work in combining the use of multi-view x-ray screening (2 or more views of the same scanned item) based on the Region-based Convolutional Neural Network approach of (Steitz, 2018) which complements an existing body of research work on this topic from the Durham research team. The project would involve the re-implementation of the multi-view object detection framework outlined within the work of (Steitz, 2018) for evaluation against the current (single and multiple view) detection approaches developed at Durham (Akcay et al., Kundegorski et al., 2016 / 2017 / 2018).<br><br>The project would make use of existing an X-ray imagery data-set held within the Durham research team and potentially use/integration with a new dual-view X-ray evaluation scanner available at Durham for \"live\" testing of detection approaches on sample parcel/baggage items. It would build and support upon a range of existing X-ray detection and classification research within the Durham team. A demo of prior related work (on single view imagery) at Durham is available here - [demo]  |
| Reference URLs         | Multi-view X-ray R-CNN.Steitz, Jan-Martin O., Faraz Saeedan, and Stefan Roth. arXiv preprint arXiv:1810.02344 (2018).<br>On Using Deep Convolutional Neural Network Architectures for Automated Object Detection and Classification within X-ray Baggage Security Imagery (S. Akcay, M.E Kundegorski, C.G. Willcocks, T.P. Breckon), In IEEE Transactions on Information Forensics & Security, IEEE, Volume 13, No. 9, pp. 2203-2215, 2018 [pdf] [doi]<br>Transfer Learning Using Convolutional Neural Networks For Object Classification Wit  |
| Anticipated Outcomes   | a working software demonstrator and technical evaluation of state of the art in Region-based Convolutional Neural Network for multiple view X-ray baggage security screening (which could extend to publishable research contributions if done well).  |
| Requirements           |  Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevant Machine Learning / Deep Learning modules (L2/L3/L4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the Linux operating system is of benefit. |
| Max Number of Students |  1 |
| Project Type           |  L3, L4 |
| Keywords               |  computer vision, image processing, machine learning |
### Theme TB-9: Autonomous End-to-End Driving Extended to Mobile Robot Indoor and Outdoor Navigation Tasks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The increased use of deep learning approaches within robotics and autonomous vehicles has led to the concept of \"end-to-end\" approaches, whereby a deep neural network is used to perform direct translation of image (sensor) data inputs to drive command outputs (images in, speed and direction out). From the initial work on this topic by [Bojarski et al., 2016] explicitly applying this to autonomous road vehicles a range of variants have emerged in the literature.<br><br>"We trained a convolutional neural network (CNN) to map raw pixels from a single front-facing camera directly to steering commands. This end-to-end approach proved surprisingly powerful. With minimum training data from humans the system learns to drive in traffic on local roads with or without lane markings and on highways. It also operates in areas with unclear visual guidance such as in parking lots and on unpaved roads. The system automatically learns internal representations of the necessary processing steps such as detecting useful road features with only the human steering angle as the training signal. We never explicitly trained it to detect, for example, the outline of roads. Compared to explicit decomposition of the problem, such as lane marking detection, path planning, and control, our end-to-end system optimizes all processing steps simultaneously. We argue that this will eventually lead to better performance and smaller systems." [Bojarski et al., 2016]<br><br>This project aims to investigate this recent approach and its applicability to generalized mobile robot navigation in both indoor and outdoor environments over a range of terrains and under a range of illumination conditions. The project would involve the re-implementation of one or more of the leading end-to-end driving deep neural network approaches from the recent research literature and evaluating their suitability for this less constrained navigation task.<br><br>The project would make use of existing sensor and mobile robot hardware within the Durham research team that operates via the ROS framework. A demo of prior related work (on segmentation for off-road stereo imagery) at Durham in collaboration with Jaguar Landrover is available here - [demo]  |
| Reference URLs         |  Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Monfort, M., Muller, U., Zhang, J. and Zhang, X., 2016. End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316.<br>Learning to Drive: Using Visual Odometry to Bootstrap Deep Learning for Off-Road Path Prediction (C. Holder, T.P. Breckon), In Proc. Intelligent Vehicles Symposium, IEEE, 2018.<br>Xu, Huazhe, Yang Gao, Fisher Yu, and Trevor Darrell. \"End-to-end learning of driving models from large-scale video datasets.\" In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2174-2182. 2017. |
| Anticipated Outcomes   |  a working software demonstrator and technical evaluation of state of the art in autonomous end-to-end driving extended for use on existing robot platforms within the department, operating in both indoor and outdoor environments on the Durham University campus (with potential to extend to publishable novel contributions in this research area). |
| Requirements           | Students must have taken or be taking Image Processing / Machine Learning (L2, as available), Computer Vision (L3 + L4 as appropriate) and ideally relevant Machine Learning / Deep Learning and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the linux operating system is of benefit.  |
| Max Number of Students |  2 |
| Project Type           |  L3, L4 |
| Keywords               |  	computer vision, image processing, machine learning , robotics, autonomous driving |

## Staff Proposer: Alexandra Cristea
### Theme AC-1: exploring the antecedents of knife crime
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Apply NLP to Child and Vulnerable Adult Case Reviews to look for common features; look at 'Learning'; 'Recommendations'; maybe look at the relationships (via NLP) between these summaries (L and R) and fuller text. |
| Reference URLs         | https://learning.nspcc.org.uk/case-reviews/recently-published-case-reviews/ https://www.cps.gov.uk/legal-guidance/child-and-vulnerable-adult-case-reviews https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/779401/Working_Together_to_Safeguard-Children.pdf https://www.unicef.org.uk/what-we-do/un-convention-child-rights/  |
| Anticipated Outcomes   | Potential outcomes can include: Use descriptive, predictive, prescriptive and/or explanatory data analytics. Building prediction models based on government data and/or social media. Visualisation of the data. User-facing system.  |
| Requirements           |  Some understanding of data analytics; some level of experience with R and/or PyTorch, Keras or similar is useful. |
| Max Number of Students | 2  |
| Project Type           |  L3, L4 |
| Keywords               | data analytics, NLP  |
### Theme AC-2: exploring the antecedents of child sexual abuse
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Apply NLP to Child and Vulnerable Adult Case Reviews to look for common features; look at 'Learning'; 'Recommendations'; maybe look at the relationships (via NLP) between these summaries (L and R) and fuller text  |
| Reference URLs         | https://learning.nspcc.org.uk/case-reviews/recently-published-case-reviews/ https://www.cps.gov.uk/legal-guidance/child-and-vulnerable-adult-case-reviews https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/779401/Working_Together_to_Safeguard-Children.pdf https://www.unicef.org.uk/what-we-do/un-convention-child-rights/  |
| Anticipated Outcomes   | Potential outcomes can include: Use descriptive, predictive, prescriptive and/or explanatory data analytics. Building prediction models based on government data and/or social media. Visualisation of the data. User-facing system.  |
| Requirements           | Some understanding of data analytics; some level of experience with R and/or PyTorch, Keras or similar is useful.  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               |  data analytics, NLP |
### Theme AC-3: exploring the antecedents of child suicide
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Apply NLP to Child and Vulnerable Adult Case Reviews to look for common features; look at 'Learning'; 'Recommendations'; maybe look at the relationships (via NLP) between these summaries (L and R) and fuller text.  |
| Reference URLs         | https://learning.nspcc.org.uk/case-reviews/recently-published-case-reviews/ https://www.cps.gov.uk/legal-guidance/child-and-vulnerable-adult-case-reviews https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/779401/Working_Together_to_Safeguard-Children.pdf https://www.unicef.org.uk/what-we-do/un-convention-child-rights/  |
| Anticipated Outcomes   | Potential outcomes can include: Use descriptive, predictive, prescriptive and/or explanatory data analytics. Building prediction models based on government data and/or social media. Visualisation of the data. User-facing system.  |
| Requirements           | Some understanding of data analytics; some level of experience with R and/or PyTorch, Keras or similar is useful.  |
| Max Number of Students | 2  |
| Project Type           |  L3, L4 |
| Keywords               | 	data analytics, NLP  |
### Theme AC-4: automating reviews of various areas
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | This is an excercise in automatically selecting (e.g. from google scholar api) and reviewing papers on a given topic - e.g., deep learning, author profiling, predictions in MOOCs, etc.; or of a given type - e.g., randomised controlled trials, cohort studies, case control studies.  |
| Reference URLs         | https://scholar.google.com/ https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=automatic+reviews&btnG= https://scholar.google.com/scholar?as_ylo=2019&q=automatic+reviews&hl=en&as_sdt=0,5  |
| Anticipated Outcomes   |  Outcomes can be any (combination of) of: - topic, or trends, or main results, or accuracy or measurements analysis - longitudinal, time-evolution studies or target variable (e.g., topic, trends, methodology, main results, accuracy, measurements) - visualisation of results |
| Requirements           | Some understanding of data analytics; some level of experience with R and/or PyTorch, Keras or similar is useful; and/or experience in visualisation. Or a strong capacity to quickly learn.  |
| Max Number of Students | 2  |
| Project Type           |  L3, L4 |
| Keywords               | NLP, data scraping, visualisation  |
### Theme AC-5: Simulate the vocabulary growth of children during childhood
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The way in which children’s vocabulary grows during childhood is modelled. We know that vocabulary rises steadily from the age of about 2 and then levels off around the teens to early 20s. It is also established that some children acquire vocabulary quicker than others and that some, often the ones with higher vocabulay, continue to learn new words longer than others. Further we know that children need interaction with others to acquire language. The model seeks to replicate these patterns with a few simple rules. It can be extended with options designed to test a series of hypotheses which explain why the growth levels off, the spread of scores increase and some individuals continue to gain vocabulary longer than others. HOW IT WORKS A child starts with zero knowledge of words but the model starts when they have learnt just a modest number (around 300) of word around the age of 2. By adulthood they have a vocabulary level around 12,000 words. They acquire vocabulary through encounters with others. Each time the child meets another person (child or adult) there is a chance of acquiring a new word or words. The probability of this happening is modelled, most simply, as being proportional to the child’s ability to absorb new word, moderated by a chance element. But if the other person knows fewer words than the child’s vocabulary then the child’s vocabulary does not increase or decrease. This corresponds to the “Level-off?” option “As_others”. This simple approach produces results which do not quite fit the known pattern. For example it takes too long to flatten off at the highest adult vocabulary. And so, three alternative possibilities can be selected from “Level-off?”: a) “Brain_full”: The brain gets filled up. In other words, there is a preordained maximum number of words that the brain can hold. b) “Distracted”: The motivation to learn new words falls away - the child becomes more interested in other things. d) “Ability_fade”: The ability to learn new words falls away as the children age. One other possibility, which is not modelled, is that all the words in the language are finally acquired, but extremely unlikely, especially in English. A final variation seeks, in a small way, to model the tendency of individuals to cluster together in groups which are similar to one another. This is an on/off option called “Association?”. HOW TO USE IT For the basic model set the number of children to about 20 and the number of adults to about 70. Pick the option “As_others” and no “Association?” Click the SETUP button Click the Go button The model can be rerun with other options. THINGS TO NOTICE As the model runs you will be able to see the children and adults move around at random and the average vocabulary level of the children rise visually as well as on in a box showing a number. The vocabulary levels of the more able and less able children is also tracked. The lower chart shows a histogram of the children’s vocabulary levels and the standard deviation of the distribution is also indicated. If the model relates to reality the vocabulary levels should rise steadily and then level off. The more able children should experience more rapidly rising vocabulary levels than the less able children and they should rise for a longer period. When the Associate? option is on you should be able to see pairs of fiends moving around together for a while and then splitting up. THINGS TO TRY Try varying the numbers of children and the numbers of adults and watching the impact on vocabulary acquisition. Similarly try the various options that are available from “Level-off?” and “Association?”. Try to relate the results to real life. Are there parallels to be found in unusual contexts? For example when there are few adults for large numbers of children. WHAT NEXT A natural next stage is to run experiments which manipulate the available options. Taking vocabulary as the outcome the options trialled were: numbers of children, numbers of adults, the four “Level-off?” possibilities and “Association?”. These suggest that the numbers of Adults in the model is a key feature in the Children’s vocabulary acquisition but that all variables are significant (p<.05) and that most 2-way interactions are also statistically significant but not of great magnitude. With the patterns that emerge in mind, it would be interesting to: a) Alter the relative importance of “ability” in the code of the model to see how that changes the patterns that are seen. Perhaps there is an interaction between “ability” and some of the other variables. b) Set the initial levels of variables, in the code, so that vocabulary and ability are related to one another; a correlation of 0.7 would be realistic. Then see what patterns emerge. c) Change “association”, in the3 code, to see if associating greater numbers of children together makes any difference, or, if associating adults with children with similar relative vocabularies makes much difference. There are many possible further steps. One involves adjustments to the existing model and other involve serious changes. The adjustments could involve changes to the parameters so that the findings match reality more closely. For example, all models with large numbers should finish with the average child having the same vocabulary of the average adult. And the standard deviation of the children should match the standard deviation of the adults. Three major additions to the structure of the model, which can be expected to influence vocabulary levels, and which could be programmed, are: a) Homes, located at specific patches, for the children with parents. The children will tend to stay at home less and less as they age. b) The children go to school and, some of them, start reading books. At school they are specifically introduced to new vocabulary. Further, reading is well-known to increase vocabulary. c) The children and adults come from and, largely live in, areas of differing socio-economic status (SES). Whole areas could be designated Low SES, Mid SES and High SES. These would be characterised by systematic variation in; the density of homes, the speed of movement of people, the starting vocabulary levels and, perhaps, other variables. A further, more substantial, next step is to use actual data as the input and aim to simulate real life outcomes. This could be both in terms of the variables allocated to the children but also in the physical location of homes and schools.  |
| Reference URLs         | https://doctiktak.com/infant-contributions-to-joint-attention-predict-vocabulary-development.html https://experts.umn.edu/en/publications/early-vocabulary-growth-relation-to-language-input-and-gender https://www.isca-speech.org/archive/archive_papers/interspeech_2009/papers/i09_1727.pdf Diack, H. (1979). Test your own wordpower: your vocabulary and its measurement. Granada Publ.. https://www.superduperinc.com/handouts/pdf/149_VocabularyDevelopment.pdf  |
| Anticipated Outcomes   | See above.  |
| Requirements           | Some programming skills; and/or some visualisation skills; some basic (rule-based) and/or NN or GA etc. skills.  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | 	simulation; rule-based AI; AI;  |
### Theme AC-6: Bias in AI
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Artificial Intelligence is a thriving area in Computer Science. Especially trending is the sub-area of Machine Learning and Deep Learning, including Data Analytics. This Project specifically targets students interested in looking at all aspects of Bias in Artificial Intelligence. Bias can be introduced in many forms, from data to methods and algorithms, and it impacts negatively on people as well as research quality. It affects an increasing amount of areas, including sensitive ones, such as healthcare, law, criminal justice, hiring. An important task for researchers is to use AI to identify and reduce (human or machine) biases, as well as improve AI systems, to prevent introducing and perpetuating bias. Thus, this project is open to students willing to work on any aspects of Bias in AI: • from statistical/theoretical perspectives –where bias should be avoided with new algorithmic solutions, methodologically correct procedures (e.g., bias induced by overlapping training/test set, historically inaccurate time series, average accuracy results only in classification); sensitivity analysis (including k-anonymity, l-diversity, t-closeness, k-safety, k-confusability, t-plausibility) for structured/unstructured data, or ways of quantifying uncertainty in deep learning, e.g., via adversarial learning, generative models, invertible networks, meta-learning nets. • to human perspectives – where specific types of bias introduced by data or methodology can do harm, such as in implicit racial, ethnic, gender, ideological biases. The former perspectives are to produce correct or optimised results, the latter are to lead to conversational explanations and explainable AI, in view of GDPR and increasing ethical concerns, and the move from symbolic AI to sub-symbolic (deep) representations, with no direct answer to the classic AI questions of ‘Why’ and ‘How’. This includes the novel field of Machine Teaching, expanding on the classical field of knowledge extraction from (shallow or, more recently, deep) Neural Networks. This area should lead to novel insights into accountability of AI. |
| Reference URLs         | https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=bias+in+ai&btnG=  |
| Anticipated Outcomes   | Outcomes can include (any of): - interpretable AI systems - visualisation of AI reasoning - ethical issue detection  |
| Requirements           | understanding of data analytics; some experience with R and/or PyTorch, Keras; some potential visualisation experience.  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | bias in AI; data analytics; deep learning  |

## Staff Proposer: Stefan Dantchev
### Theme SSD-1: Machine Learning for Game Playing
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Reinforcement Learning (RL) is a machine-learning paradigm according to which an agent ought to take actions in an environment so as to maximize some notion of cumulative reward. When applied to games, a computer player gradually learns a good strategy by repeatedly playing against another player or against itself. For a number of games most notably Go, RL has produced not only the strongest AI players known up to now but also a player that can easily beat the best humans. The purpose of this project is to develop an RL algorithm for a game of the student\'s choice, to implement it, and to evaluate its competitiveness.  |
| Reference URLs         |  https://www.nature.com/articles/nature24270 https://arxiv.org/abs/1712.01815 |
| Anticipated Outcomes   | An implementation of one or more computer players for a game chosen by the student.  |
| Requirements           | Interest in Machine Learning.  |
| Max Number of Students | 4  |
| Project Type           | L3, L4  |
| Keywords               | Machine Learning, Reinforcement Learning, Neural Networks, Monte Carlo Tree Search, Alpha Go Zero, Deep Q Learning  |
### Theme SSD-2: Real-World Assignment Problem
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | This is a real assignment problem for a local charity, who provide a service for transporting cancer patients to their treatment. E.g. given ~ 40 volunteers, ~ 25 ambulances and ~ 60 patients per day, all distributed at points over the North East, what is a good allocation of resources? The challenge is to keep everyone happy - volunteers not driving too far, patients not having long journeys, and making good use of the ambulances. See the URL below for a detailed description.  |
| Reference URLs         | https://github.com/paulcc/daab-algorithm  |
| Anticipated Outcomes   |  User-friendly software that produces a good-quality solution. |
| Requirements           |  Interest in Combinatorial Optimisation and Heuristic Algorithms. |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               |  Combinatorial Optimisation, Assignment Problem, Heuristic Algorithms. |
### Theme SSD-3: Learning and Generating Graphs with Deep Neural Networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	Modelling and generating graphs is fundamental for studying networks in many areas of science and engineering. However, modelling complex distributions over graphs and being able to efficiently sample from them is challenging due to the high-dimensional nature of graphs and the non-local dependencies between edges. Recently, GraphRNN, a deep autoregressive model that addresses the above challenges and approximates any distribution of graphs with minimal assumptions about their structure, has been proposed. The main aim of this project is to implement (a modification of) the method and evaluate it on real-world data as well as on synthetic data.  |
| Reference URLs         | https://cs.stanford.edu/people/jure/pubs/graphrnn-icml18.pdf  |
| Anticipated Outcomes   | An implementation of (a modification of) the GraphRNN model.  |
| Requirements           | Interest in Machine Learning and Graph Theory.  |
| Max Number of Students |  3 |
| Project Type           | L3, L4  |
| Keywords               |  	Machine Learning, Graph Theory. |

## Staff Proposer: Yona Falinie
### Theme YF-1: Eye in the Sky: Drone-Based Object Detection and Localisation using Convolutional Neural Network
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Drones equipped with a single camera have been widely deployed to a broad range of applications, such as aerial photography, fast goods delivery and most importantly, surveillance. Consequently, automatic understanding of visual data collected from drones becomes highly demanding, involving recognizing the categories of objects in the scene, locating the objects and determining exact boundaries of each object, which brings computer vision to drones more and more closely. Over the past few years, with the rapid development of deep learning, the convolutional neural network (CNN) has proven to be successful in detecting objects. Many CNN-based detection frameworks are proposed and achieve state-of-the-art results on PASCAL VOC and COCO. However, most CNN detection frameworks a based on still images and directly utilizing these still image detectors on video objects remains a great challenge. To deal with these challenges, this project aims to design an object detection network where it can observe the ground at a certain altitude where obejcts (pedestrian, car, bicycle) need to be detected. Detecting objects from certain altitude is a considerably challenging given the fact that then objects may have higher degree of occlusions, low resolution and targets are considerbaly small and may contain few numbers of pixels. Therefore this project would leverage existing deep learning implementation on object detection such as Faster R-CNN and YoloV3 then identify a components underlying neural network architecture that would lead to new network variants for this task.  |
| Reference URLs         | YOLOv3: An Incremental Improvement (https://arxiv.org/pdf/1804.02767.pdf) Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (https://arxiv.org/abs/1506.01497) Vision Meets Drones: A Challenge (https://arxiv.org/abs/1804.07437)  |
| Anticipated Outcomes   | A working software demonstrator, open source contribution and technical evaluation of state of the art in object detection in aerial imagery using deep CNN architectures.  |
| Requirements           |  Students must have taken or be taking Image Processing, Computer Vision and ideally Machine Learning / Deep Learning and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the Linux operating system is of benefit. |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | computer vision, image processing, machine learning , deep learning, convolutional neural networks, object detection, object segmentation  |

## Staff Proposer: Tom Friedetzky
### Theme TF-1: Reversi/Othello or similar
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Reversi is a strategy board game for two players, played on an 8×8 uncheckered board. There are sixty-four identical game pieces called disks (often spelled discs), which are light on one side and dark on the other. Players take turns placing disks on the board with their assigned color facing up. During a play, any disks of the opponent\'s color that are in a straight line and bounded by the disk just placed and another disk of the current player\'s color are turned over to the current player\'s color. The object of the game is to have the majority of disks turned to display your color when the last playable empty square is filled. [https://en.wikipedia.org/wiki/Reversi].<br><br>The aim of this project is to design and implement a strong Reversi/Othello program using modern methods and principles from machine learning, AI, and generally (algorithmic) Computer Science. We may also consider variations of the standard board layout, or maybe even the rules.<br><br>Other, similar games can also be considered  |
| Reference URLs         |  https://skatgame.net/mburo/ps/compoth.pdf |
| Anticipated Outcomes   | A lean, mean Reversi-playing machine  |
| Requirements           | Ideally some knowledge of (or at least strong interest in) machine learning  |
| Max Number of Students | 3  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               | 	games, Reversi, Othello, machine learning  |
### Theme TF-2: PRAM simulator
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  A Parallel Random Access Machine, or PRAM for short, is a generalisation of von Neumann's Random Access Machine (RAM) model. A PRAM consists of a set of processors which can access a shared memory. The PRAM model is not very realistic in that actually implementing concurrent access to the shared memory is difficult, but it is used in the design and analysis as well as teaching of parallel computing as it allows for very elegant description of algorithmic ideas. The objective of this project is the design and implementation of a PRAM simulator. The system consists of two main parts: the PRAM language in which users will then write their parallel code, and the simulation engine as such. |
| Reference URLs         | https://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/classnotes.pdf https://www.cs.cmu.edu/~guyb/papers/BM04.pdf https://www.ida.liu.se/~chrke/fork95.html  |
| Anticipated Outcomes   |  A complete, working PRAM simulator |
| Requirements           | None  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | 	parallel programming, shared memory, simulation  |
### Theme TF-3: Photo editor
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  The purpose of this project is to design and implement a photo editor that supports a wide variety of image adjustments, e.g., exposure, contrast, colour and detail, graduated filtering, context-aware spot healing, noise reduction, haze removal, all in a modern, user-friendly GUI. The focus will very much be on algorithmic aspects of those operations, all of which will be implemented from scratch. |
| Reference URLs         | http://ip4ec.upf.edu/system/files/publications/DenoisingTIP.pdf http://www.ijcaonline.org/archives/volume141/number10/katiyar-2016-ijca-909827.pdf  |
| Anticipated Outcomes   | Development of a stand-alone photo editor  |
| Requirements           | Interest in algorithms, mathematics, photography and GUI programming  |
| Max Number of Students | 2  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |  	photo editing |
### Theme TF-4: Distributed black-box operations
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | There is a large number of primitive operations for distributed/parallel systems that run \"under the bonnet\" and are typically not visible to the user. Among those are routing or load balancing, but also less well-known black-box operations as leader election, majority, consensus, or (pseudo) synchronisation, which are primitives frequently being used by higher-level operations. Many of those operations are randomised. In this project the student will pick one of those areas, make themselves familiar with questions and flavours of methods, select relevant literature and implement a system simulating a selection of methods, verify statements made in the literature, and possibly improve on one or the other aspect of one or the other approach. Theoretical contributions will most definitely be an option.  |
| Reference URLs         |  https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.4186 https://homes.cs.washington.edu/~karlin/papers/balls.pdf http://dro.dur.ac.uk/27810/ https://www.cs.yale.edu/homes/aspnes/classes/465/notes.pdf |
| Anticipated Outcomes   | An implementation of an efficient simulation engine in C or C++ for one of the listed models. Possibly theoretical contributions.  |
| Requirements           | C/C++ programming, interest in distributed/parallel systems  |
| Max Number of Students | 5  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |  Distributed computing, load balancing, leader election, majority, consensus, synchronisation |
### Theme TF-5: Graph drawing in/for LaTeX
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  LaTeX is a programming language for producing high-quality typeset (usually) scientific documents. Many scientific papers and books contain diagrams of graphs, and while packages like TiKZ have made it much easier to (programmatically) produce those than was the case only a few years ago, the process is still more grunt work and requires more concentration than what should be strictly necessary (this is not even mentioning LaTeX's and in particular TiKZ's syntactical oddities, which are very much an acquired taste and take some getting used to). The objective of this project will be to provide a LaTeX package, likely building on TiKZ and possibly LUALaTeX extensions (or similar), that offers to the user (a) a library of predefined graph classes (trees, rings, grids, hypercubes etc) with flexible labelling schemes, and, as piece de resistance, a graph layout engine that ideally takes as input a list of a graph's vertices and edges and possibly labels thereof, or a programmatic description of a graph, and produces a pleasantly laid-out rendering of this graph. Graph drawing is an active research area, and therefore established as well as cutting-edge literature describing relevant methods will be available aplenty. |
| Reference URLs         | https://link.springer.com/chapter/10.1007/978-3-319-91908-9_6 https://kam.mff.cuni.cz/gd2019/  |
| Anticipated Outcomes   | A LaTeX package to support user-friendly drawing of graphs.  |
| Requirements           | Interest in algorithms. Familiarity with LaTeX and ideally TikZ.  |
| Max Number of Students | 2  |
| Project Type           |  L3, L4 |
| Keywords               |  	LaTeX, TikZ, graph drawing |

## Staff Proposer: Max Gadouleau
### <span style="color:red;">Theme MG-1: Simulation of Boolean Networks on GPUs</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | A Boolean network is a set of entities, each having a Boolean variable (state) and an update function which depends on the state of other entities on the network. Boolean networks have been used to model gene networks, neural networks, social interactions, etc. The purpose of this project is to produce a tool which allows for efficient simulation of these networks. Since Boolean entworks are made of many independent entities, it is very well suited for parallelisation. As such, the tool will take full advantage a GPU to simulate large networks. This will then lead to a theoretical study of the dynamics Boolean networks (fixed points, oscillations, etc.).  |
| Reference URLs         |  |
| Anticipated Outcomes   | A tool to efficiently simulate large Boolean networks and to identify some of their key dynamical fixed points, such as fixed points, attractors and their basins of attraction.   |
| Requirements           | Knowledge of GPU of parallel programming  |
| Max Number of Students | 2  |
| Project Type           | MISCADA, L4  |
| Keywords               | Boolean networks, gene networks, simulation, fixed points  |
### <span style="color:red;">Theme MG-2: The Shannon capacity of graphs</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The capacity of a channel is the maximal rate for which we can transmit information with error probability tending to zero. However, in some channels, such as the noisy typewriter, we can transmit some information with error probability EQUAL to zero. This leads to the definition of the zero-error capacity of a channel. We can represent a channel by a graph, where vertices are the symbols and two vertices are adjacent if the channel can confuse them. As such, we have a purely graph-theoretic quantity: the Shannon capacity of a graph. That is a very hard parameter to compute in general, so the main objective of this project is to come up with fast implementations of algorithms to compute bounds on that parameter.  |
| Reference URLs         | The book: Bondy and Murty, "Graph Theory" - The seminal paper: Lovász, László, "On the Shannon Capacity of a Graph", IEEE Transactions on Information Theory, IT-25 (1), 1979.  |
| Anticipated Outcomes   | An implementation and optimisation of existing algorithms to compute or approximate the Shannon capacity of graphs. A thorough investigation of specific classes of graphs, e.g. Paley graphs, for which new lower bounds are epxected to be computed.  |
| Requirements           | Recommended: Theoretical Computer Science III (Information Theory); Computing Methdologies (Linear and Integer Programming)  |
| Max Number of Students | 1  |
| Project Type           | MISCADA, L4  |
| Keywords               |  Shannon capacity, graph theory, zero-error capacity, independent set |
### <span style="color:red;">Theme MG-3: Entropy of graphs</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | How do you measure the complexity of a graph? A crude solution is to look at the degree distribution of the vertices, to view it as a probability distribution (after scaling), and to consider the entropy of the corresponding variable. Despite its simplicity, this technique allows to classify trees rather well. Since the inception of this technique, several extensions and modifications have been proposed. The aim of this project is to analyse those different graph entropy definitions, to obtain meaningfull results about them, and maybe to come up with new measures of the complexity of a graph that could be more meaningful or accurate.  |
| Reference URLs         | Matthias Dehmer, Abbe Mowshowitz, A history of graph entropy measures, Information Sciences 181, 2011. Matthias Dehmer, Information processing in complex networks: Graph entropy and information functionals, Applied Mathematics and Computation 201, 2008.  |
| Anticipated Outcomes   | A theoretical analysis of the entropy of graphs in general. Some results of maximisation/minimisation of the graph entropy for different classes of graphs. Optionally, a comparison of different definitions for the graph entropy and how they relate to each other.  |
| Requirements           |  Basic knowledge of graphs and entropy |
| Max Number of Students | 1  |
| Project Type           | MISCADA, L4  |
| Keywords               |   |
### Theme MG-4: Hat games
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Winkler's hat game is a cooperative game played by a team of n players. Each player has a hat on their head; each hat can take q possible colours. They do not know their own hat's colour but can see some other hats (this can be easily modelled using a directed graph). All the players must take a guess at their own hat colour; the team wins if at least one player guesses correctly. A winning strategy is a deterministic strategy which ensures that the team always wins, regardless of the distribution of hat colours. For instance, if the graph is the clique on n vertices, there is a winning strategy if and only if n >= q (you can check!). The main question is to determine, given a directed graph on n vertices and the number q of colours, whether there is a winning strategy for that graph and that many colours. The purpose of this project is to develop a tool which allows to search for winning strategies or to analyse theoretically some specific classes of graphs.  |
| Reference URLs         | M. Gadouleau and N. Georgiou, "New constructions and bounds for Winkler's hat game," SIAM Journal on Discrete Mathematics, 2015. S. Riis, "Information flows, graphs and their guessing numbers" Electronic Journal of Combinatorics, 2006.  |
| Anticipated Outcomes   |  A software tool which allows to search for winning strategies or to analyse theoretically some specific classes of graphs. |
| Requirements           |  Basic understanding of graph theory. Understanding of Linear Programming and Integer Programming is a plus. |
| Max Number of Students | 2  |
| Project Type           | L3  |
| Keywords               |   |
### <span style="color:red;">Theme MG-5: Linear Programming Complementation</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | LP complementation is another duality for linear programmes that was recently discovered. The main aim of this open-ended project is to investigate different aspects of LP complementation. In particular, serching whether using complementation can improve the efficiency of known LP algorithms of the accuracy of solving IP by LP relaxation is very important.  |
| Reference URLs         | Maximilien Gadouleau, George B. Mertzios, and Viktor Zamaraev, "Linear Programming complementation and its application to fractional graph theory," preprint available on arxiv.org  |
| Anticipated Outcomes   | An experimental analysis of the computational performance of LP complementation.  |
| Requirements           | Understanding of Linear Programming and Integer Programming  |
| Max Number of Students |  2 |
| Project Type           | MISCADA, L4  |
| Keywords               |   |

## Staff Proposer: Suncica Hadzidedic
### <span style="color:red;">Theme SH-1: Deep learning in recommender systems</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Recommender systems (RS) assist web users filter through the staggering amount of online information. These are tools (algorithms, techniques) that combine machine learning, business and human-computer interaction fields to understand user preferences (at individual or group level) and produce recommendations of items that best match those preferences. Deep learning (DL) has gained significant attention in different fields due to its successful application. It employs neural architectures to learn ‘deep’ representations from data. Research on DL application to RSs has been, as of recently, thriving, however, there are still multiple open questions. The goal of this project would be to explore the use of deep learning in recommender systems (in a selected domain), as a technique for learning/representing features (e.g. latent contexts) or as a recommendation model; and furthermore, analyse and evaluate the performance of this technique in comparison to the traditionally used ones.  |
| Reference URLs         | https://dl.acm.org/doi/pdf/10.1145/3285029; https://www.sciencedirect.com/science/article/pii/S0950705116300727  |
| Anticipated Outcomes   | 	Implementation of a Deep Learning-based Recommender System; Evaluation against alternative algorithms  |
| Requirements           | recommender systems, machine learning, deep learning, programming skills  |
| Max Number of Students | 5  |
| Project Type           |  L4 |
| Keywords               |  recommender systems, deep learning, deep neural networks, machine learning |
### Theme SH-2: Affect- and personality-aware recommender systems
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Recommender systems (RS) assist web users filter through the staggering amount of online information. These are tools (algorithms, techniques) that combine machine learning, business and human-computer interaction fields to understand user preferences (at individual or group level) and produce recommendations of items that best match those preferences. Context-aware RS (CARS) aim to grasp a holistic picture of a user’s condition (internal and external), in modelling her/his preferences and in using the contextual information to influence the resulting recommendations. Research has shown that expanding user profiles, beyond behaviour, with psychological models – such as emotions and/or personality, improves RS performance. This project should, hence, aim to: - Identify and evaluate tools/methods for acquiring affect and/or personality; - Implement an affect-aware, or personality-aware, or an affect- and personality-aware recommender system in one of the following domains: education, healthcare, music, fashion, job ads/seeking, technical consumer goods; - Analyse and evaluate the performance of this technique in comparison to alternative approaches (e.g., traditional 2D recommender without contextual factors)  |
| Reference URLs         | https://link.springer.com/chapter/10.1007/978-0-387-85820-3_7; https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374807; https://link.springer.com/chapter/10.1007/978-1-4939-0530-0_6; https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7904698  |
| Anticipated Outcomes   | Evaluation and selection of tools for affect/personality acquisition; Implementation of affect-/personality-aware RS; Evaluation against alternative algorithms  |
| Requirements           | recommender systems, machine learning  |
| Max Number of Students | 4  |
| Project Type           |  L3, L4 |
| Keywords               |  recommender systems, context-aware recommender systems, machine learning, emotions, personality, affective computing |
### Theme SH-3: Affective Human-Computer Interaction
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Human-computer interaction (HCI) links computer science, design, and cognitive/behavioural sciences to explore people’s use of computing devices and approaches to improving the usefulness and usability of those devices for human users. Advances in fields such as machine learning, computer vision, psychology, have led to numerous new developments in HCI methods and applications, including affective HCI, thus bridging the gap between humans and technology. The goal of this project is to explore machine learning techniques for automatic intelligent agent adaptation, based on changes in a user’s affective state. Agent adaptation can be reflected, e.g., via user interface (colour pallet, button shapes, navigation style, etc.), intelligent multimodal feedback, etc. Affect acquisition and recognition should be explored via multimodal methods (i.e., combining e.g. heart rate, body movement and facial expressions). The intelligent agent should be applied to the domain of education (e.g., learning platform) or health (e.g., mental health application), and evaluated for usability and other HCI metrics via a user study.  |
| Reference URLs         |  https://dl.acm.org/doi/pdf/10.1145/641007.641038; https://www.sciencedirect.com/science/article/pii/S1071581903000478 |
| Anticipated Outcomes   | Intelligent affect-adaptive agent for education or health; Multimodal affect recognition method; Evaluation results of an HCI user-based study  |
| Requirements           | Machine learning, computer vision  |
| Max Number of Students |  4 |
| Project Type           | L3, L4  |
| Keywords               |  Human computer interaction, affect, adaptation, adaptive agents, user interface design, usability testing, multimodal emotion recognition |
### <span style="color:red;">Theme SH-4: Explainability in Recommender Systems</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | AI-related ethical concerns have, as of recently, frequently been in the headlines. Some effort from governments (e.g. GDPR) and companies (e.g., Google) has been directed to addressing this issue, however, research on explainability and bias in AI is lacking. Recommender systems (RS) assist web users filter through the staggering amount of online information. These are tools aim to understand user preferences and produce recommendations of items that best match those preferences. However, due to the increasing complexity of algorithms and data sources, there is a need for transparency as to why a specific item is recommended to a user. Explainable recommendations increase system’s scrutability and users’ trust and decision-making ability. Therefore, the goal of this project is to: - Explore and implement methods based on deep- or reinforcement-learning for explainable recommendations in a selected domain (with publicly available datasets); - Employ user ratings and reviews as a source for explanations; - Experiment with different approaches to presenting explanations to users (e.g., format/media of presentation, explanation styles, presenting and explaining the user model/profile to the user, etc.); - Perform offline experiment to evaluate the implemented algorithms against alternative approaches (e.g. kNN collaborative filtering or rule-based methods); - Carry out a user study to evaluate the explanations (on usefulness, trust, user preference).  |
| Reference URLs         | https://ieeexplore.ieee.org/abstract/document/8594883;<br> https://dl.acm.org/doi/abs/10.1145/3331184.3331211;<br> https://www.researchgate.net/profile/Behnoush_Abdollahi/publication/301616080_Explainable_Matrix_Factorization_for_Collaborative_Filtering/links/59e0de0e0f7e9b97fbddb945/Explainable-Matrix-Factorization-for-Collaborative-Filtering.pdf;<br> https://dl.acm.org/doi/abs/10.1145/3301275.3302306;<br> http://www.cs.jhu.edu/~taochen/data/pubs/cikm15.pdf; <br>https://www.cs.cmu.edu/~glai1/papers/yongfeng-guokun-sigir14.pdf  |
| Anticipated Outcomes   | Recommender system with explainable recommendations; Evaluation results from an offline experiment and user study  |
| Requirements           | recommender systems, machine learning, deep learning, AI  |
| Max Number of Students | 4  |
| Project Type           | L4  |
| Keywords               | Explainable recommendations, explainability in AI, recommender systems, machine learning, deep learning, AI  |
### Theme SH-5: Authentication methods for people with disabilities
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Authentication is the process or action of verifying the identity of a user, via something they know, have or are (e.g., via textual passwords). While most of us use different authentication methods to access our computing devices or services on the Internet without much effort, for people with disabilities this can be a difficult task due to no or poor design considerations for this type of users in the conventional security and privacy approaches. Inclusive technology, on the other hand, addresses the wide-range of needs, values, abilities, characteristics its users can have. The goal of this project is to: - Explore authentication methods for online services or mobile devices tailored to people with disabilities (specifically focusing on those with dyslexia, visual impairment, or upper extremity disabilities); - Develop and evaluate inclusive authentication software and/or hardware, within a specific context, targeting people with a specific type of a disability.  |
| Reference URLs         | https://www.bedicon.org/wp-content/uploads/2018/01/laws_topic4_source1.pdf; http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.697.3724&rep=rep1&type=pdf#page=99; https://www.bedicon.org/wp-content/uploads/2018/01/laws_topic4_source1.pdf; https://dl.acm.org/doi/abs/10.1145/3234695.3236342; https://ieeexplore.ieee.org/abstract/document/6329201; https://ieeexplore.ieee.org/abstract/document/8425612; http://www.gierad.com/assets/thumprint/thumprint.pdf  |
| Anticipated Outcomes   | Implementation and evaluation of an authentication method for people with disabilities  |
| Requirements           | 	cyber security  |
| Max Number of Students | 3  |
| Project Type           |  L3 |
| Keywords               | Authentication methods, security, privacy, people with disability  |

## Staff Proposer: Leonardo Impett
### <span style="color:red;">Theme LI-1: Cross-Depiction Image Matching</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In computer vision, most tasks (matching images, recognizing objects) tend to be performed on photographs of the natural world. What happens when we try to match depictions of everyday objects, from drawings or art? What happens when we try to match between a photo and drawing of the same object, or two artworks of the same building? This project will use a new dataset (prepared by the supervisor) to implement some existing algorithms for cross-depiction matching/recognition, and attempt to find new ones. Alongside that, this project may attempt to define new error metrics for cross-depiction tasks, if the error metrics used in traditional computer vision prove insufficient.  |
| Reference URLs         |  Google Quickdraw Dataset on Github, https://github.com/googlecreativelab/quickdraw-dataset<br>Cai et al, “The Cross-Depiction Problem: Computer Vision Algorithms for Recognising Objects in Artwork and in Photographs”, https://arxiv.org/abs/1505.00110<br>Shen et al, “Discovering Visual Patterns in Art Collections with Spatially-consistent Feature Learning”, http://imagine.enpc.fr/~shenx/ArtMiner/ |
| Anticipated Outcomes   | The reimplementation of 2-4 existing approaches for cross-depiction matching, in the same framework; an experimental comparison and analysis of their different advantages and dynamics; an implementation of several error metrics for these approaches on a reference dataset  |
| Requirements           | An interest in computer vision or image processing.  |
| Max Number of Students | 2  |
| Project Type           | L4  |
| Keywords               | 	Deep learning, art, painting, drawing  |
### Theme LI-2: Detecting Emotions in Paintings
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In the 1660s, Charles Le Brun gave an important lecture on the depiction of human facial expressions, and how they changed according to emotions. Le Brun’s lecture was accompanied by a set of images, and these images became enormously popular references for artists for the next two hundred years. They reappear in thousands of paintings (maybe more) - but nobody knows exactly how many, where and when, and which emotions were most popular. In the last few years, computer vision has powered tools like OpenFace that can recognize human emotions very precisely from photographs - not just as “happy” or “sad”, but following a precise scientific description, based on the Facial Action Coding System. This project will adapt facial emotion recognition code (e.g. OpenFace) to work on paintings and drawings, harvest emotion data from a dataset of hundreds of thousands of paintings, and show how Le Brun’s expressions moved through space and time.  |
| Reference URLs         | Charles le Brun’s Science of Human Expressions, https://historycollections.blogs.sas.ac.uk/2016/10/27/charles-le-bruns-science-of-human-expression-its-all-in-the-eyebrows-hope-and-fear-at-the-warburg/<br>Le Brun’s Passions at the Metropolitan Museum, https://www.metmuseum.org/art/collection/search/376816<br>Facial Action Coding System, part of the OpenFace Github wiki, https://github.com/TadasBaltrusaitis/OpenFace/wiki/Action-Units<br>Jackson et al, “Style Augmentation”, https://arxiv.org/abs/1809.05375  |
| Anticipated Outcomes   | A modification of OpenFace to make it more flexible to working on visual art, and a spatial and temporal analysis of the spread of specific facial expressions through a dataset of paintings.  |
| Requirements           | 	An interest in computer vision or computer graphics, and perhaps in visual art.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | 	Facial emotions, art, painting, drawing, computer vision  |
### Theme LI-3: Social Media and Culture during COVID lockdown
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In the past few months, people from Beijing to Bradford have had to spend much more time indoors, and much less time in museums. At the same time, museums and galleries have tried especially hard to keep in contact with their public: opening up their digitized material, creating new “online exhibitions”, or just being much more active on Twitter. Understanding the “big data” of how people across the UK (and the world) interact with museums virtually, especially over the past few months, is key for museums and governments alike. This project will use a combination of image matching, sentiment analysis/text mining, and social media analysis to understand the different clusters of users interacting with museums, the kinds of content they interact with, and how different strategies have evolved through time.  |
| Reference URLs         | Twitter’s API for academic uses: https://developer.twitter.com/en/use-cases/academic-researchers/helpful-tools<br>Lev Manovich, Selfiecity: http://selfiecity.net/<br>Intro to (social) network analysis: https://www.datacamp.com/community/tutorials/social-network-analysis-python  |
| Anticipated Outcomes   | A rough-and-ready implementation of simple image matching (feature-based matching for twitter photographs and museum objects) and text mining (sentiment analysis and Named Entity Recognition), followed by a more advanced social media analysis (i.e. network analysis) of the resulting data.  |
| Requirements           | Some prior knowledge of basic NLP or graph theory would be an advantage.  |
| Max Number of Students |  1 |
| Project Type           |  L3 |
| Keywords               |  Social media analytics, text mining, image matching, sentiment analysis, museums |

## Staff Proposer: Khalid Ismail
### Theme KI-1: Investigating the End-to-End Performance of Recent Advances in Deep Learning Visual Odometry Approaches
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Next generation driver-less vehicles (i.e. autonomous cars and/or robots) require accurate odometry for on-road localisation beyond the accuracy available from current GPS systems, wheel odometers and within scenarios of limited GPS coverage (both current/future GPS systems – e.g. built up environments, tree coverage, tunnels etc). Current developments within the field use a combination of visual odometry integrated with inertial measurement unit (IMU) and any available GPS information. Visual odometry can be based upon either monocular (1 camera) or stereo (2 camera) based sensing and traditionally follows a feature-driven approach - a range of algorithms have been developed for real-time visual odometry (e.g. libvisio2, ORB-SLAM2, LSD-SLAM and many others). More recently a number of approaches have emerged that alternatively use an end-to-end deep learning approach for this problem. Some of these approaches simultaneously recover depth information from the scene (see examples below), related work also exists in the recovery of Structure from Motion via deep learning (as part of the growing area of geometric deep learning) This project would look to implement one or more these approaches, leveraging existing open source implementations and libraries, over multiple common reference datasets gathered both locally to Durham and available as international research benchmarks to explore both performance and experimental variations within the underlying neural network architectures in use. Ideally, this would then identify a range of common components or structures which would lead to new network variants for this task that offer superior performance in terms of either improved accuracy, reduced complexity or both. Evaluation could be carried out based on sensor mounting on the department mobile robot platforms or potentially on our new on-road sensor vehicle platform.  |
| Reference URLs         | https://senwang.gitlab.io/DeepVO/ https://arxiv.org/abs/1709.06841 https://arxiv.org/abs/1802.02209 https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/ https://pdfs.semanticscholar.org/3eb6/28c163458f5a2ba7202cec0e6128665dc30a.pdf https://arxiv.org/abs/1802.05522 http://ieeexplore.ieee.org/document/8100079/ http://ieeexplore.ieee.org/document/8100178/  |
| Anticipated Outcomes   | a working software demonstrator and technical evaluation of the state of the art in deep learning based visual odometry approaches leading to insights into overall performance vs. network complexity with potential to extend to publishable novel contributions in this research area.  |
| Requirements           | Students must have taken or be taking Image Processing / Data Science (L2), Computer Vision (L3 + L4 as appropriate) and ideally Machine Learning / Deep Learning (L3/L4) and be comfortable with (or able to readily pickup) python and/or C++ to be able to leverage existing implementations. A familiarity with OpenCV, a strong numerical background, familarity with 3D geometry and the linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           |  L3, L4 |
| Keywords               | computer vision, image processing, machine learning, deep learning, visual odometry, geometry, driver-less vehicles  |
### Theme KI-2: Real Time Scene Understanding to Support Human-like Guidance
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In recent years, self-driving cars have been a hot topic for industrial companies and research communities. A crucial aspect of autonomous driving is to acquire a comprehensive understanding of the surroundings in which the car is moving. This includes the recognition of various objects such as other cars, pedestrians, traffic signs, buildings, etc. Along with object recognition on the scene, it is important to identify the attributes of the detected objects, such as type, colour and size, to support a human-like guidance application. Although many approaches have been developed to address the scene understanding problem, using a number of approaches, few have addressed understanding the scene whilst including attributes of the objects. The aim of this project is to develop a single Deep Neural Network (DNN) for the automatic detection of a range of street scene objects. The project is also aiming to include the automatic determination of object attributes for a range of detected street scene objects using the same model.  |
| Reference URLs         |  https://arxiv.org/pdf/1506.01497 http://community.dur.ac.uk/toby.breckon/publications/papers/akcay16transfer.pdf http://community.dur.ac.uk/toby.breckon/publications/papers/holder16offroad.pdf |
| Anticipated Outcomes   | a working software demonstrator and technical evaluation of state of the art in scene understanding to support human-like guidance.  |
| Requirements           | Students must have taken or be taking Image Processing / Data Science (L2), Computer Vision (L3 + L4 as appropriate) and ideally Machine Learning / Deep Learning (L3/L4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | computer vision, image processing, machine learning , convolutional neural networks, deep learning  |
### Theme KI-3: 3D Object Detection for Autonomous Driving
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In recent years, autonomous driving has been a focus of attention of both industry as well as the research community. 3D object detection plays an important role in the visual perception system of Autonomous driving cars. Modern self-driving cars are commonly equipped with various devices, such as LiDAR and cameras. The fusion and integration of LIDAR point cloud and RGB images should be able to achieve higher performance to self-driving cars. The focus of this project is on 3D object detection utilising both LiDAR and RGB image data. The aim of the project is to achieve highly accurate 3D localisation and detection of objects within the road scene.  |
| Reference URLs         | http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Multi-View_Harmonized_Bilinear_CVPR_2018_paper.pdf https://arxiv.org/pdf/1506.01497 https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Chen_Monocular_3D_Object_CVPR_2016_paper.pdf http://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_Frustum_PointNets_for_CVPR_2018_paper.pdf http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Multi-Level_Fusion_Based_CVPR_2018_paper.pdf  |
| Anticipated Outcomes   | a working software demonstrator and technical evaluation of state of the art in 3D object detection using LiDAR and image data  |
| Requirements           | Students must have taken or be taking Image Processing / Data Science (L2), Computer Vision (L3 + L4 as appropriate) and ideally Machine Learning / Deep Learning (L3/L4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the linux operating system is of benefit.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | computer vision, image processing, machine learning , convolutional neural networks, deep learning
  |
### Theme KI-4: End-to-end Region-based Convolutional Neural Network (R-CNN) architecture for Small object detection
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Recent advances in efficient object detection architectures have played an important role within the rapid development of autonomous driving technologies. With the development of deep convolutional neural networks (CNN), real-time object detection has become both robust and real-time. The region based CNN (R-CNN) and it\'s later versions Fast(er)-RCNN marked initial attempts at applying deep learning approaches to the joint task of both object detection and classification achieving significant performance improvement on benchmarks comparing to the traditional hand-crafted features based methods. However, Region based CNN methods such as Faster RCNN suffers from weak performance on small object instances recognition. This project aims to investigate how to improve Faster RCNN performance on small object detection for real time applications.  |
| Reference URLs         | https://arxiv.org/pdf/1506.01497 https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8019550 http://bmvc2018.org/contents/papers/0897.pdf https://arxiv.org/pdf/1808.02246.pdf  |
| Anticipated Outcomes   | a working software demonstrator and technical performance evaluation of a modified version of faster RCNN end to end network for better small object detection.  |
| Requirements           | 	Students must have taken or be taking Image Processing / Data Science (L2), Computer Vision (L3 + L4 as appropriate) and ideally Machine Learning / Deep Learning (L3/L4) and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the linux operating system is of benefit.  |
| Max Number of Students |  1 |
| Project Type           |  L3, L4 |
| Keywords               | 	computer vision, image processing, machine learning , convolutional neural networks, deep learning  |

## Staff Proposer: Matthew Johnson
### Theme MJ-1: Using Network Science for Authorship Attribution
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The problem of attributing authorship to a piece of text has several applications particularly in detecting plagiarism or other fraudulent acts. There are many techniques used; one of these is to use the text to build a graph where the words of the text form the vertices and the edges represent how often pairs of words are adjacent (or at least close to one another) and it is claimed that looking at the structure of this graph is sufficient to determine authorship. Looking at the structure might mean looking at, for example, the distribution of the degrees of the vertices or at "clustering coefficients". The aim of this project is to test this idea and to refine our understanding of the aspects of the graphs' structure most useful in applying this technique.  |
| Reference URLs         | https://arxiv.org/pdf/1705.04187.pdf  |
| Anticipated Outcomes   | Successful implementation and evaluation of a piece of a piece of software.  |
| Requirements           |  Completion of Theory of Computation, enjoyment of the graph algorithms part. The Modelling with Graphs capsule in Computational Thinking gives a good idea of the flavour of the work to be done. |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | 	graphs, networks, authorship attribution, word semantics, similarity measures  |
### Theme MJ-2: Managing Large Network Datasets
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Large networks arise in many computer science applications and their size leads to many computational and data-analysis challenges. "Sparsification" is the name given to operations that aim to reduce the size of the networks by removing many links whilst maintaining important structural properties. In fact, most work to date has concentrated on preserving a limited range of properties --- the aim of the project would be to broaden this range and it would involve examining existing techniques, developing and implementing new graph algorithms and evaluating them on real world networks. |
| Reference URLs         |  https://arxiv.org/pdf/1701.07221.pdf |
| Anticipated Outcomes   | Successful implementation and evaluation of existing and new techniques  |
| Requirements           | Success and enjoyment of graph algorithms within Theory of Computation and the Modelling with Graphs capsule of Computational Thinking would indicate that you would do well at this project.  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | networks, graphs, algorithms  |
### Theme MJ-3: Investigating the structure of solutions to problems
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | For many optimization problems, it is possible to define a graph that represents solutions (or possible solutions) and relationships amongst them. For example, for the Travelling Salesman Problem a potential solution is just an ordered list of the cities. We can define a graph that contains all solutions of length below some threshold value as vertices, and say that two solutions are adjacent if they are the same except that the order in which some pair of cities is reversed. The structure of such "solution graphs" can provide insight into the algorithmic complexity of optimization problems. Projects in this theme would choose an optimization problem and investigate its solution graphs.  |
| Reference URLs         | http://arxiv.org/abs/1312.2816  |
| Anticipated Outcomes   | New theorems on structure of solution graphs for some previously unanalysed problems. It might also be necessary to write code to investigate the structure of the graphs for small examples  |
| Requirements           | This project requires a good understanding of the kind of graph theory covered in the algorithms part of Theory of Computation  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | graphs, algorithms, optimization  |
### Theme MJ-4: How Good are Models of Networks?
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Network structures are at the heart of many complex systems used in the study of, for example, the spread of epidemic diseases, the algorithms of search engines and the biology of the cell. Research on networks often uses models because of the limited availability, and difficulty in analysing, real datasets. When using a model it is necessary to ask: do the networks obtained have the same properties as real data. The properties that might be looked at include, for example, the amount of connectivity, the "distance" between nodes, the distribution of links. This project will extend this work with a focus on asking, for models and datasets, whether or not "important" nodes are clustered together in networks (where important might mean having many links to other nodes, or being a node that sees a high volume of traffic in the network). The project will involve setting up and analysing existing network models and comparing their structure with that of real world data, and then proposing and evaluating improvements. |
| Reference URLs         | https://academic.oup.com/comjnl/article-abstract/62/9/1247/5112948 above available at https://tinyurl.com/qp5s532 http://networksciencebook.com/  |
| Anticipated Outcomes   | Better understanding of existing models. Design of improved models.  |
| Requirements           | Completed module on graph algorithms in Computational Thinking  |
| Max Number of Students |  3 |
| Project Type           | L3, L4  |
| Keywords               | graph theory, network analysis, algorithms  |
### Theme MJ-5: Finding communities in networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The structure of large networks (eg the web, an online social network) is often better understood using the mesoscopic concept of a community, a part of the network that is internally highly connected but only weakly connected to the rest of the network (eg webpages on the same topic, groups of mutual friends). There is a considerable research literature on the problem of identifying communities within networks but most of it assumes that networks are static -- in practice, many networks are highly dynamic with nodes and links being created and destroyed. This project will look at some recent work to develop a piece of software that will find communities in dynamic networks and evaluate whether proposed algorithms perform well and explore possible improvements.  |
| Reference URLs         | https://arxiv.org/abs/1709.08350 https://arxiv.org/pdf/1911.02780.pdf https://arxiv.org/pdf/1908.04901.pdf  |
| Anticipated Outcomes   | Program to analyse community detection algorithms Improved algorithms  |
| Requirements           | Completion of graph algorithms module of Computational Thinking  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | graphs, networks, community detection, python, networkx  |

## Staff Proposer: Stamos Katsigiannis
### Theme SK-1: Machine learning-based perceptually sound full-reference video quality assessment
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | It is well established in the literature that objective video quality assessment metrics do not align well with video quality as perceived by human viewers. To this day, the best way to acquire perceptually accurate video quality ratings is to conduct subjective experiments with the participation of human viewers and calculate mean opinion scores (MOS). However, this approach is costly and time-consuming and thus cannot be employed for large collections of video sequences. In this project, a new full-reference video quality assessment metric will be created by combining various objective quality metrics and mapping them to MOS ratings using machine learning.  |
| Reference URLs         | https://netflixtechblog.com/toward-a-practical-perceptual-video-quality-metric-653f208b9652<br>https://netflixtechblog.com/vmaf-the-journey-continues-44b51ee9ed12<br>https://doi.org/10.1007/s11042-017-4848-x<br>https://doi.org/10.1017/ATSIP.2019.16<br>https://doi.org/10.1109/TIP.2010.2042111<br>https://doi.org/10.1109/TBC.2011.2104671  |
| Anticipated Outcomes   | A piece of software that takes as input an original video sequence and a distorted version of the same sequence and computes an approximation of the mean opinion score provided by human viewers.  |
| Requirements           |  Interest in computer vision and image processing, basic knowledge of machine learning, knowledge of Python or Matlab |
| Max Number of Students | 2 |
| Project Type           |  L3, L4 |
| Keywords               |  	Full-Reference video quality assessment, FR VQA, machine learning, computer vision |
### Theme SK-2: Machine learning-based perceptually sound no-reference video quality assessment
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | It is well established in the literature that objective video quality assessment metrics do not align well with video quality as perceived by human viewers. To this day, the best way to acquire perceptually accurate video quality ratings is to conduct subjective experiments with the participation of human viewers and calculate mean opinion scores (MOS). However, this approach is costly and time-consuming and thus cannot be employed for large collections of video sequences. Furthermore, widely used objective or subjective video quality metrics require both the original undistorted version of a video sequence, as well as the distorted version in order to compute the quality score (Full-Reference metrics). There are many user-scenarios that the original version does not exist or is unavailable. Consequently, there is a lot of interest in creating perceptually sound no-reference video quality assessment metrics. In this project, a new no-reference video quality assessment metric will be created by combining various elementary quality metrics and mapping them to MOS ratings using machine learning.  |
| Reference URLs         | https://netflixtechblog.com/toward-a-practical-perceptual-video-quality-metric-653f208b9652<br>https://netflixtechblog.com/vmaf-the-journey-continues-44b51ee9ed12<br>https://doi.org/10.1007/s11042-017-4848-x<br>https://doi.org/10.1017/ATSIP.2019.16<br>https://doi.org/10.1109/TIP.2010.2042111<br>https://doi.org/10.1109/TBC.2011.2104671  |
| Anticipated Outcomes   | A piece of software that takes as input a video sequence and computes an approximation of the mean opinion score provided by human viewers.  |
| Requirements           | Interest in computer vision and image processing, basic knowledge of machine learning, knowledge of Python or Matlab  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | No-Reference video quality assessment, NR VQA, machine learning, computer vision  |
### Theme SK-3: Detection of COVID-19 cases from chest radiography images
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The global COVID-19 pandemic showed the importance of rapid low-cost diagnosis of COVID-19 cases. In this project, chest x-rays associated with COVID-19 cases and with healthy individuals will be used to train machine learning models for the task of classifying between COVID-19 and healthy cases.  |
| Reference URLs         | https://pjreddie.com/media/files/papers/YOLOv3.pdf<br>https://arxiv.org/pdf/2004.10934<br>https://arxiv.org/pdf/2004.12823<br>https://github.com/dogydev/COVID-Efficientnet-Pytorch<br>https://dx.doi.org/10.1016%2Fj.compbiomed.2020.103792<br>https://towardsdatascience.com/investigation-of-explainable-predictions-of-covid-19-infection-from-chest-x-rays-with-machine-cb370f46af1d  |
| Anticipated Outcomes   | A piece of software that given a chest x-ray image as input will detect if it can be associated with COVID-19  |
| Requirements           | Interest in computer vision and image processing, basic knowledge of machine learning, knowledge of Python or Matlab  |
| Max Number of Students | 2 |
| Project Type           | L3, L4  |
| Keywords               |  Computer vision, image processing, machine learning, CNNs |

## Staff Proposer: George Koulieris
### <span style="color:red;">Theme GK-1: Automatic Projector Calibration</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Setting up a projector takes time, as geometric distortions often appear and/or the image quality is degraded due to lighting conditions. Moving the projector around to correct for geometric distortions and/or fiddling with its geometry/brightness/contrast controls can be very laborious. Ideally, the user would like to aim the projector at the projection surface, define the desired display corners, and then an automatic method should align the display to the surface. In this project, a camera-projector pair and computer vision will be used to calibrate the projector automatically by appropriately pre-distorting the image content to account for perspective projection, lighting conditions and the material properties of the projection surface.  |
| Reference URLs         | https://ieeexplore.ieee.org/abstract/document/6375029 https://ieeexplore.ieee.org/abstract/document/1565423  |
| Anticipated Outcomes   | A piece of software that can pre-correct images/slides for arbitrary projection surface geometries and environmental lighting conditions using a projector-camera pair.  |
| Requirements           | Interest in Computer Vision and Computer Graphics.  |
| Max Number of Students |  2 |
| Project Type           | L4  |
| Keywords               | 	Camera/Projector calibration, Homographies  |
### Theme GK-2: Real-time 6-DoF Pose Estimation using a Single RGB Camera
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  	Tracking the user's body pose in VR is critical for immersive interaction with virtual worlds. Full body tracking in particular is still either unavailable in most commercial headsets or very expensive, requiring specialised external hardware. In this project we will use a cheap RGB camera to track the user's body and estimate its pose. |
| Reference URLs         | https://arxiv.org/pdf/1312.4659.pdf  |
| Anticipated Outcomes   | An interactive demo that tracks the user\'s body and then estimates the body pose using a cheap webcam.  |
| Requirements           | 	Interest in Computer Vision and Computer Graphics.  |
| Max Number of Students | 3  |
| Project Type           |  L3, L4 |
| Keywords               | Human-centred computing, Interaction devices, Graphics input devices, Pointing devices, Gestural input  |
### Theme GK-3: Wearable Haptics
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Haptic feedback for VR headsets is currently unavailable for commercial headsets. In this project we will develop a device that induces haptic feedback, i.e., the sense of force/touch and temperature among others. The device will be based on a custom-designed 3D printed frame with embedded Peltier elements to induce a thermal sensation and motors/voicecoils for vibrations. |
| Reference URLs         | https://dl.acm.org/doi/10.1145/3275476.3275488 https://ieeexplore.ieee.org/abstract/document/7463168  |
| Anticipated Outcomes   | A piece of hardware and an accompanying demo application in Unity 3D.  |
| Requirements           | 	An interest in Computer Graphics and Human Computer Interaction.  |
| Max Number of Students | 3  |
| Project Type           | L3  |
| Keywords               |  Human-centred computing, Haptic devices |
### Theme GK-4: Enhancing Dark Video Features via Inverse Tone Mapping
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Inverse tone mapping operators strive to re-generate a High Dynamic Range (HDR) image from a single Low Dynamic Range (LDR) input image. These operators intelligently boost luminance in the bright parts of the scene in an attempt to "stretch" the LDR image luminance range for it to match to the output luminance range of a HDR display. However, these operators do not perform equally well in the -also suppressed- darker regions of LDR images, where block artefacts often appear and camera noise gets significantly amplified. A "dark-area" enhancement function would optimally suppress both noise and quantisation artefacts while boosting those dark features in a temporally coherent way. The clipped luminance values in the lower part of the luminance range could be estimated based on notions from image statistics. The theoretical framework could also get inspiration from Laplacian Pyramids and Bilateral Filtering for image processing, or Median Cuts for dark area estimation.  |
| Reference URLs         | https://forums.cs.tau.ac.il/~hezy/Vision%20Seminar/pyramid83.pdf https://dl.acm.org/doi/10.1145/1186954.1187029 https://ieeexplore.ieee.org/abstract/document/710815  |
| Anticipated Outcomes   | In this project a theoretical foundation for an inverse tone mapping operator will be devised that enhances dark scene regions in legacy LDR video sequences. The operator will generate a plausible HDR radiance map from a single-exposure video frame and then boost the luminance levels optimally in dark regions in order to improve perceived contrast and the appearance of details.  |
| Requirements           | An interest in Computer Graphics, Image Processing and Computer Vision.  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | Computer Graphics, Image Processing, Tone Mapping  |
### Theme GK-5: Transition Types in 360 Media
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  	Many experiences use multiple camera locations for shooting. In such multi-view 360 media systems, a visual effect is required when the user transitions from one camera location to another. This effect can be a cut or an image-based warp, and the choice of effect impacts many aspects of the experience, including issues related to visual comfort, enjoyment and scene understanding. In this project a multi-view 360 media system will be implemented and quality issues will be investigated via psychophysical experiments. |
| Reference URLs         | https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260946  |
| Anticipated Outcomes   |  A 360 Media system for VR to investigate transition types |
| Requirements           | An interest in Computer Vision and Computer Graphics.  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | 360 Media, Virtual Reality  |
### <span style="color:red;">Theme GK-6: A 3D Rendering Pipeline on FPGA</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | FPGAs have gone from being simple glue logic chips to actually replacing custom application-specific integrated circuits (ASICs) and processors for signal processing and real-time applications. FPGAs are becoming more useful in areas where ASICs were used before. 3D graphics rendering is one such area, where research is underway as to how FPGAs can help to improve the performance of graphics processing units with less energy consumption. In this project an FPGA-based Graphic Processor for low power applications will be developed.  |
| Reference URLs         | http://advances.utc.sk/index.php/AEEE/article/view/1125  |
| Anticipated Outcomes   | An FPGA-based Graphic Processor for low power applications will be developed on Vidor 4000.  |
| Requirements           | An interest in Computer Graphics and hardware.  |
| Max Number of Students | 2  |
| Project Type           |  L4 |
| Keywords               | 	3D Graphics Pipeline, FPGA  |
### Theme GK-7: Telepresence in Virtual Reality using 360 Cameras
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	One of the features of Telepresence systems is enabling a person to feel as if they were present at a place other than their true location. In this project a telepresence system in virtual reality will be developed using VR headsets and 360 cameras.  |
| Reference URLs         | https://philpapers.org/rec/MINT https://philpapers.org/rec/MINT  |
| Anticipated Outcomes   |  A piece of software allowing for the telepresence of a user to a remote location. An advanced outcome would be teleoperation, i.e., the user affecting the remote environment via remotely controlled actuators. |
| Requirements           | An interest in Computer Graphics and Computer Vision.  |
| Max Number of Students | 1  |
| Project Type           |  L3, L4 |
| Keywords               | Telepresence, Teleoperation, Virtual Reality  |

## Staff Proposer: Andrei Krokhin
### Theme AK-1: Backgammon with variable luck
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Backgammon is a game of skill and luck. This project is about developing and implementing a computer backgammon player whose luck can be adjusted to match the skill of a human opponent. While there are many successful AI-based backgammon players (the best ones can even beat human world champions), a good implementation of variable luck remains a challenge. |
| Reference URLs         |  https://www.semanticscholar.org/paper/Using-GP-Gammon%3A-Using-Genetic-Programming-to-Azaria-Sipper/13daf271f013f94da3416108c53e0d706041e628 https://skatgame.net/mburo/ps/STAR-B.pdf |
| Anticipated Outcomes   | Implementation of a computer backgammon player with adjustable luck  |
| Requirements           | None  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | AI, games, backgammon  |
### Theme AK-2: Research tool for AI search in graphs
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Graph homomorphisms generalise graph colourings, and there are many open problems about the complexity of graph colouring and graph homomorphisms. The complexity usually depends on the mathematical structure of problems. Understanding this structure can be quite hard, but it often depends on polymorphisms, i.e. edge-preserving functions. Thus, research into this topic can be guided by a computational tool that detects special polymorphisms, as this can provide intuition about the structure (or sometimes even completely resolve complexity questions). The difficulty is that finding such polymorphisms involves search in spaces that grow very fast. For example, one might look for a 6-ary edge-preserving function, with specific propertes, from a graph with 7 vertices to a graph with 13 vertices, and the number of such possible functions is too large for a naive search. Thus, a highly optimised software tool (in particular, utilising the inherent symmetry of the search space) is needed to cope with such search spaces. Such a tool can be built, for example, on top of a SAT solver (or another AI search engine).  |
| Reference URLs         | http://www.karlin.mff.cuni.cz/~stanovsk/math/gpoly.htm  |
| Anticipated Outcomes   | Implementation of a flexible and usable software tool to search for special graph polymorphisms.  |
| Requirements           |  Interest in AI, strong maths background |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               |  	Graph theory, algorithms, AI search, automated reasoning |
### Theme AK-3: Steganography
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The goal of steganography is to embed a digital file into another digital file, such as a photo, an audio or a video file, or a 3D model, in ways that keep the existence of the embedded message hidden from third parties. Unlike cryptography, where a secret message can be conspicuous and yet protected by encryption, steganography protects not only the message, but also the sender and the receiver by concealing the very existence of the message.  |
| Reference URLs         | http://library.dur.ac.uk/record=b2846691~S1 https://www.sciencedirect.com/science/article/pii/S0165168409003648?via%3Dihub  |
| Anticipated Outcomes   | Implementation and evaluation of existing steganographic algorithms. Possibility for further development and improvement of them.  |
| Requirements           | None  |
| Max Number of Students | 3  |
| Project Type           |  MISCADA, L3, L4 |
| Keywords               |  Steganography, Watermarking, Steganalysis |
### Theme AK-4: Matching under preferences
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Matching theory studies how agents and/or objects from different sets can be matched with each other while taking agents' preferences into account. This theory has been successfully applied to many real-world problems such as matching students to universities, doctors to hospitals, kidney transplant patients to donors, and tenants to houses. Many important variations of the matching problem are NP-hard. Hence appropriate algorithmic solutions (e.g. based on integer programming or on SAT solving) for them need to be explored. This project is about exploration and comparison of different algorithmic approaches to (hard) matching problems.  |
| Reference URLs         |  http://www.unil.ch/de/files/live/sites/de/files/working-papers/14.07.pdf http://eprints.gla.ac.uk/121248/7/121248.pdf |
| Anticipated Outcomes   | Implementation and comparison of the performance of algorithmic approaches to variations of the Hospitals/Residents matching problems.  |
| Requirements           | None  |
| Max Number of Students | 2  |
| Project Type           |  L3, L4 |
| Keywords               | Matching problems, algorithms, heuristics  |
### Theme AK-5: Solving edge-matching problems with SAT solvers
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Edge-matching problems are popular puzzles, that appeared first in the 1890s. Given a set of pieces and a grid, the goal is to place the pieces on the grid such that the edges of the connected pieces match. Such problems are known to be computationally hard. Famously, a prize of 2 million US dollars was offered in 2007 for solving the Eternity 2 edge-matching puzzle with 256 pieces - despite many computational attempts, the prize was left unclaimed. It is well-known that the way a problem is encoded into SAT may strongly affect the performance of SAT solvers on this problem. This project is about creatively using SAT solvers to solve various edge-matching problems.  |
| Reference URLs         | https://www.cs.utexas.edu/~marijn/publications/eternity.pdf  |
| Anticipated Outcomes   |  Solutions of various edge-matching problems via encodings into SAT. |
| Requirements           | None  |
| Max Number of Students | 2  |
| Project Type           |  L3, L4 |
| Keywords               | SAT solving, algorithms, heuristics  |
### Theme AK-6: Integer factorisation algorithms
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | A lot of computer security relies on the perceived computational hardness of the tasks such as integer factorisation. Yet there is little theoretical evidence (that is, no proof) that these tasks are computationally hard. Hence it is important to try to come up with algorithms for these problems (which are based on number theory, naturally). This project will investigate and evaluate the state-of-the-art in algorithms for one of these problems, and implement a selection of such algorithms.  |
| Reference URLs         | https://library.dur.ac.uk/record=b2906346~S1  |
| Anticipated Outcomes   | Implementation of a selection of integer factorisation or discrete logarithm algorithms, evaluation of the state-of-art.  |
| Requirements           | Interest in cryptography, strong maths background  |
| Max Number of Students |  3 |
| Project Type           |  L3, L4 |
| Keywords               | Integer factorisation, algorithms, cryptography  |

## Staff Proposer: Frederick Li
### Theme FL-1: Attractiveness Analysis
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Perception of beauty has been long debated, where color or layout design is a critical part for conveying attractiveness of a piece of design work, e.g., painting or indoor design. Criteria for determining attractiveness may include color combination, color theme construction, item relation, etc. This project is to develop an algorithm for attractive analysis, which can be tested against existing or newly captured data sets to determine its applicability.  |
| Reference URLs         | Building look & feel concept models from color combinations (https://link.springer.com/article/10.1007/s00371-011-0657-9); Computer-generated residential building layouts (https://doi.org/10.1145/1882261.1866203)  |
| Anticipated Outcomes   | The development of an algorithm for attractiveness analysis, which can be integrated into other projects.  |
| Requirements           | Machine learning, image processing  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | 	Color feature analysis, Item relation analysis, Machine Learning  |
### Theme FL-2: Remote rendering for interactive graphics
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 3D scene rendering typically requires a significant amount of computing and hardware resources. To alleviate such a requirement at client devices, remote rendering is a popular solution to adopt, which relies on a server to perform all rendering tasks and send the rendered images to clients for display. Recently, Google Stadia, NVidia GRID and Xbox Streaming, follow this idea to support user game playing. However, their implementations are still not perfect. For instance, Xbox remote rendering on a PC under a home network is sometimes lagging if you even just opt for a medium quality display. This project is to develop a depth-image based rendering algorithm to efficiently support multi-client interaction for a remote 3D application. The algorithm will be tested against some performance analysis to determine its applicability.  |
| Reference URLs         | Depth-image-based rendering (DIBR) (http://dx.doi.org/10.1117/12.524762); Scalable Remote Rendering using Synthesized Image Quality Assessment (https://doi.org/10.1109/ACCESS.2018.2853132)  |
| Anticipated Outcomes   | The development of a remote rendering algorithm to support multi-client interaction within a collaborative virtual environment.  |
| Requirements           | Computer Graphics, Image processing  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | Depth-image based rendering, remote rendering  |
### Theme FL-3: Human-Object Interaction Recognition through Machine Learning
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Understanding human-object interaction is essential for a variety of applications, such as security surveillance and game interaction. Recently, machine learning techniques, including CNN, RNN and LSTM, have been adopted to recognise human motions, producing more accurate results than using traditional hand-crafted features. However, there is still a gap for them to recognise human-object interaction, particularly due to complicated human-object relations and occlusion problems. This project is to develop an algorithm to support accurate human-object interaction recognition. The algorithm will be tested against some performance analysis to determine its applicability.  |
| Reference URLs         | A survey on vision-based human action recognition (https://doi.org/10.1016/j.imavis.2009.11.014); A survey of video datasets for human action and activity recognition (https://doi.org/10.1016/j.cviu.2013.01.013)  |
| Anticipated Outcomes   | The development of an algorithm to support human-object interaction recognition, which can be integrated into other projects.  |
| Requirements           | Machine Learning, Image processing, computer vision  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | Motion analysis, machine learning  |
### Theme FL-4: Game-based Learning
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Machinations is a technique for game designers to work out and visualize the internal economy of a game. It is an effective approach for designing rules to govern how game players can make progress during a game-playing session. Machinations can be borrowed to support the design of a game-based learning system, explicitly developing rules to govern how students can make learning progress through the learning system. This project is to develop a machinations supported game-based learning system, where student learning progress can be explicitly qualified and measured through the internal economy of game-based learning elements. The system will be tested against some user studies to determine its applicability.  |
| Reference URLs         | Simulating Mechanics to Study Emergence in Games (https://aaai.org/ocs/index.php/AIIDE/AIIDE11WS/paper/view/4093); Digital game-based learning: Towards an experiential gaming model (http://dx.doi.org/10.1016/j.iheduc.2004.12.001)  |
| Anticipated Outcomes   | The development of a system to support game-based learning.  |
| Requirements           | Computer Graphics, Game Development  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | game development, game-based learning, e-Learning  |
### Theme FL-5: 3D modeling by Machine Learning
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 3D models comprises a lot of geometric features, which are complicated to generate by inexperience users. With the advance of machine learning techniques, it is now possible for computers to accept intuitive inputs from users, such as images and sketches of 3D objects, generating the expected 3D models through learning algorithms. This project is to develop a learning algorithm for 3D model or 3D environment generation. The algorithm will be tested against some qualitative and quantitative analysis to determine its applicability.  |
| Reference URLs         | Make3D: Learning 3D Scene Structure from a Single Still Image (http://ieeexplore.ieee.org/abstract/document/4531745/); Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling (http://3dgan.csail.mit.edu/papers/3dgan_nips.pdf)  |
| Anticipated Outcomes   | The development of an algorithm to support 3D model or 3D environment generation, which can be integrated into other projects.  |
| Requirements           | Machine Learning, 3D Modeling, Computer Vision  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | 	Machine Learning, Computer Graphics, Adversarial Networks  |
### Theme FL-6: VR Gaming
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  VR equipment, such as HTC Vive and Playstation VR become very popular because they provide users immersive experience to graphics or game environments. Besides graphics visualisation, some of these equipment also provide controllers for users to interact with their motions. This project investigates methods to capture meaningful motions from users and generate proper visual responses to users, which aims at providing users realistic immersive experience. The methods will be tested against some performance and correctness analysis to determine its applicability. |
| Reference URLs         | Virtual reality: how much immersion is enough (https://doi.org/10.1109/MC.2007.257); Evaluating display fidelity and interaction fidelity in a virtual reality game (https://doi.org/10.1109/TVCG.2012.43)  |
| Anticipated Outcomes   | The development of methods to support immersive user interaction and feedback, which can be integrated into other projects.  |
| Requirements           | Computer Graphics, Game Development  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | Virtual reality, motion capture, visual feedback generation  |

## Staff Proposer: Yang Long
### Theme YL-1: Zero-shot Image Classification: Teach AI to Recognise Unknown Things
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Existing supervised learning system for image classification requires a large number of training images with paired annotations. Collecting a sufficient training set for each of ever-growing new categories is expensive and sometimes infeasible, e.g. due to privacy issues or is of unavailable novel categories. Zero-Shot Learning (ZSL) exploits prior human knowledge shared by seen and unseen categories. By learning a mapping from the image domain to the knowledge domain, unseen categories with zero-shot training images can be recognised at test time. This project aims to both exploring visual-semantic learning algorithms and new knowledge representation methods to improve the model performance. Also, the knowledge-based model can potentially help address the edge-cutting interpretability issues of deep learning and AI.  |
| Reference URLs         | Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition  |
| Anticipated Outcomes   | Make AI recognise new categories without training images.  |
| Requirements           | Programming skills in MATLAB and Python, and basic knowledge in machine learning.  |
| Max Number of Students | 2  |
| Project Type           |  MISCADA, L3, L4 |
| Keywords               | Zero-shot Learning, Visual-semantic Model, Knowledge Representation, Interpretability of Deep Learning.  |
### Theme YL-2: AI Musician: Music Genre Recognition Transfer and Generation
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  AI creativity is one of the most charming topics and generating realistic and aesthetic pieces of music is an exciting task. Style and domain transfer techniques have been widely applied in Computer Vision tasks for generating images, videos and texts. The increasing number of successful showcases have motivated attempts made to generate symbolic music. This project aims to investigate the recent development of AI music generation and take step-by-step to explore or focus on tasks of 1) recognise the music genre by data-driven features; 2) transfer a given piece of music to a new style by manipulating the recognised features; 3) generate genre-specific music pieces. |
| Reference URLs         | Code: https://github.com/sumuzhao/CycleGAN-Music-Style-Transfer; Demo: https://www.youtube.com/channel/UCs-bI_NP7PrQaMV1AJ4A3HQ; Paper: https://arxiv.org/pdf/1809.07575.pdf  |
| Anticipated Outcomes   | 1) A deep understanding of the AI music generation techniques by thorough literature reviews. 2) Implement basic signal processing, sequential and generative deep learning models. 3) Task modelling using machine learning methodologies. 4) Investigate and develop how to evaluate the proposed AI music model.  |
| Requirements           |  Python, Machine Learning, Deep Neural Networks |
| Max Number of Students | 5  |
| Project Type           |  MISCADA, L3, L4 |
| Keywords               |  	Music Genre Recognition; Style Transfer; Generative Models; Sequential Models; |
### Theme YL-3: Intelligent Vlogging: Personalised Task-driven Video-audio Summarisation
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | How to trace back to the time spent in the past is an important question in daily lives, such as for behavioural understanding, security surveillance, or just help memorise important activities and make the life more meaningful. Despite low-cost cameras and pervasive network connections, it is still intractable to make an ever-lasting recording due to the lack of data storage, uploading broadband width, information retrieval. This project aims to explore the cutting-edge active video summarisation techniques to seek innovative approaches to compress, summarise, display, and retrieve visual-audial contents with minimal information loss and better user experience. The exploration will start from basic frame-based entropy, optical-flow approaches, to more advanced deep learning-based models.  |
| Reference URLs         | Paper: http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14856/14279 Demo: https://www.youtube.com/watch?v=jLDe1uB2vj4 Code: https://github.com/GarciaDelMolino/active-video-summarization  |
| Anticipated Outcomes   |  1) An efficient video-audio summarisation toolbox to edit and process daily video recorder in an intelligent way. 2) Discover the potential applications for video summarisation. 3) A thorough understanding of the development of video summarisation with intensive literature review. 4) Implementation skills in machine learning, computer vision, and software engineering. |
| Requirements           | Strong programming skills in Python, C++; Knowledge of machine learning, computer vision and AI;  |
| Max Number of Students | 5  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |  Video, Audio, Summariation, AI, Computer Vision, Machine Learning |
### Theme YL-4: How Intelligent is AI? Machine Reasoning on IQ questions
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Thinking in pictures is a crucial factor to measure the intelligent level and the ability to carry out logical induction. Raven's Progressive Matrices (RPM) is designed to measure the reasoning ability of human reasoning ability, which has been adopted to test machine intelligence recently. This project will explore the development of machine reasoning abilities and implement cutting-edge AI models on the RPM datasets. The ideal outcomes are two folds - while we can improve the machine performance, it is also helpful to better understand the essence of human intelligence.  |
| Reference URLs         | Paper: http://papers.nips.cc/paper/8392-learning-perceptual-inference-by-contrasting.pdf Code: https://github.com/WellyZhang/CoPINet  |
| Anticipated Outcomes   | 1) A thorough investigation of AI test standards and machine reasoning models. 2) Implement basic AI models on visual perceptive inference task with Raven\'s Progressive Matrices. 3) Observe the results, evaluate models, and discover potential improvements.  |
| Requirements           | strong coding in Python&PyTorch, strong machine learning knowledge, strong mathematical skills  |
| Max Number of Students |  3 |
| Project Type           | MISCADA, L3, L4  |
| Keywords               | 	Perceptive Reasoning, AI, Machine Inference  |

## Staff Proposer: Barnaby Martin
### Theme BM-1: The Student-Project Allocation problem
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  The Student-Project Allocation problem with preferences over Projects (SPA-P) involves sets of students, projects and lecturers, where the students and lecturers each have preferences over the projects. In this context, we typically seek a stable matching of students to projects (and lecturers). However, these stable matchings can have different sizes, and the problem of finding a maximum stable matching (MAX-SPA-P) is NP-hard (description from [Manlove, Milne and Olaosebikan 2018]). In this project we will try to solve this problem in various ways, potentially using Integer Programming. |
| Reference URLs         |   |
| Anticipated Outcomes   | A working system to solve instances of the Student-Project Allocation problem with preferences over Projects.  |
| Requirements           |  Integer Programming, Algorithms, Complexity |
| Max Number of Students | 1  |
| Project Type           |  MISCADA, L3, L4 |
| Keywords               |   |
### Theme BM-2: Arithmetic constraint satisfaction
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	Constraint satisfaction problems (CSPs) allow for a rich expressive framework especially in their infinite-domain generality over structures of arithmetic such as the rationals or integers. Recent work has exposed interesting hybrid algorithms for new tractable classes. In this project we would explore building a solver for certain class of infinite-domain CSPs. This project could also go in the direction of Satisfiability Modulo Theories which gives a powerful formalism for solving general arithmetic CSPs.  |
| Reference URLs         | https://arxiv.org/abs/1503.08572,https://arxiv.org/abs/1503.08572 <br>https://people.eecs.berkeley.edu/~sseshia/pubdir/SMT-BookChapter.pdf  |
| Anticipated Outcomes   | A constraint solver for infinite-domain Constraint Satisfaction Problems.  |
| Requirements           | Basic mathematics, basic programming.  |
| Max Number of Students | 2  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |  CSP solving, Constraint programming, Satisfiability Modulo Theories |
### Theme BM-3: Solving Quantified Constraints
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Quantified constraint satisfaction problems (QCSPs) allow for a richer expressive framework than classical constraint satisfaction problems with computational complexity rising to Pspace. They are used in Artificial Intelligence to model non-monotonic reasoning and planning. Quantified Boolean Formulas (QBF) is the canonical extension of propositional Satisfiability from NP to Pspace by restoring universal quantification. In this project we would explore building a solver for QCSPs or certain classes of QCSPs that enjoy benign properties such as the so-called collapsibility or ability to be solved by local consistency methods.  |
| Reference URLs         | https://pn.host.cs.st-andrews.ac.uk/qcsp_aij_final_version.pdf,https://arxiv.org/abs/cs/0607106  |
| Anticipated Outcomes   | The building of a QCSP solver  |
| Requirements           | Basic mathematics, basic logic, basic programming.  |
| Max Number of Students |  1 |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |  	QCSP solving, Quantified constraints, Constraint programming |
### Theme BM-4: Solving problems with Satisfiability
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Modern SAT-solvers are very efficient and many practitioners argue they make NP a tractable class. Additionally, they can be used to improve upper and lower bounds for many constants arising from combinatorial problems. This project would look at encodings of problems into propositional satisfiability in order to seek bounds for Ramsey numbers, van der Warden numbers, graph colouring numbers or similar.  |
| Reference URLs         | https://www7.in.tum.de/um/bibdb/kugele/kugele_diploma06.pdf<br>https://arxiv.org/abs/1510.02374<br>https://www.sciencedirect.com/science/article/pii/S0307904X14006556  |
| Anticipated Outcomes   |  A good encoding to propositional satifiability that yields improved bounds for combinatorial constants. |
| Requirements           | Basic mathematics, basic programming  |
| Max Number of Students | 1  |
| Project Type           | MISCADA. L3, L4  |
| Keywords               | SAT-solving, Ramsey Theory, Combinatorics  |
### Theme BM-5: Verification
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Verification is a powerful tool for proving certain desirable properties are satisfied in some system. In many critical processes, verification forms an invaluable dual procedure to testing. The aim of this project is to formally specify some chosen system of protocol in order that some desirable property might be verified to hold in it, though the use of a formal verifier such as SMC or SPIN. An alternative possibility is to add some functionality to these formal verifiers. |
| Reference URLs         | http://discover.durham.ac.uk/primo_library/libweb/action/display.do?tabs=detailsTab&ct=display&fn=search&doc=44DUR_LMS_DS.b19834111&indx=1&recIds=44DUR_LMS_DS.b19834111&recIdxs=0&elementId=0&renderMode=poppedOut&displayMode=full&frbrVersion=&frbrSourceidDisplay=44DUR_LMS_DS&frbrIssnDisplay=&dscnt=0&frbrRecordsSource=Primo+Local&mode=Basic&vid=44DUR_VU1&lastPag=&rfnGrp=frbr&tab=default_tab&frbrJtitleDisplay=&dstmp=1581338260420&frbg=142899139&lastPagIndx=1&frbrSrt=date&frbrEissnDisplay=&scp.scps=scope%3A%2844DUR%29%2CEbsco44DURb%2CEbsco44DURa%2Cprimo_central_multiple_fe&fctV=142899139&cs=frb&srt=rank&fctN=facet_frbrgroupid&dum=true&vl(freeText0)=logic%20in%20computer%20science  |
| Anticipated Outcomes   |  The formal verification of some property on a specified system or protocol |
| Requirements           | Basic mathematics, basic programming  |
| Max Number of Students |  1 |
| Project Type           | MISCADA, L3, L4  |
| Keywords               | Verification, Temporal logics, Modal logics  |
### Theme BM-6: Social Network Analysis
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Social Network Analysis is a powerful tool for understanding the dynamics and flow properties in social networks. For example, these could be in the form of friendship ties or knowledge flows in a network of people, or disease propagation in a network of animals. The aim of this project is to formulate and implement useful metrics for the analysis of social networks, which could be mined from the internet or come from some established data set.  |
| Reference URLs         | https://networkx.github.io/,http://discover.durham.ac.uk/primo_library/libweb/action/display.do;jsessionid=78FFFCD11AC3EA2751C887DDF898EE8C?tabs=detailsTab&ct=display&fn=search&doc=44DUR_LMS_DS.b2644978x&indx=1&recIds=44DUR_LMS_DS.b2644978x&recIdxs=0&elementId=0&renderMode=poppedOut&displayMode=full&frbrVersion=&frbg=&&dscnt=0&scp.scps=scope%3A%2844DUR%29%2CEbsco44DURb%2CEbsco44DURa%2Cprimo_central_multiple_fe&mode=Basic&vid=44DUR_VU1&srt=rank&tab=default_tab&vl(freeText0)=Analyzing%20Social%20Media%20Networks%20with%20NodeXL%3A%20Insights%20from%20a%20Connected%20World&dum=true&dstmp=1487866918162  |
| Anticipated Outcomes   |  The meaningful analysis of a social network |
| Requirements           | Basic mathematics, basic programming  |
| Max Number of Students |  2 |
| Project Type           | MISCADA, L3, L4  |
| Keywords               | Network Analysis, Graph Theory  |

## Staff Proposer: George Mertzios
### Theme GM-1: Coloring a graph via a game
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  A proper coloring of a graph is an assignment of colors to the vertices of the graph (one color for every vertex) such that any two adjacent vertices receive different colors. Computing the smallest number of colors that are needed to proper color a given graph is an NP-hard problem, i.e. most probably there does not exist any exact algorithm that runs in polynomial time in worst-case. However, as the proper coloring problem finds many applications in various contexts, it is important to deal with this problem with various algorithmic approaches, even if they do not always guarantee an optimum output. In this project we aim at implementing and experimentally evaluating a recently developed game-theoretic method for computing a proper coloring of a given graph, in which every vertex of the graph corresponds to a strategic player of the game. |
| Reference URLs         | https://www.tandfonline.com/doi/abs/10.4169/amer.math.monthly.119.09.771  |
| Anticipated Outcomes   | To implement and experimentally evaluate a recently developed game-theoretic method for computing a proper coloring of a given graph.  |
| Requirements           | none  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | 	proper coloring problem, graph, chromatic number, strategic game, equilibrium.  |

### Theme GM-2: Influence spreading in networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The notion of influence spreading in a network is central in many modern applications, including social networks. There are two main types of influence propagation models, progressive and non-progressive. In a progressive model, once a node of the network becomes infected (i.e. influenced), it will remain forever; in contrast, in non-progressive models the nodes may become infected and uninfected many times. The goal of this project is to simulate and compare various influence spreading models, progressive and non-progressive, the performance of which will be analyzed and compared with the theoretical findings in the area.  |
| Reference URLs         | https://www.sciencedirect.com/science/article/pii/S0304397514005398  |
| Anticipated Outcomes   | The implementation and simulation of influence spreading models and the comparison of the experimental findings with the theoretical ones.  |
| Requirements           | none  |
| Max Number of Students |  5 |
| Project Type           |  L3, L4 |
| Keywords               | 	influence spreading, network, progressive model, non-progressive model, target set.  |
### Theme GM-3: Temporal Networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Consider a network where every edge is assigned a set of natural numbers (its labels). The set of labels of an edge represent the different moments in time in which this specific edge is available. Such labeled networks are called temporal networks and they represent networks that are dynamically changing over time. Many problems in standard networks can be appropriately modified to make sense in the context of temporal networks. For instance, while to guarantee connectivity in standard networks we need to have a path between any pair of vertices, in the context of a temporal network we achieve connectivity if there exists a temporal path between any pair of vertices, i.e. a path in which the labels of the edges are increasing. Various further classical “non-path” graph problems can be naturally extended to the temporal settings, such as Maximum Clique, Minimum Vertex Cover, Maximum Matching. The goal of this project is to implement and evaluate various algorithmic approaches to optimization problems in temporal networks.  |
| Reference URLs         | https://arxiv.org/abs/1502.04382 https://link.springer.com/article/10.1007/s00453-018-0478-6  |
| Anticipated Outcomes   | To implement various algorithms on temporal networks and to compare their experimental performance with the theoretically predicted performance.  |
| Requirements           | none  |
| Max Number of Students |  5 |
| Project Type           | L3, L4  |
| Keywords               |  algorithm, graph theory, temporal network, dynamic network, edge label, temporal path. |
### Theme GM-4: Blockchain tokens
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The blockchain paradigm when coupled with cryptographically-secured transactions has demonstrated its utility through a number of projects, not least Bitcoin. Extending on the Bitcoin, Ethereum revolutionized the blockchain technology by providing a platform on which arbitrary smart contracts can be implemented and executed. These smart contracts (ERC20 tokens) need to be implemented on a dedicated, Turing-complete programming language, called Solidity. At a later stage other blockchain platforms appeared, having the same –or in some cases even more enhanced– capabilities, such as the NEO platform (issuing NEP5 tokens). The aim of this project is to implement an ERC20 or a NEP5 token with smart contracts of a specific functionality and to explore the capabilities of such a token.  |
| Reference URLs         | http://blockchain.mit.edu/ https://www.ethereum.org/ https://solidity.readthedocs.io/en/develop/introduction-to-smart-contracts.html  |
| Anticipated Outcomes   | To implement an ERC20 or a NEP5 token with smart contracts of a specific functionality and to explore the capabilities of such a token.  |
| Requirements           | The student should be comfortable with learning a new programming language (e.g. Solidity) and have sufficient self-motivation to learn about the underlying technology of blockchain and its applications.  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               |  blockchain, Ethereum, ERC20 token, algorithm, programming language. |
### Theme GM-5: Mutating Networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Consider a network with nodes and undirected edges, where the nodes are occupied by (at least two) different kinds of individuals. As time elapses, neighboring individuals in this network interact with each other. In that case, the color of two interacting individuals may change according to some fixed rule (which may be probabilistic or not). That is, individuals mutate, and thus the network itself mutates as well. In such “mutating rules” that are interesting in practice, some colors are more “aggressive” than others, in the sense that these colors mutate more rarely than others (they act as viruses). This project aims at implementing a platform for mutating networks, where different interaction rules/patterns can be experimentally tested against their theoretically predicted behavior.  |
| Reference URLs         | https://www.sciencedirect.com/science/article/pii/S0304397512010754?via%3Dihub  |
| Anticipated Outcomes   | The implementation of a platform for mutating networks, where different interaction rules/patterns can be experimentally tested.  |
| Requirements           | none  |
| Max Number of Students |  3 |
| Project Type           |  L3, L4 |
| Keywords               | evolutionary dynamics, directed/undirected graphs, fixation probability, potential function, Markov chain, fitness, population structure.  |

## Staff Proposer: Lawrence Mitchell
### Theme LM-1: Automating the generation of performance models for simulation code
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | When it comes to the simulation of physical systems, scientists and engineers always want the answer faster! Having implemented some numerical model, they say "it runs too slow, what should I do?". Sometimes, the answer is "buy a better computer", but perhaps it might be "write better code". To determine which it is, we need a performance model of the code. These are available, but often difficult to work out by hand. In this project, you will develop performance modelling tools for simulation software, that simplify answering these questions. To simplfiy things, we will work in the open source Firedrake framework, where the computation has a symbolic description that can we can introspect to determine critical information: such as the number of floating point operations required, or the amount of data that must be loaded from RAM. A starting point will be automatic production of Roofline models, which provide a simple first cut analysis of the limiting factor in a computation. We will develop these analysis tools so that they can run in situ, to provide instant feedback, along with standalone post-processing tools that can be run after a simulation is completed: these are useful when the simulation has run on a supercomputer, rather than your laptop. This project runs in the context of the Firedrake project (www.firedrakeproject.org): a library for performing numerical simulations of the laws of physics using the finite element method. At its core, it uses embedded domain specific languages, along with domain specific compilers, to offer both highly expressive and high performance code.  |
| Reference URLs         | https://www.firedrakeproject.org  |
| Anticipated Outcomes   | A tool for identifying performance bottlenecks in simulation code that can be used in the Firedrake finite element package.  |
| Requirements           |  Python programming, familiarity with and interest in Core IIb performance engineering material. |
| Max Number of Students | 1  |
| Project Type           |  MISCADA, L3, L4 |
| Keywords               |   |
### Theme LM-2: Scalable solvers for Biot's model
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Biot's model is a set of partial differential equations modelling the compaction of granular media (for example soil). There are a number of reasonably well-known approaches to solving these equations by iterative methods that are robust to parameters and size of the mesh. This project would implement Biot's model using the Firedrake finite element system (https://www.firedrakeproject.org) and then study the performance of different methods. We could then implement a new multigrid scheme that appears not to have been studied previously based on compatible relaxation in the spirit of Vanka relaxation. This would again be implemented in Firedrake using the PCPATCH preconditioning framework. Refs: Farrell, Knepley, Mitchell, Wechsung. PCPATCH: software for the topological construction of multigrid relaxation methods. arxiv:1912.08516 Adler, Gaspar, Hu, Rodrigo, Zikatanov. Robust block preconditioners for Biot's model. doi:10.1007/978-3-319-93873-8_1 Lee, Mardal, Winther. Parameter-robust discretization and preconditioning of Biot's consolidation model. doi:10.1137/15M1029473  |
| Reference URLs         |  https://www.firedrakeproject.org |
| Anticipated Outcomes   | An implementation of Biot's model in Firedrake, and a comparison of some different preconditioning strategies.  |
| Requirements           | Python programming, numerical linear algebra, finite elements and/or numerical analysis desirable.  |
| Max Number of Students |  1 |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme LM-3: Optimal complexity function evaluation on triangles and tetrahedra
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In almost all areas of numerical computing, fast algorithms appear when we can expose and exploit structure in the problem. This project is to do exactly that for the evaluation of a certain class of polynomials known as Bernstein polynomials. These are used both in computer graphics (where they are related to Bezier curves) and in finite element methods as an approximation space. In multiple dimensions, they admit a decomposition that allows for fast evaluation using appropriate loop reordering techniques. These transformations are too complex to be spotted by a general purpose compiler, and so this project will develop appropriate symbolic representations of the evaluation rules such that a domain specific compiler (TSFC, https://github.com/firedrakeproject/tsfc) can find the low-complexity implementation. This project runs in the context of the Firedrake project (www.firedrakeproject.org): a library for performing numerical simulations of the laws of physics using the finite element method. At its core, it uses embedded domain specific languages, along with domain specific compilers, to offer both highly expressive and high performance code.  |
| Reference URLs         |  https://www.firedrakeproject.org |
| Anticipated Outcomes   | - An extension of the TSFC intermediate representation to handle affine loop constraints - Implementation of tabulation of Bernstein polynomials that exposes appropriate structure - Optimisation passes in compiler that exploit the newly exposed structure.  |
| Requirements           | Python programming; interest in compiler techniques; linear algebra.  |
| Max Number of Students | 1  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme LM-4: Eating functions fast
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | This project runs in the context of the Firedrake project (www.firedrakeproject.org): a library for performing numerical simulations of the laws of physics using the finite element method. At its core, it uses embedded domain specific languages, along with domain specific compilers, to offer both highly expressive and high performance code. One core feature that is presently missing in the symbolic levels is the ability to perform dual evaluation: akin to integration of functions. This project will develop the necessary symbolic algebra and representations to enable reasoning about the numerical dual evaluation schemes that Firedrake already uses. The goal is to exploit structure to provide optimal complexity implementations. In particular, we will do this in the Python package FInAT (https://github.com/finat/finat).  |
| Reference URLs         |  https://www.firedrakeproject.org https://github.com/finat/finat |
| Anticipated Outcomes   | Specification and implementation of appropriate API for dual evaluation Implementation of symbolic dual evaluation wrapping existing numerical approach  |
| Requirements           |  Python programming; linear algebra; numerical methods |
| Max Number of Students | 1  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme LM-5: Scientific visualisation in the browser
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The goal of this project is to enable visualisation of solution fields in a webbrowser for use when embedding Jupyter notebooks (https://jupyter.org). This will probably either involve interfacing with the GLvis library (https://glvis.org), or else using X3DOM (https://www.x3dom.org) to directly access WebGL. This project runs in the context of the Firedrake project (www.firedrakeproject.org): a library for performing numerical simulations of the laws of physics using the finite element method. At its core, it uses embedded domain specific languages, along with domain specific compilers, to offer both highly expressive and high performance code.  |
| Reference URLs         |   |
| Anticipated Outcomes   | Interactive plotting output of fields and meshes suitable for embedding Jupyter notebooks  |
| Requirements           | 	Python programming; Interest in visualisation; Javascript/WebGL a plus.  |
| Max Number of Students | 1  |
| Project Type           |  MISCADA, L3, L4 |
| Keywords               |   |

## Staff Proposer: Boguslaw Obara
### Theme BO-1: 3D Morphological Skeletonization
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Description: In the processing and analysis of images it is important to be able to extract features, describe shapes and recognize patterns. Such tasks refer to geometrical concepts such as size, shape, and orientation. Mathematical morphology uses concepts from set theory, geometry and topology to analyse geometrical structures in an image. In particular, morphological skeleton is a skeleton (or medial axis) representation of a shape or binary image, computed by means of morphological operators. The student(s) doing this project will implement a morphological skeletonization algorithm based on sets of structuring elements for hit-or-miss transforms whereas each structuring element actually describes a shape primitive. The performance of the implemented coupled active contours approach will be evaluated by its applications to centreline extraction in 3D biomedical networks.  |
| Reference URLs         |   |
| Anticipated Outcomes   | The development of a one-class image processing code, which can be integrated into other projects.  |
| Requirements           | Python  |
| Max Number of Students |  3 |
| Project Type           |  L3, L4 |
| Keywords               | Image Processing  |
### Theme BO-2: Count calories using photos
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Advanced image processing combined with deep learning technology can be used to find out exactly what food you are eating. The student(s) doing this project will implement a mobile phone app. The app will be able to work out the size of each piece of food in relation to the plate, as well as any condiments that were placed beside it. It then adds up exactly how many calories you are eating, and may even tell you the food\'s nutritional value. |
| Reference URLs         |   |
| Anticipated Outcomes   | The development of a one-class image processing code, which can be integrated into other projects  |
| Requirements           |  Python |
| Max Number of Students |  3 |
| Project Type           |  L3, L4 |
| Keywords               | Image Processing, Deep Learning  |
### Theme BO-3: 2D/3D Junction Detection Using Streamlines
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The student(s) doing this project will implement an image processing method to detect multi-modal regions composed of linear structures and measure the orientations in these regions, i.e. at line X-sings, T-junctions and Y-forks. The method is based on streamlines which are constructed from a vector field that represents the local structure in the image. This method allows us to accurately locate junctions and crossings and at the same time measures the attributes of the underlying uni-modal structures. The performance of the implemented junction detection approach will be evaluated by its applications to branching points extraction in 2D/3D biomedical networks.  |
| Reference URLs         |   |
| Anticipated Outcomes   | The development of a one-class image processing code, which can be integrated into other projects.  |
| Requirements           |  Python |
| Max Number of Students | 3  |
| Project Type           | L3, l4  |
| Keywords               | 	Image Processing  |
### Theme BO-4: An Image Processing Approach for Detection of Brain Aneurysms in 3D CT/MRI Imaging Data
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | An aneurysm is a bulge in a blood vessel caused by a weakness in the blood vessel wall, usually where it branches. As blood passes through the weakened blood vessel, the blood pressure causes a small area to bulge outwards like a balloon. Aneurysms can develop in any blood vessel in the body, but the two most common places are: the abdominal aorta and the brain. The student(s) doing this project will implement an image processing approach to detect the aneurysm symptoms in 3D CT/MRI images. The performance of the proposed approach will be evaluated by its applications to wide range of 3D medical images provided by the The James Cook University Hospital.  |
| Reference URLs         |   |
| Anticipated Outcomes   |  The development of a one-class image processing code, which can be integrated into other projects. |
| Requirements           | Python  |
| Max Number of Students |  3 |
| Project Type           |  L3, L4 |
| Keywords               | Image Processing  |

## Staff Proposer: Daniel Paulusma
### Theme DP-1: Snake-in-the-Box
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The problems Snake-in-the-Box and Coil-in-the-Box are those of finding a longest induced path or longest induced cycle in an n-dimensional hypercube, respectively. For dimension at least 9 the answer is still open and only lower bounds are known. The ultimate goals of this project are to beat these lower bounds and to set new world-records as has been done by Durham in the past (see also the list of current records in the reference below). It will also be possible to consider a number of variants of these two problems known in the literature.  |
| Reference URLs         | http://ai1.ai.uga.edu/sib/sibwiki/doku.php/records http://ai1.ai.uga.edu/sib/sibwiki/doku.php/ https://arxiv.org/abs/1603.05119  |
| Anticipated Outcomes   | Improved heuristics and new techniques for finding snakes and coils (ideally resulting in better lower bounds on the length of a longest snake or coil for various dimensions, but this is not a requirement for a successful project as the emphasis is to increase our understanding of the problems of finding snakes and coils in highly structured networks).  |
| Requirements           | 	an interest in heuristics for solving a graph-theoretic problem (that has applications)  |
| Max Number of Students | 4  |
| Project Type           | L3, L4  |
| Keywords               | longest induced paths, longest induced cycles, hypercubes, heuristics  |
### Theme DP-2: Parameterized Graph Algorithms
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Discrete optimization problems often have an associated natural parameter k, which we may assume is small compared to the rest of the input. The goal of a project under this theme is to design and implement algorithms or heuristics for solving discrete optimization problems that exploit the fact that k is small. To give an example of such a problem, the Feedback Vertex Set problem is to modify a graph into a tree by deleting at most k vertices. To give another example, the Vertex Cover problem is to modify a graph into an independent set by deleting at most k vertices. The project could be related to the Parameterized Algorithms and Computational Challenge (PACE), which was established in 2015 "to deepen the relationship between parameterized algorithms and practice", provided PACE will run again and deadlines are compatible.  |
| Reference URLs         | https://pacechallenge.org http://parameterized-algorithms.mimuw.edu.pl  |
| Anticipated Outcomes   | new parameterized algorithms and heuristics for solving one or more central graph-theoretic problems  |
| Requirements           | an interest in exact algorithms and heuristics for solving graph-theoretic problems  |
| Max Number of Students |  6 |
| Project Type           | L3, L4  |
| Keywords               |  graph, parameterized algorithm, heuristic |
### Theme DP-3: Graph Colouring
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Graph colouring involves the labeling of the vertices of some given graph by integers called colours such that no two adjacent vertices receive the same colour. The objective is to minimize the number of colours. Alternatively, it is possible to consider edge colourings, where edges sharing an end-vertex need to receive a different colour. Graph colouring has been a popular research topic since its introduction as a map colouring problem more than 150 years ago. Some reasons for this are its appealingly simple definition, its large variety of open problems, and its many application areas. Because the Graph Colouring problem is NP-hard, it is natural to restrict the input to special graph classes and to design and implement algorithms tailor-made for such graph classes. This will be the focus of a project under this theme. |
| Reference URLs         | https://arxiv.org/abs/1407.1482 http://community.dur.ac.uk/daniel.paulusma/Papers/Submitted/survey2.pdf  |
| Anticipated Outcomes   | new algorithms for colouring graphs that exploit the graph structure  |
| Requirements           |	an interest in graph theory and graph algorithms   |
| Max Number of Students |  4 |
| Project Type           | L3, L4  |
| Keywords               | 	graph, graph class, colouring, algorithm, heuristic  |
### Theme DP-4: On-line Graph Colouring
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Graph colouring involves the labeling of the vertices of some given graph by integers called colours such that no two adjacent vertices receive the same colour. The objective is to minimize the number of colours. Graph colouring has been a popular research topic since its introduction as a map colouring problem more than 150 years ago. Some reasons for this are its appealingly simple definition, its large variety of open problems, and its many application areas. In the on-line version of Graph Colouring, vertices are presented one by one, and must be coloured by the algorithm with no (or limited) knowledge on the remainder of the graph. To give an example, one of the best-known on-line colouring algorithms is First-Fit, which assigns each new vertex with the smallest available colour. This project is to design and implement on-line colouring algorithms and to compare their performance.  |
| Reference URLs         | http://community.dur.ac.uk/daniel.paulusma/Papers/Submitted/online_bipartite.pdf http://community.dur.ac.uk/daniel.paulusma/Papers/Submitted/survey2.pdf  |
| Anticipated Outcomes   |  new on-line colouring algorithms |
| Requirements           |  an interest in graph theory and graph algorithms |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | graph, graph class, on-line colouring, algorithm, heuristic  |
### Theme DP-5: SAT Solving: the (k,s)-SAT problem
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Suppose we consider SAT formulas where - every clause contains exactly k literals - every variable appears in at most s clauses. This yields the (k,s)-SAT problem. For example, it is known that every instance of(3,3)-SAT is satisfiable, but (3,4)-SAT is NP-complete. However, every instance of (3,4)-SAT with at most 3 variables occurring in four clauses is satisfiable. And there exists an instance of (3,4)-SAT with 9 variables occurring in four clauses that is not satisfiable. Asking if we can narrow this gap is a typical question that we seek to answer in this project.  |
| Reference URLs         | http://community.dur.ac.uk/daniel.paulusma/Papers/Submitted/ks-sat3.pdf  |
| Anticipated Outcomes   | New heuristics for (k,s)-SAT and new examples of non-satisfiable instances of (k,s)-SAT  |
| Requirements           | An interest in SAT solvers  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | Satisfiability problem, heuristic  |

## Staff Proposer: Rob Powell
### Theme RP-1: Reinforcement Learning - Looking for New Backgammon Strategies
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Backgammon is a two player board game that involves a combination of strategy and luck. You may have an "unlucky" roll of the dice, but the player with the better strategy will win on average over a number of games. There are 5 well known backgammon strategies, but what has not been studied so well are the hybrids of these strategies. Recent match analysis suggests a hybrid of the Priming Game, and the Back Game strategies may be interesting. Most of the well known AI software for playing backgammon is also designed without the doubling cube in play, which can significantly alter decision making. Looking at strategies for use of the doubling cube could also prove interesting.  |
| Reference URLs         | http://incompleteideas.net/book/bookdraft2018feb28.pdf https://cling.csd.uwo.ca/cs346a/extra/tdgammon.pdf  |
| Anticipated Outcomes   | An implementation of one or more computer players for backgammon to evaluate new strategy concepts (either with or without the doubling cube and Crawford rule).  |
| Requirements           | None  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | 	AI, Machine Learning, Backgammon  |
### Theme RP-2: Implementing efficient hash tables on GPUs
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Modern GPUs from both Nvidia and AMD offer enormous amounts of processing power, yet a number of algorithms are deemed unsuitable for computation on GPUs as they require random memory accesses, such as those required to insert and retrieve entries in hash tables. Various probing schemes lead to divergence, where some GPU cores are forced to wait for the worst-case number of probes, and in high density hash tables this can cause significant slowdowns. The student working on this project will investigate and implement various hashing algorithms and analyse their performance on modern GPUs.  |
| Reference URLs         |  https://www.researchgate.net/publication/211178395_Building_an_Efficient_Hash_Table_on_the_GPU |
| Anticipated Outcomes   | Implement a number of various hashing algorithms in CUDA and/or OpenCL and compare performance with various constraints. Compare the results to those in the thesis of Alcantara, particularly considering updates in GPU architectures since 2011.  |
| Requirements           | C/C++/CUDA/OpenCL Programming. We have NVidia GPUs available on NCC, though having access to your own GPU would likely be an advantage.  |
| Max Number of Students | 1  |
| Project Type           | L3  |
| Keywords               | 	CUDA, OpenCL, Hash Tables, Optimisation  |
### Theme RP-3: Exploring Aliquot Sequences with Markov Chains
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | An aliquot sequence is a sequence of positive integers, where each term is the sum of the proper divisors of the previous term. The sequence ends when you reach the number 1 (or 0), or you reach a repeating sequence. E.g. Perfect numbers such as 6 - the proper divisors are 1,2 and 3, which sum to 6. It is still an open problem as to whether all aliquot sequences eventually terminate (with a 1 or a repeating sequence), or whether a sequence can continue infinitely. The growth of these sequence is controlled by mathematical objects called drivers and guides, which regularly mutate. These mutations can be modelled using Markov Chains, and we can analyse the underlying directed graph. The theoretical results can be compared against the practical results which can be scraped from the factor database (factordb.com), and an algorithm can be devised to predict which open aliquot sequences should be the easiest to terminate.  |
| Reference URLs         | https://www.ams.org/journals/mcom/1975-29-129/S0025-5718-1975-0384669-X/S0025-5718-1975-0384669-X.pdf  |
| Anticipated Outcomes   | Build a theoretical model of Aliquot driver and guide mutations, and compare this with experimental findings. Using the theoretical model we can implement algorithms to attempt to determine expected sequence lengths, the maximum size of numbers to be factorised, and which open sequences might be easiest/hardest to terminate.  |
| Requirements           | Strong interest in mathematics and graph theory, and likely a passing interest in Integer Factorisation.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4 |
| Keywords               | 	Aliquot Sequence, Catalan's Conjecture, Markov Chains, Directed Graphs, Probability  |
### Theme RP-4: Reinforcement Learning for Team Based Card Games
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Reinforcement learning has been successfully used to learn to play board games such as backgammon through self-play. In this project we would like to apply a similar technique to card games, where players play in teams. AI has had much success in learning to play 2-player card game such as heads-up Texas hold\'em, but there has been less research into card games such as Bridge and Cribbage which are generally played in pairs. |
| Reference URLs         | http://www.ifaamas.org/Proceedings/aamas2019/pdfs/p16.pdf  |
| Anticipated Outcomes   | An implementation of an AI agent for playing a team based card game such as Cribbage or Bridge  |
| Requirements           | None  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | 	AI, Machine Learning, Card Games, Bridge, Cribbage  |

## Staff Proposer: Anne Reinarz
### <span style="color:red;">Theme AR-1: Wavelets and Tsunamis</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Models quantifying uncertainty for, e. g., earthquakes or tsunamis heavily depend on the size of their input parameter space. Here this input consists of topography data which naturally comes with a huge parameter space. We aim to reduce the dimensionality of the input topography data using a wavelet compression. Advantages of the wavelet approach include vanishing moments conserving the total mass of water in the simulation, as well as an inherent hierarchy allowing easy access to multilevel models.  |
| Reference URLs         |  Schwab, Mishra, Multi-level Monte Carlo finite volume methods for shallow water equations with uncertain topography in multi-dimensions (https://pdfs.semanticscholar.org/875d/d4c87b2f46ab48fbdf0b1b78ec48ce422ce0.pdf) Book: Cohen, Numerical Analysis of Wavelet Methods |
| Anticipated Outcomes   | A reduced bathymetry model, comparison in simulation results to existing machine learning approach  |
| Requirements           | Interest in Maths and C/C++|
| Max Number of Students | 2  |
| Project Type           |  L4 |
| Keywords               | 	Wavelets, parameterised problems  |
### Theme AR-2: Reduced Order Modeling
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Composite materials are notoriously difficult to model due to their fine-scale structure (on the order of 0.1 mm) and complex anisotropy. We use a reduced order model to create smaller problems that nevetheless retain important fine-scale information. This requires pre-computing basis functions, a task that is often performed in an offline step. Generally not much attention is given to the cost of the offline step. We try to find representative subdomains to compute on, vastly reducing the cost of this step.  |
| Reference URLs         | Yvon Maday, Einar M. RÃ¸nquist, A Reduced-Basis Element Method (https://link.springer.com/article/10.1023/A:1015197908587#citeas)  |
| Anticipated Outcomes   | An improved offline cost for the model  |
| Requirements           |  Knowledge of C++ and templates a plus |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | reduced order models, online-offline computation, domain decomposition  |
### Theme AR-3: UQ for Seismic
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In earthquake modeling the earth\'s crust is modeled as an elastic solid. Within this crust are fault planes, zones of weakness along which earthquakes often occur. We are interested in using data gathered during earthquakes to localise such faults. To do so we plan to extend an existing interface between the MIT UQ library MUQ and the ExaHyPE Engine and apply it to simulate Bayesian Inverse Problems for seismic applications. This requires two levels of parallelism: firstly parallelism in the foward model and secondly in the Markov chain.  |
| Reference URLs         | Bonnet, Inverse problems in elasticity (https://iopscience.iop.org/article/10.1088/0266-5611/21/2/R01)  |
| Anticipated Outcomes   | Extensions to a MUQ/ExaHyPE Interface, distribution of fault data  |
| Requirements           | C/C++, probability theory   |
| Max Number of Students |  3 |
| Project Type           | L3, L4  |
| Keywords               | 	Bayesian Inverse Problems, HPC  |

## Staff Proposer: Lei Shi
### Theme LS-1: Concept Map to Support Cognitive Behaviour and Behavioural Changes
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Concept Mapping has been proven to have a promising impact on learning. Some studies suggest that effective feedback, hyperlinks, expert templates, comparative strategies, etc. may support better learning behaviour. In this project, you will be developing and evaluating a mobile (iOS/Android) or web-based application providing concept mapping facilities that can help students learn more efficiently and effectively.  |
| Reference URLs         | https://doi.org/10.1145/3290605.3300258  |
| Anticipated Outcomes   | (1) a piece of software that can run on either mobile devices or web browsers; (2) a report on the evaluation of the software.  |
| Requirements           | (1) knowledge about Concept Map and User-Centred Design; (2) skills of software development (iOS/Android or HTML/JS/CSS, and database management).  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               |  	Concept Mapping, Comparative Strategy, Data Visualisation, Behavioural Patterns, Educational Tool, Software Development, Evaluation. |
### Theme LS-2: Adaptive Gamification for Learning
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Gamification, defined as the use of game elements in non-game contexts, is a widely used approach to enhancing learners’ engagement, motivation and learning gain in the educational environments. In this project, you will develop and evaluate a gamified educational system (mobile (iOS/Android) or web-based). More importantly, you will explore the effects of different game elements and mechanisms on different learners and implement design strategies to adapt gamification to suit individual user’s needs (e.g. gender, player type, current learning status and progress, etc.). |
| Reference URLs         |  https://en.wikipedia.org/wiki/Gamification https://www.researchgate.net/publication/324430336_Adaptive_Gamification_for_Learning_Environments |
| Anticipated Outcomes   | (1) a piece of software that can run on either mobile devices or web browsers; (2) a report on the evaluation of the software.  |
| Requirements           |  (1) knowledge about Gamification, Adaptation and User-Centred Design; (2) skills of software development (iOS/Android or HTML/JS/CSS, and database management). |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | 	Gamification, Adaptation, E-Learning, Education, Evaluation  |
### Theme LS-3: Interactive System for XAI
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Explainable AI (XAI) refers to methods and techniques in the application of Artificial Intelligence such that the results of the solution can be understood and trusted by humans. There is a strong need for quantifiable measurements used by actual humans to assess the interpretability of AI decisions. In this project, you will develop a novel, scalable web-based system that supports the quantifiable assessment of AI Explanations with humans.  |
| Reference URLs         |  https://en.wikipedia.org/wiki/Explainable_artificial_intelligence |
| Anticipated Outcomes   |  (1) a piece of software that can run on either mobile devices or web browsers; (2) a report on the evaluation of the software. |
| Requirements           | (1) knowledge about Explainable AI and User-Centred Design; (2) skills of software development (iOS/Android or HTML/JS/CSS, and database management).  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               |  	Explainable Artificial Intelligence (XAI), Software Development, Evaluation. |
### Theme LS-4: Games for Learning Machine Learning
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | At present, Machine Learning (ML) is among the most popular modules/courses in many undergraduate programmes in the globe. However, there are many challenges in learning ML. For example, (1) to start learning ML, it is important that a student has essential math knowledge including Equations, Functions, Graphs, Differentiation and Optimisation, Vectors and Vectors and Metrics, Statistics and Probability and so on; (2) ML processes and many of its algorithms are very complex and abstract, thus in need of good visualisations and explanations; and (3) students normally come with diverse background (knowledge, skills, cognitive preferences) such that the “one-size-fits-all” approach does not really work. In this project, you will develop a digital game to help undergraduate students learn ML. It could be either web-based or mobile-based application. You will also evaluate the application with real users.  |
| Reference URLs         | http://www.savie.ca/sage/articles/940_300027-kiili-2005.pdf  |
| Anticipated Outcomes   | (1) a piece of software that can run on either mobile devices or web browsers; (2) a report on the evaluation of the software.  |
| Requirements           | (1) knowledge about Game Design and User-Centred Design (desirable); (2) Knowledge about education or educational psychology (desirable); (3) programming skills (iOS/Android or HTML/JS/CSS, and database management).  |
| Max Number of Students | 2  |
| Project Type           | L3, L4  |
| Keywords               | Game, Software Development, Evaluation, Machine Learning.  |
### Theme LS-5: Towards Building Trust in AI through Visualisation Approach
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Artificial Intelligence (AI) systems have achieved great successes in supporting human decision-making. However, they are often opaque and operate in a black box, and so end-users don’t know how decisions are being made thus lacking trust on them, which hinders broad adoption of AI systems. In this project, you will implement and evaluate different visualisations of the output of Machine Learning (ML) algorithms, from the end-user point of view. For example, you could explore how instance representations and spatial layouts may effect on end-users’ trust, and what are the best visualisation strategies to increase their trust in the output of the ML algorithms. |
| Reference URLs         |  	https://dl.acm.org/doi/pdf/10.1145/3377325.3377480 https://www.research.ibm.com/artificial-intelligence/trusted-ai/ |
| Anticipated Outcomes   | (1) knowledge about design principles of AI systems and ML algorithms (desirable); (2) programming skills of web-based system development (some visualisation libs might be useful, e.g., d3.js).  |
| Requirements           | 	Explainable AI (XAI), Machine Learning, Web-based System, Visualisation, Trust in AI.  |
| Max Number of Students |  2 |
| Project Type           |  L3, L4 |
| Keywords               |   |

## Staff Proposer: Craig Stewart
### Theme CS-1: An Enhanced Tutor
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	This project will involve the use of AI to inform an ‘enhanced’ digital tutor. Educational systems generally focus on a closed corpus of information as set by a teacher, the result of which is that the learner is limited by the teacher’s own knowledge. Open Hypermedia Systems, are systems that remove this artificial boundary, but lessons made using such a system can be extremely broad and can lose their focus. This project will involve you to creating an AI system to identify the semantics and meaningful content for a lesson. The training data identified will need to create a critical friend (the enhanced tutor)) for the student in that lesson.  |
| Reference URLs         | (1) Luckin, R., & Cukurova, M. (2019). Designing educational technologies in the age of AI: A learning sciences‐driven approach. British Journal of Educational Technology, 50(6), 2824-2838. (2) Somyürek, Sibel. (2015). The New Trends in Adaptive Educational Hypermedia Systems. International Review of Research in Open and Distance Learning. 16. 221-241. 10.19173/irrodl.v16i1.1946.  |
| Anticipated Outcomes   |  A Proof of Concept for the enhanced tutor which can deliver (or support delivery of) a lesson in a given subject topic. The topic content needs to be gathered from an Open corpus of data. |
| Requirements           |   |
| Max Number of Students |  3 |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme CS-2: Developing a collaborative intelligence with the EThOS collection of the British Library
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  This project will combine human and digital knowledge by testing machine learning approaches to mining and analysing the EThOS repository. This repository contains over 500,000 theses many containing unique, unreported research findings. For example: ageing generates 24,779 theses, migration generates 6857 theses and homelessness generates 279 theses. The project will utilise unsupervised machine learning models (such as Clustering and Natural Language Processing) with further insight gained from Deep Learning techniques to draw unseen and unknown connections from the EThOS corpus that will highlight and guide the study of societal challenges. |
| Reference URLs         | Montgomery, C. (2019). Surfacing ‘Southern’ perspectives on student engagement with internationalisation: doctoral theses as alternative forms of knowledge. Journal of Studies in International Education. Vol. 23(1) 123 –138 https://doi.org/10.1177/1028315318803743  |
| Anticipated Outcomes   | The project will trial the development of a dashboard or hub which will enable analysis using search strings and will more accurately draw together theses in accessible formats.  |
| Requirements           |   |
| Max Number of Students | 2  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme CS-3: iLife: your data in your hands
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Data is often compared to oil in terms of monetisation, however the people that this data is extracted from are often not aware of this. We give out personal data either inadvertently or deliberately to 100s of companies who may subsequently pass this on to other companies without our knowledge. This project aims to explore how best to monitor and control this flow of information within a personal area network, utilising intelligent agents to negotiate with and inform the data owner.  |
| Reference URLs         | (1) Daronnat, S., Azzopardi, L., Halvey, M., & Dubiel, M. (2019). Human-agent collaborations: trust in negotiating control. CHI 2019. (2) Kot, M. and Leszczyński, G. (2020), \"The concept of intelligent agent in business interactions: is virtual assistant an actor or a boundary object?\", Journal of Business & Industrial Marketing, Vol. ahead-of-print No. ahead-of-print. https://doi.org/10.1108/JBIM-10-2018-0291  |
| Anticipated Outcomes   | An intelligent agent able to collate personal data from various sources and inform the data owner of usage scenarios whilst regulating permissions.  |
| Requirements           |   |
| Max Number of Students |  3 |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme CS-4: Tamagotchi: from egg to avatar
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Novel interaction mechanisms & modalities are being enabled with the creation of more immersive and ubiquitous Augmented Reality interfaces. AR avatars are already being created for to support exploration of an augmented world. This project seeks to explore the current state of the art from a UX, HCI and affective computing point of view. Issues such as visualisation, personalisation (for example through the use of the Watson Personality Insights service), development, and security will need to be addressed.  |
| Reference URLs         |  Yoon, B., Kim, H. I., Lee, G. A., Billinqhurst, M., & Woo, W. (2019, March). The Effect of Avatar Appearance on Social Presence in an Augmented Reality Remote Collaboration. In 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR) (pp. 547-556). IEEE. |
| Anticipated Outcomes   | The output will be an extension of the research into best practice validated via the creation of an augmented ‘pet’ that the user can interact with constantly.  |
| Requirements           |   |
| Max Number of Students |  2 |
| Project Type           | L3, L4  |
| Keywords               |   |
### Theme CS-5: Cultural Artefacts in eLearning
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  This project will examine an extant system of adaptive interfaces which caters for cultural diversity in education, instead of presenting a homogeneous delivery for the whole student population. The project will utilise an eLearning system based on the framework for cultural adaptation, CAE (Cultural Artefacts in Education), grounded in Marcus & Gould’s web model, as well as its source, Hofstede’s indexes. This system will be expanded to implement the CAE-F ontology as well as expanding these cultural personalisation aspects using the Watson Personality Insights service. |
| Reference URLs         | Scotton, J., Stewart, C., & Cristea, A. I. (2011). ADE: the adaptive display environment for adaptive hypermedia. In Proceedings of the ACM Hypertext 2011 International Conference, Eindhoven, The Netherlands (pp. 2269-2295).  |
| Anticipated Outcomes   | Updated and expanded eLearning system (ADE+CAE)  |
| Requirements           |   |
| Max Number of Students |  3 |
| Project Type           | L3, L4  |
| Keywords               |   |
### Theme CS-6: Cultural Sentiment Analysis in a Social World
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Sentiment analysis is a well-established research area, as is applying this research to gather insights over a social media landscape (YouTube, Facebook, Twitter, TikTok etc …). However in these studies the world is normally considered as a single homogeneous organism. Cultural studies prove that this is clearly not the case. This project will examine social media data utilising a cultural framework (such as those by Hofstede, Schwartz and Trompenaar) to determine the congruity of the data to these frameworks. In so doing a sentiment weighting can be created to better inform current sentiment analysis research.  |
| Reference URLs         | Kennedy, H. (2012). Perspectives on sentiment analysis. Journal of Broadcasting & Electronic Media, 56(4), 435-450.  |
| Anticipated Outcomes   | A dashboard that will gather social data, organise it by culture, apply a cultural weight to the subsequent sentiment analysis.  |
| Requirements           |   |
| Max Number of Students | 2  |
| Project Type           |  MISCADA, L3, L4 |
| Keywords               |   |

## Staff Proposer: Iain Stewart
### Theme IAS-1: Colouring Nodes of a Decentralized Network
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Graph colouring is a fundamental problem in Computer Science; it has a number of applications and is often mentioned as an archetypal NP-hard problem. The importance of graph colouring means that there have been a wide range of heuristic algorithms developed so as to secure good, if not optimal, colourings of graphs. Heuristic methodologies employed have included greedy approaches, tabu search, ant colony optimization, chaotic ant swarm, honey bee optimization and firefly algorithms, along with many others. Most of these methodologies are such that global knowledge of the graph to be coloured is assumed.<br><br>However, suppose that we wish to colour the nodes of a decentralized network where each node (representing a computing device) only has local knowledge of itself and (the colours of) its neighbours. Decentralized colouring has applications in wireless sensor networks, where each sensor node only has local network knowledge, in relation to control, distributed resource management, wireless channel allocation and wakeup scheduling.<br><br>In [1], a decentralized colouring algorithm is developed. This algorithm uses only local knowledge and can operate either synchronously (where all nodes update their colours at the same time) or asynchronously (where nodes update their colours at different times). The algorithm from [1], called SDGC, is empirically compared with another distributed graph colouring called FrogSim from [2,3] on a range of benchmark data-sets. This project is to replicate the research in [1] and to possibly extend it. |
| Reference URLs         |  [1] S.V. Galán, Simple decentralized graph coloring, Computational Optimization and Applications 66 (2017) 163-185 (URL: https://doi.org/10.1007/s10589-016-9862-9)<br>[2] H. Hernández and C. Blum, Distributed graph coloring: an approach based on the calling behavior of Japanese tree frogs, Swarm Intelligence 6 (2012) 117-150 (URL: https://doi.org/10.1007/s11721-012-0067-2)<br>[3] H. Hernández and C. Blum, FrogSim: distributed graph coloring in wireless ad hoc networks, Telecommunication Systems 55 (2014) 211-223 (URL: https://doi.org/10.1007/s11235-013-9776-0) |
| Anticipated Outcomes   |  The SDGC algorithm from [1] will be implemented, possibly along with FrogSim from [2,3] and other novel evolutionary algorithms, and evaluated on the data-sets used in [1], possibly along with some other real-world data-set corresponding to a specific application of graph colouring in a decentralized network. |
| Requirements           | There are no special requirements beyond a basic understanding of algorithmic graph theory.  |
| Max Number of Students |  1 |
| Project Type           | L3, L4  |
| Keywords               |  Heuristic methods, greedy algorithms, evolutionary algorithms, distributed graph colouring. |
### Theme IAS-2: Influence Spreading in Networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In a social network, many applications require the discovery of nodes of influence and how these nodes of influence actually exert an influence on the other nodes in the network. Lots of centrality indices have been proposed such as degree centrality, betweenness centrality and closeness centrality. Usually, the influence of single nodes in a network is considered rather than the influence of sets of nodes. This latter consideration makes things much more difficult and it has been shown that finding the optimal multiple influence spreaders is NP-hard. Nevertheless, there have been various attempts made to identify optimal multiple influence spreaders based around the use of, for example, percolation, graph colouring and node degrees. The obvious approach is just to select the best however-many single influence spreaders as the set of multiple influence spreaders; however, this can lead to redundancy as single influence spreaders tend to have a significant overlap in terms of their influence.<br><br>In [1], a heuristic clustering algorithm is proposed to obtain multiple influence spreaders. In this algorithm, nodes are classified into different clusters based on a specific similarity index, where the number of clusters equals the number of multiple influence spreaders. Then the "centre" nodes in the clusters are selected as the multiple influence spreaders, when the heuristic clustering process is finally stable. This project is to replicate the experimentation in [1] and to empirically examine algorithms that find multiple influence spreaders. This will mean the implementation of algorithms from [1] (and other papers too) and the empirical evaluation of these algorithms on the data-sets used in [1] (and possibly on other data-sets too).  |
| Reference URLs         | [1] Z.-K. Bao, J.-G. Liu and H.-F. Zhang, Identifying multiple influential spreaders by a heuristic clustering algorithm, Physics Letters A 381 (2017) 976-983 (URL: https://doi.org/10.1016/j.physleta.2017.01.043)  |
| Anticipated Outcomes   | A suite of multiple influence spreader algorithms will be implemented and evaluated on various real-world and synthetic data-sets. The basic aim will be to replicate (and possibly extend) the results from [1].  |
| Requirements           | There are no special requirements beyond a basic understanding of algorithmic graph theory.  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | Social networks, influence spreading, heuristic methods.  |
### Theme IAS-3: Positive Influence Dominating Sets in Social Networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In a social network, it is important to find nodes that exert influence on others within the network. Moreover, it is also important to find (small) sets of nodes that can exert influence over the whole network. The notion of what constitutes "influence" is variable and so one would wish for a methodology that allowed the notion of "influence" to be fluid. One notion of influence is supplied by a dominating set: a dominating set D in a network is a set of nodes with the property that every node in the network but not in D is adjacent to at least one node of D. Finding a dominating set of smallest size in a network is well-known to be NP-hard. Another notion of influence comes from a positive influence dominating set which is a set D of nodes so that every node not in D has at least 50% of its neighbours in D.<br><br>In [1], four heuristics were developed so as to find positive influence dominating sets of smallest size in a network and these methods were compared against each other on various benchmark social networks. This project is to replicate the research undertaken in [1] and to extend it.  |
| Reference URLs         | [1] F.N. Abu-Khzam and K. Lamaa, Efficient heuristic algorithms for positive-influence dominating set in social networks, Proc. of IEEE INFOCOM Workshops (2018) 610-615 (URL: https://doi.org/10.1109/INFCOMW.2018.8406851)  |
| Anticipated Outcomes   | The heuristic algorithms from [1] will be implemented and evaluated on data-sets considered in that paper. The basic aim will be to replicate the results from [1]. There is considerable scope to extend the research in [1] by, for example: implementating other methodologies and comparing them; parameterizing the notion of a positive influence dominating set by varying the fraction of neighbours required from the set D (or by coming up with other conditions); and varying the notion of a dominating set (some suggestions can be found in [1]).  |
| Requirements           | There are no special requirements beyond a basic understanding of algorithmic graph theory.  |
| Max Number of Students | 1  |
| Project Type           |  L3, L4 |
| Keywords               | 	Social networks, influence spreading, heuristic methods, dominating sets.  |
### <span style="color:red;">Theme IAS-4: Simulating Data Centre Networks</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | There is a drive to build bigger and bigger data centres, with the data centre network (DCN) being the main limiting factor. The DCN is the network of switches and servers that provides the communications infrastructure of the data centre. Server-centric DCNs are DCNs specificially designed to host the next generation of data centres and are undergoing considerable research. Server-centric DCNs, where routing is handled in software by the servers, have certain scalability advantages when compared with the current switch-centric DCNs, where routing is handled by switches and their associated routing tables. Whatever the paradigm, DCN designs need to be validated by simulation prior to construction; it is not feasible to build and test a network of hundreds of thousands of servers and switches. This validation involves properties relating to, for example, scalability, latency, wiring complexity, bisection bandwidth, connectivity, throughput, routing algorithms, fault tolerance, energy efficiency, costs and packaging, reliability, security, and agility, and across a range of traffic patterns.<br><br>Professor Stewart and his research collaborators have developed INRFlow [1,2]: a tool specifically designed to simulate server-centric DCNs (INRFlow is written in C). This project is concerned with using and developing INRFlow in order to evaluate server-centric DCNs. There are various potential directions for this project.<br><br>Within the literature, often evaluations of DCN designs are somewhat lightweight in that not many properties or traffic patterns are studied; that is, evaluation is often at the proof-of-concept level. There is much scope to undertake more detailed comparative evaluations of the various existing server-centric DCN designs.<br><br>While INRFlow is a powerful tool, there are many modes of evaluation yet to be implemented. There is much scope to extend the functional capability of INRFlow and so enhance server-centric DCN evaluations. For example, there is as yet no mechanism by which energy usage of a DCN can be evaluated within INRFlow.  |
| Reference URLs         |  [1] Interconnection Networks Research Flow-level (INRFlow) Extensible Framework (URL: https://bitbucket.org/alejandroerickson/inrflow and also https://gitlab.com/ExaNeSt/inrflow)<br>[2] J. Navaridas, J.A. Pascual, A. Erickson, I.A. Stewart and M. Luján, INRFlow: An interconnection networks research flow-level simulation framework, Journal of Parallel and Distributed Computing, 130 (2019) 140-152 (URL: https://doi.org/10.1016/j.jpdc.2019.03.013)<br>[3] T. Chen, X. Gao and G. Chen, Guihai, The features, hardware, and architectures of data center networks: a survey, Journal of Parallel and Distributed Computing 96 (2016) 45-74 (URL: https://doi.org/10.1016/j.jpdc.2016.05.009)<br>[4] A. Erickson, I.A. Stewart, J. Navaridas and A.E. Kiasari, The stellar transformation: from interconnection networks to datacenter networks, Computer Networks 113 (2017) 29-45 (URL: https://doi.org/10.1016/j.comnet.2016.12.001)<br>plus others from Professor Stewart's web-page. |
| Anticipated Outcomes   |  Outcomes might include: the coding of various server-centric DCNs and a range of experimental evaluations of them using INRFlow; the programming of additional functionalities within INRFlow; and perhaps (at a more advanced level) the design and coding of new DCNs for study using INRFlow. It is highly possible that a successful project might lead to publication. |
| Requirements           | Programming skills in C. DCNs are abstracted as graphs and consequently basic knowledge of and interest in algorithmic graph theory are required.  |
| Max Number of Students | 3  |
| Project Type           | L4  |
| Keywords               | Server-centric data centre networks, simulation, INRFlow.  |
### Theme IAS-5: Solving Reconfiguration Problems using Heuristic Methods
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | A reconfiguration graph is, roughly speaking, a graph obtained from the feasible solutions to some problem on some fixed structure. For example, take a graph G and consider all the proper colourings of its vertices using 4 colours (so that two adjacent vertices have different colours). The corresponding reconfiguration graph has a vertex for every 4-colouring of G and there is an edge joining two 4-colourings if the colourings are identical except for 1 vertex. Alternatively, the reconfiguration graph of Rubik's cube has a vertex for every setting of Rubik's cube and there is an edge joining two settings if one can be obtained from the other by a single twist of the cube. The study of reconfiguration graphs that emerge in this way is currently an active topic of research.<br><br>Here are some typical results in relation to reconfiguration graphs. Consider the problem of deciding whether given a structure and two vertices in its reconfiguration graph (with respect to some problem), there is a path in the reconfiguration graph from one vertex to the other, i.e., the reachability problem. It has been proven that the reachability problem for reconfiguration graphs of 4-colourings of a graph is PSPACE-complete, whereas the reachability problem for reconfiguration graphs of 3-colourings of a graph is solvable in polynomial-time. Consider the problem of computing the diameter of some reconfiguration graph (if it is connected). It has been shown that in the 3-colouring reconfiguration graph of some graph G, the diameter of each connected component is O(\|V(G)\|2) but that in the 4-colouring reconfiguration graph of some graph G, the diameter of each connected component can be super-polynomial in \|V(G)\|.<br><br>This project is to investigate the use of heuristic methods, e.g., evolutionary algorithms, to answer questions as regards reconfiguration graphs. There exist similar concepts to reconfiguration graphs such as token swapping graphs and sorting networks which can form the basis for similar studies. All details of basic concepts and numerous recent results are given in [1] whereas [2] focusses more on sorting networks. A web survey [3] provides access to lots of papers on reconfiguration problems.  |
| Reference URLs         | [1] N. Nishimura, Introduction to reconfiguration, Algorithms 11(4) (2018) article 52 (URL: https://doi.org/10.3390/a11040052)<br>[2] D. Kim, Sorting on graphs by adjacent swaps using permutation groups, Computer Science Review 22 (2016) 89-105 (URL: https://doi.org/10.1016/j.cosrev.2016.09.003)<br>[3] T. Ito and A. Suzuki, Web Survey on Combinatorial Reconfiguration (URL: http://www.ecei.tohoku.ac.jp/alg/coresurvey)  |
| Anticipated Outcomes   | There is massive scope within this project as there are so many different basic problems to consider and also properties of reconfiguration graphs, token swapping networks and sorting networks to establish. Any chosen project should look to contribute useful information to those interested in this general research area, e.g., although we can have super-polynomial diameter 4-colouring reconfiguration graphs (as described above), can we obtain experimental evidence that shows that if we concern ourselves only with some restricted class of graphs then the diameter is much less?  |
| Requirements           | There are no special requirements beyond a basic understanding of algorithmic graph theory.  |
| Max Number of Students |  1 |
| Project Type           | L3, L4  |
| Keywords               | Heuristic methods, evolutionary algorithms, reconfiguration problems, token swapping, sorting networks.
  |
### Theme IAS-6: Using Cuckoo Search to Colour Graphs
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Graph Colouring is a fundamental problem in Computer Science; it has a number of applications and is often mentioned as an archetypal NP-hard problem. The importance of graph colouring means that there have been a wide range of heuristic algorithms developed so as to secure good, if not optimal, colourings of graphs. Heuristic methodologies employed have included greedy approaches, tabu search, ant colony optimization, chaotic ant swarm, honey bee optimization, firefly algorithms and many others.<br><br>In [1], the cuckoo search algorithm has recently been employed to colour graphs. This evolutionary algorithm is inspired by the strategy followed by a cuckoo when it lays its eggs in other birds' nests. In [1], an implementation of the cuckoo search algorithm was applied to a wide range of benchmark graphs and directly compared with two other evolutionary graph colouring algorithms that are derived from the behaviour of bees and ants. This project is to replicate and hopefully extend the research in [1].  |
| Reference URLs         |  [1] S. Mahmoudi and S. Lotfi, Modified cuckoo optimization algorithm (MCOA) to solve graph coloring problem, Applied Soft Computing 33 (2015) 48-64 (URL: https://doi.org/10.1016/j.asoc.2015.04.020) |
| Anticipated Outcomes   | The cuckoo search algorithm from [1] will be implemented, possibly along with other novel evolutionary algorithms, and evaluated on the data-sets used in [1], possibly along with some other real-world data-set corresponding to a specific application of graph colouring. Note that it is not entirely straightforward to arrange things so that the graph colouring problem is amenable to attack by the cuckoo search algorithm. It is possible that a successful project might lead to publication.  |
| Requirements           | 	There are no special requirements beyond a basic understanding of algorithmic graph theory.  |
| Max Number of Students |  1 |
| Project Type           | L3, L4  |
| Keywords               | 	Evolutionary algorithms, heuristic methods, graph colouring.  |
### <span style="color:red;">Theme IAS-7: Embedding Virtual Machines in Data Centre Networks</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Data centre providers rent out portions of their data centres to users. This involves embedding the users' virtual machines within the data centre network (DCN) so as to secure quality-of-service guarantees. Virtual machines often come in the form of virtual networks with a basic "star" graph forming a common such network (where a central "root" switch is connected directly to a number of "leaf" servers). The data centre provider wants to embed as many virtual networks as possible so as to optimize revenue but so that quality-of-service guarantees can be met. The basic virtualization problem can be abstracted as a graph embedding problem where the graphs have weights (reflecting numerical parameters of the underlying networks). Two illustrative existing virtualization methodologies are Oktopus [1] and SecondNet [2].<br><br>Server-centric DCNs have been proposed as a paradigm to support the next generation of DCNs as there are problems regarding, for example, scalability for the switch-centric DCNs that form the current paradigm of production DCNs. Unfortunately, Oktopus and SecondNet cater only for switch-centric DCNs. However, a virtualization methodology for server-centric DCNs has been sketched in [3]. This project would be to flesh out the skecth in [3] and develop a tool to enable virtualization in server-centric DCNs.  |
| Reference URLs         | [1] H. Ballani, P. Costa, T. Karagiannis and A. Rowstron, Towards predictable datacenter networks, Proc. of ACM SIGCOMM (2011) 242-253 (URL: https://doi.org/10.1145/2018436.2018465)<br>[2] C. Guo, G. Lu, H.J. Wang, S. Yang, C. Kong, P. Sun, W. Wu and Y. Zhang, SecondNet: a data center network virtualization architecture with bandwidth guarantees, Proc. of ACM Conf. on Emerging Networking Experimentsand Technology article no. 15 (12 pages), 2010 (URL: https://doi.org/10.1145/1921168.1921188)<br>[3] I.A. Stewart and A. Erickson, The influence of data center usage on symmetry in data center network design, Journal of Supercomputing 74 (2018) 2276-2313.(URL: https://doi.org/10.1007/s11227-017-2217-1)  |
| Anticipated Outcomes   |  Outcomes might include: an implementation of the virtualization methodology in [3] for the DCNs HCN and BCN, as described in [1]; a more general tool which will allow the virtualization methodology of [3] to be applied to other DCNs; adaptions of Oktopus and SecondNet to server-centric DCNs; and experimentation with a more general tool so as to evaluate server-centric DCNs with respect to their capacity for virtualization. This will be a challenging project and will involve initially extending the description of the virtualization methodology in [3] prior to implementation. However, it is highly possible that a successful project might lead to publication; moreover, there is lots of scope to make a contribution. |
| Requirements           | As mentioned above, DCNs are abstracted as graphs and consequently basic knowledge of and interest in algorithmic graph theory is required, as well as good programming skills.  |
| Max Number of Students | 1  |
| Project Type           |  L4 |
| Keywords               | Server-centric data centre networks, virtualization.  |
### Theme IAS-8: Wireless Recharging in Wireless Sensor Networks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  The field of recharging wireless sensor networks (WSNs) through wireless energy transmission has recently emerged. In one scenario, a mobile charger (MC) traverses a circular region, starting from the centre where an energy source resides, that contains randomly distributed static sensors and wirelessly charges them. In order to do this, the MC needs to travel to a sensor so that it is sufficiently close to enable wireless recharging. Of course, the sensors are sending messages amongst each other and so as time goes by, a sensor\'s available energy diminishes; moreover as the MC progresses, its own energy diminishes too. The aim is to devise a traversal strategy for the MC, knowing the distribution of the sensors and their message transmissions, so as to recharge sensors so that no sensor finds itself without enough energy to send its messages.<br><br>An energy-charging model has been derived in [1] where the goal is to achieve highly efficient recharging, given some messaging (and so energy) requirements of the sensors. The basic recharging (optimization) problem has been shown in [1] to be NP-hard, even when full knowledge of the whole scenario is available. Various movement strategies for the MC have been considered in [1] and empirically evaluated. This project is to build a tool to simulate basic wireless recharging strategies in WSNs and to devise and evaluate various strategies. The project will replicate and possibly extend the research in [1]. |
| Reference URLs         | [1] C.M. Angelopoulos, S. Nikoletseas, T.P. Raptis, C. Raptopoulos and F. Vasilakis, Improving sensor network performance with wireless energy transfer, International Journal of Ad Hoc and Ubiquitous Computing 20(3) (2015) 159-171 (URL: https://doi.org/10.1504/IJAHUC.2015.073169)  |
| Anticipated Outcomes   | Outcomes might include: a software tool to evaluate wireless recharging strategies; a library of strategies and their evaluations; and an extension to and refinement of the basic recharging model/problem from [1]. It is possible that a successful project might lead to publication.  |
| Requirements           | 	Nothing in particular.  |
| Max Number of Students |  1 |
| Project Type           | L3  |
| Keywords               | 	Wireless sensor networks, wireless recharging optimization, simulation.  |
### Theme IAS-9: Applying Heuristic Methods to Solve Hard Problems
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  [This is a general theme under which projects can be developed with Professor Stewart; for some concrete versions, see Professor Stewart's other projects.]<br><br>Computationally hard problems, usually defined as those problems the solution of which is NP-hard, cannot be efficiently solved exactly unless P = NP. Many of them are combinatorial optimization problems where we are looking to find the minimum or maximum value of some property, e.g., the graph colourability problem, the graph independent set problem, the travelling salesman problem, the knapsack problem, the longest path in a graph problem, and so on. In practice, we generally work with heuristic algorithms that give approximate solutions or work well a lot of the time<br><br>There is a vaste range of heuristic algorithms available many of which are evolutionary algorithms; that is, inspired by nature, e.g., genetic algorithms, ant colony optimization, particle swarm algorithms, artificial bee colony algorithms, cuckoo search, firefly algorithms, ..., the list is endless. Moreover, the areas of research and scientific journals dedicated to the use and development of these algorithms with two such journals being Soft Computing and Applied Soft Computing.<br><br>For a project within this theme, a student should find a (recent) paper in a journal such as the two mentioned and meet with Professor Stewart to discuss a possible project around the paper. At the least, the project would be to implement the algorithms within the paper and replicate the results obtained. |
| Reference URLs         | [1] Soft Computing, Springer (URL: https://link.springer.com/journal/500)<br>[2] Applied Soft Computing, Elsevier (URL: https://www.journals.elsevier.com/applied-soft-computing)  |
| Anticipated Outcomes   | The implementation of algorithms within a chosen paper and a replication of the results from the paper together with, hopefully, an extension of the implementations or implementations of other heuristic algorithms.  |
| Requirements           | Nothing in particular beyond programming competency and a basic understanding of the algorithms used in artificial intelligence search.  |
| Max Number of Students |  10 |
| Project Type           | L3, L4  |
| Keywords               |  Artificial intelligence search, heuristic algorithms, evolutionary algorithms. |

## Staff Proposer: Donald Sturgeon
### Theme DS-1: Named Entity Disambiguation using Knowledge Graphs
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Named Entity Disambiguation is an important task in Natural Language Processing, associating strings in a document (e.g. 'London') with particular entities in a knowledge base (e.g. representing London (the city in the UK), vs London (the city in Ontario)). Graph-based approaches - often based on linking patterns extracted from large publicly available systems such as Wikipedia - have recently been shown to be effective in performing this task. This project would involve implementing and evaluating the procedures described in the papers referenced below, and/or extending these to include additional information not directly accounted for in knowledge graphs based purely on link structure, such as geographical and temporal information. |
| Reference URLs         |  https://aclweb.org/anthology/papers/K/K16/K16-1025/ https://www.aclweb.org/anthology/N15-1026 |
| Anticipated Outcomes   | Implementation and evaluation of existing methods with possible further development.  |
| Requirements           | Interest in Natural Language Processing  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | 	NLP; NER; NED  |
### Theme DS-2: OCR Post-correction through Text Reuse Identification
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  In certain domains - such as historical written and printed works - Optical Character Recognition involves recognition of multiple documents whose contents are not identical, but nevertheless contain high degrees of overlap. This property can potentially be leveraged to greatly increase recognition accuracy as a post-correction task by identifying and aligning similar sections of text, then using these alignments to infer and correct probable errors. The goal of this project is to develop and evaluate the effectiveness of this approach. |
| Reference URLs         | http://www.ccs.neu.edu/home/dasmith/infect-bighum-2013.pdf http://www.ep.liu.se/ecp/133/010/ecp17133010.pdf  |
| Anticipated Outcomes   | Development and evaluation of techniques against a baseline, and a tool to perform unsupervised post-correction on arbitrary collections of OCR output.  |
| Requirements           | Interest in Natural Language Processing  |
| Max Number of Students |  3 |
| Project Type           | L3, L4  |
| Keywords               | NLP; OCR  |
### Theme DS-3: Interactive analysis and visualisation of TEI documents
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In humanities computing, an XML format maintained by the Text Encoding Initiative (TEI) provides a standard mechanism for representing written materials - such as historical documents - together with a wide variety of associated metadata and semantic annotation. Due to the complexity of the standard and substantial degree of freedom in how texts are marked up in accordance with it, processing materials originating from arbitrary sources is non-trivial. This project implements a web-based user interface for displaying and navigating arbitrary TEI encoded texts, and producing and appropriately visualising summary data relevant to the data present in the chosen texts. The interface may also provide editing functionality to modify or refactor TEI documents.  |
| Reference URLs         | https://teibyexample.org/ https://wiki.tei-c.org/index.php/Samples_of_TEI_texts https://academic.oup.com/dsh/article/24/3/281/968658  |
| Anticipated Outcomes   | Software to interactively present and analyze arbitary TEI texts.  |
| Requirements           |  Familiarity with Javascript; interest in visualisation. |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               |  Text processing, digital humanities, visualization |
### Theme DS-4: Using character compositionality to improve Chinese NER
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Named Entity Recognition (NER) is an important task in natural language processing. In contrast to alphabetic languages like English, Chinese is written using a large number of distinct character types, many of which are composed of subcomponents which convey some degree of semantic content. In addition, written Chinese does not use spaces or other delimiters to explicitly indicate boundaries between words; together these factors present challenges and opportunities specific to Chinese NER. This project involves implementing and evaluating approaches to the Chinese NER task, using conditional random fields and/or LSTM, incorporating information about character decomposition.  |
| Reference URLs         | https://arxiv.org/pdf/1910.11470.pdf http://ir.ia.ac.cn/bitstream/173211/19944/1/13%E8%91%A3%E4%BC%A0%E6%B5%B7Character-Based%20LSTM-CRF%20with%20Radical-Level%20Features%20for%20Chinese%20Named%20Entity%20Recognition.pdf  |
| Anticipated Outcomes   | Implementation and evaluation of NER system using character compositionality.  |
| Requirements           | Machine learning and/or deep learning; interest in natural language processing.  |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               | Chinese; NER; NLP  |

### Theme DS-5: Unsupervised authorship clustering
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Unsupervised clustering of written materials by probable author has many applications, both historical (e.g. in premodern literature where authorship and authors are often unknown or disputed) and contemporary (e.g. connecting authors of multiple pieces of user-generated content, such as online reviews or social media posts). This project will implement and evaluate multiple strategies for linking and clustering documents by authorship. It may involve reproducing and supplementiing the results of the paper by Kocher and Savoy (linked below), e.g. by evaluation on additional domains, using a wider range of natural languages than the two used in that paper, and/or developing and evaluating additional metrics of authorship similarity.  |
| Reference URLs         | https://academic.oup.com/dsh/article/34/1/189/5032370 https://petsymposium.org/2012/papers/hotpets12-6-yelp.pdf  |
| Anticipated Outcomes   | Implementing a system for evaluating a range of authorship clustering algorithms; evaluation of these across a range of corpora and natural languages.  |
| Requirements           | Familiarity with machine learning; interest in natural language processing  |
| Max Number of Students |  3 |
| Project Type           | L3, L4  |
| Keywords               | NLP, digital humanities, authorship  |


## Staff Proposer: Ehsan Toreini
### <span style="color:red;">Theme ET-1: Acoustic Side Channel Attack on Historic Enigma Machine with deep learning</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Side channel attacks focus on exploiting the physical leakages of the system that executes the cryptographic operations. In our attack scenario, acoustic side channel attacks infer the text being typed by analysing the acoustic emanations of keystrokes. These attacks has already been implemented in regular and mobile keyboards. In this topic, you will have access to the recording of an actual historic enigma machine and implement a machine learning attack on these recording. |
| Reference URLs         | Keyboard acoustic emanations: https://ieeexplore.ieee.org/abstract/document/1301311?casa_token=35jBqvNGZqcAAAAA:H_vfZI3GZDtw9ONJiQ5plUUwhyMD59AHtn5isFplO9S9ufyg0OiSa2kXVENstsc2PCtXuwoQ<br>Keyboard acoustic emanations revisited: https://dl.acm.org/doi/abs/10.1145/1609956.1609959<br>A Sound for a Sound: Mitigating Acoustic Side Channel Attacks on Password Keystrokes with Active Sounds: https://link.springer.com/chapter/10.1007/978-3-662-54970-4_21  |
| Anticipated Outcomes   |  (1) Through analysis of acoustic side channel attacks and the countermeasures against them. (2) Implementation of efficient attack on acoustic recording of an original historic enigma machine keystrokes. (3) Possibly design of a novel attack scenario on the enigma recordings. |
| Requirements           | Knowledge of machine learning, knowledge of signal processing   |
| Max Number of Students | 2  |
| Project Type           | L4  |
| Keywords               |  	acoustic, cyber security, side channel attack |
### <span style="color:red;">Theme ET-2: Machine Learning based attack on Unclonable Physical Characteristics</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Physical objects carry a unique feature that makes them traceable and unclonable, a.k.a. "Physical Unclonable Functions" in security literature. These characteristics are theoretically secure; however, if an attacker obtains enough samples of the physical object, they can train a machine learning model to learn the unique features. Regular paper sheet carry a unique texture pattern that makes them distinguishable from each other, too. In this project, you will implement a machine learning model with the purpose to distinguish the photos taken from regular paper sheet surface from each other without knowing the unique texture patterns. |
| Reference URLs         | Security Attacks on Physically Unclonable Functions and Possible Countermeasures: https://link.springer.com/chapter/10.1007/978-3-319-76804-5_5<br>Deep face recognition using imperfect facial data: https://www.sciencedirect.com/science/article/pii/S0167739X18331133<br>Texture to the Rescue: Practical Paper Fingerprinting based on Texture Patterns: https://arxiv.org/pdf/1705.02510.pdf  |
| Anticipated Outcomes   | (1) Thorough analysis of Physical Unclonable Functions, their applications and cons and pros. (2) Implementation of a malicious machine learning system that can distinguish paper sheets from each other.  |
| Requirements           |  Knowledge of Image processing, machine learning |
| Max Number of Students | 2  |
| Project Type           | L4  |
| Keywords               |  	image processing, cyber security, physical unclonable functions |
### Theme ET-3: Zero Knowledge Proofs and their application in untrusted platforms
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Application of Zero Knowledge Proofs is now widely accepted, mainly because of the popularity of blockchain. However, the concept has been around for a long time. In this project, you will overview different types of zero knowledge proof protocols. Then, you will investigate the state-of-the-art applications in the real world, especially beyond blockchain. |
| Reference URLs         | Zero Knowledge Proofs: A Survey: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.9812&rep=rep1&type=pdf<br>A Survey of Zero-Knowledge Proofs with Applications to Cryptography: http://austinmohr.com/Work_files/zkp.pdf<br>SoK of Used Cryptography in Blockchain: https://ieeexplore.ieee.org/abstract/document/8865045<br>Zero Knowledge twenty years after its invention: https://www.ais.ruhr-uni-bochum.de/media/ei/lehrmaterialien/sadeghi_aspekte-der-modernen-kryptogragrafie-ii/zk-tut_20years.pdf  |
| Anticipated Outcomes   | (1) A through analysis and comparison of different ZKP approaches and protocols. (2) Implementation of a secure system using ZKP to prove the claims (e.g. an authentication system using ZKP). (3) Possibly a novel application of ZKPs in design of secure protocols.  |
| Requirements           | basic understanding of cryptography  |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | zero knowledge proofs, blockchain  |
### Theme ET-4: Fair performance dashboard for Machine Learning systems
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Machine Learning algorithms are prone to biased behaviour. There a number of ways to mitigate such algorithmic discrimination. However, one first needs to measure the fairness of the algorithm. You will implement a dashboard to visualize different fairness metrics on a benchmark dataset. It should use IBM AIF360 on the backend side to measure and mitigate fairness. It should demonstrate the difference between the results before and after the selected fairness mitigation method. Also, it should provide a robust set of plots to demonstrate fairness metrics. We call this product “fairness dashboard”.  |
| Reference URLs         |  AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias: https://arxiv.org/abs/1810.01943 |
| Anticipated Outcomes   | (1) A Through analysis and comparison of fairness metrics in machine learning. (2) Implementation of a dashboard to visualize fairness performance of a machine learning system.  |
| Requirements           | 	python, machine learning  |
| Max Number of Students |  1 |
| Project Type           | L3, L4  |
| Keywords               | 	fair machine learning, ethics, non-discrimination  |
### Theme ET-5: Cryptojacking in modern web technologies
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Cryptojacking has been one of the leading blockchain-based attacks in the web. In these category of attacks, the attacker utilizes the processing power of the victim's computer using the web-enabled technologies such as browser extensions and malicious JavaScript. In this project, you will overview the attack types, technologies used and implement a proof-of-concept cryptojacking attack using browser extensions.  |
| Reference URLs         | A First Look at Browser-Based Cryptojacking: https://ieeexplore.ieee.org/abstract/document/8406561?casa_token=kLDNmily54cAAAAA:ZjgRoQPQLQnfRaprMa1H4EY3gjX3fQZctzW8ZscXrqdpClR0gnwH0R7Iv2kXrWFIqWciws43<br>How You Get Shot in the Back: A Systematical Study about Cryptojacking in the Real World: https://dl.acm.org/doi/abs/10.1145/3243734.3243840  |
| Anticipated Outcomes   | (1) A thorough analysis of cryptojacking techniques, attack scenarios and countermeasures. (2) Implementation of a (controlled, limited) web-based cryptojacking attack in a browser extension. (3) Possibly improvement in the current attack scenarios and discovery of bugs in mainstream browsers.  |
| Requirements           |  JavaScript |
| Max Number of Students |  1 |
| Project Type           |  L3, L4 |
| Keywords               |  browser extension attack, malware |
### Theme ET-6: Browser-based Machine Learning frameworks
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | In this project, you will comprehensively evaluate the JavaScript-based frameworks that implement machine learning algorithms in the browser. You will also investigate the recent updates on W3C machine learning group which is responsible to develop standards for machine learning APIs in browser.  |
| Reference URLs         | TENSORFLOW.JS: MACHINE LEARNING FOR THE WEB AND BEYOND: https://arxiv.org/pdf/1901.05350.pdf<br>MLitB: machine learning in the browser: https://peerj.com/articles/cs-11/?utm_source=TrendMD&utm_campaign=PeerJ_TrendMD_0&utm_medium=TrendMD<br>W3C Group: MACHINE LEARNING FOR THE WEB: https://www.w3.org/community/webmachinelearning/  |
| Anticipated Outcomes   | (1) A thorough analysis of in browser machine learning frameworks. (2) A proof-of-concept implementation of machine learning algorithms inside browser using JavaScript and web technologies. (3) Possibility further development and improvement of them.  |
| Requirements           | JavaScript, Machine Learning  |
| Max Number of Students | 1  |
| Project Type           |  L3, L4 |
| Keywords               | 	machine learning, JavaScript, web browser  |
### Theme ET-7: On-chain and off-chain transactions in blockchain technologies
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Off-chain transactions are a new trend of blockchain implementation that potentially can solve its efficiency problems. In this project, you will investigate the detail of off-chain protocols, its trends and successful case studies.  |
| Reference URLs         | SoK: Off The Chain Transactions: https://eprint.iacr.org/2019/360.pdf  |
| Anticipated Outcomes   | (1) Through analysis of off-chain and on-chain transactions. (2) Implementation and evaluation of existing off-chain protocols. (3) Possibility discovery of a practical attack scenario to off-chain transactions or further development and improvement of the protocols.  |
| Requirements           |  knowledge of blockchain |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | blockchain, side channel  |

## Staff Proposer: Qian Wang
### Theme QW-1: X-ray baggage image generation for prohibited item recognition
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Prohibited item recognition and detection in passengers luggage are of vital importance for aviation security. Automatic threat recognition algorithms require a large number of annotated With the success of deep learning in recent years, generative models such as Generative Adversarial Networks (GAN) and Variational AutoEncoder (VAE) are proven to be able to generate realistic images from random noise. In this project, the student aims to investigate the possibility of using state-of-the-art generative models to generate X-ray baggage images and their potential usage in facilitating the training of automatic threat recognition (e.g., firearms, knives, etc).  |
| Reference URLs         | X-ray baggage security image processing: (http://breckon.eu/toby/publications/papers/akcay18architectures.pdf) Generative Adversarial Networks: (https://en.wikipedia.org/wiki/Generative_adversarial_network) Variational AutoEncoder: (https://arxiv.org/abs/1606.05908)  |
| Anticipated Outcomes   | 1. Being able to use generative models (e.g., GAN, VAE) to generate realistic X-ray baggage security imagery. 2. Investigate how these generated images can help the training of automatic threat recognition algorithms.  |
| Requirements           |   Interest in computer vision, deep learning, python, pytorch. |
| Max Number of Students | 1  |
| Project Type           | L3, L4  |
| Keywords               | Convolutional neural network, X-ray baggage images, Generative Adversarial Networks, Variational AutoEncoder.  |

## Staff Proposer: Tobias Weinzierl
### Theme TW-1: Python-based visualisation of block-structured meshes through a VTK server
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | We study the AMR software Peano which is the base of multiple applications such as ExaHyPE which use dynamically adaptive mesh refinement (AMR). The YouTube channel hpcsoftware (https://www.youtube.com/channel/UC1aAT5nSVeAwdYbifdxW1EQ) gives an impression of such codes. Peano currently writes its AMR grids in a specialised format which is tailored towards the block-structuredness. Notably, this is not a standard vef format or similar which can be processed by standard visualisation software. Therefore, the Peano group provides a converter into VTK, a standard file format. This currently is a C++ tool. The output can be read by postprocessing tools such as Paraview (https://www.paraview.org/). The idea in this project is to build a Python-based GUI relying on VTK which allows to load in Peano\\\\\\\'s block file format, to inspect the data, and to write particular output formats which can be processed further in a mainstream format. From thereon, we explore multiple direction: We create a VTK visualisation (3d rendering) directly in Python, and we create the opportunity to connect to a Paraview rendering server. With the latter, our Python code can control large display walls as we find them in the Computer Science department. With this infrastructure at hand, we assess multiple algorithmical extensions which allow us to process large data files.  |
| Reference URLs         | https://www.youtube.com/channel/UC1aAT5nSVeAwdYbifdxW1EQ  |
| Anticipated Outcomes   | GUI in Python which allows to preview data sets, to extract quantities of interest in the resolution of interest, and to write files in a standardised visualisation format. (basic outcome) Support for level of level of detail algorithms, VTK filters which do not work with native AMR formats (such as isolines), and rendering of high order shape functions. (intermediate outcome) Opportunity to connect to remote rendering server, and support for various level of detail algorithms which take the user's point of view into account when output into mainstream format (or to remote server) is dumped. Finally, implementation of a pattern-based/machine learning compression algorithms for the outcomes such that memory footprint is reduced drastically.  |
| Requirements           | Python (mandatory). C/C++ (recommended). VTK (optional). See videos scientific data analysis and vis with VTK and Paraview SciPy 2015  |
| Max Number of Students |  5 |
| Project Type           | MISCADA, L3  |
| Keywords               |   |
### Theme TW-2: Invasive Scheduling
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            |  Today’s schedulers typically ask the user to specify how many ranks (processes) run on a node concurrently. The scheduler then splits up the available cores among equally among the ranks. This does not take into account that load in simulations changes quickly and we might thus run into situations where some ranks can effectively use quite a lot of cores, while others have not that much to do. The goal in this project is to write a new TBB-based library where the individual ranks bid against each other how many cores each rank may use. And then they quickly migrate ownership if it suits the code. One rank invades the cores of the other rank if it is very compute-heavy and can make use of more ranks. Low-workload processes retreat from the cores in return. |
| Reference URLs         | http://www.peano-framework.org/index.php/tobias-weinzierl/open-projects/  |
| Anticipated Outcomes   | Working software; benchmarks  |
| Requirements           | 	C++ programming; HPC performance analysis  |
| Max Number of Students |  3 |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme TW-3: DaStGen 2.0 - a Python-based C++ data structure generator
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	DaStGen is a simple, nice tool which I use quite intensively for all of my project. You find a description on my homepage. In its current form, it allows me to model C++ classes which are very memory-modest and supported by MPI. The biggest “problem” is that DaStGen is written in Java. In this project, you are supposed to redesign DaStGen in Python. DaStGen 2.0 will still be “usable” as command line tool, i.e. parse a domain-specific C++ extension, but there will also be a variant where users can assemble a DaStGen data within their Python code and then ask the code to generate plain C++ code. Finally, the new DaStGen version will support novel compressed float precision formats (bfloat16, e.g.).  |
| Reference URLs         | http://www.peano-framework.org/index.php/tobias-weinzierl/open-projects/  |
| Anticipated Outcomes   | Software; demo applications; studies on the memory footprint  |
| Requirements           |  C/C++ programming; Python |
| Max Number of Students | 3  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme TW-4: Mini SPH
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	SPH (Smooth Particle Hydrodynamics) is a popular technique in many application fields to simulate fluids (matter distribution in galaxies, e.g.). It is convenient, as the fluid is not simulated over a grid but through distributions which move around in space. Typically, developers add however a grid on top of these “particles” (centres of distributions) to speed up certain steps such as finding close-by other distributions. In the Peano code, we have successfully written some particle management routines where the grid hosts particles – the grid is not a sole metadata but actually owns all particles. While we have only used it for Particle in Cell (PIC) methods and Discrete Elements (DEM), there is no reason why these data structures should not work for SPH as well. In this project, we will demonstrate this idea by implementing a real SPH solver within Peano4.  |
| Reference URLs         |  http://www.peano-framework.org/index.php/tobias-weinzierl/open-projects/ |
| Anticipated Outcomes   | 	Code; results for some standard SPH benchmarks |
| Requirements           |  C/C++ programming; computational physics |
| Max Number of Students | 4  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               |   |
### Theme TW-5: Smart filters
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	In a project with a local company, a cloud-based system is to be developed which plugs into a CO2 gas filter. In the tradition of edge computing, a new sensor not only loads up internet into the cloud but also derives certain metrics directly from the sensor data. The project is in collaboration with a local company, therefore this information is rather brief (NDA required).  |
| Reference URLs         |   |
| Anticipated Outcomes   | A cloud-based software environment prototype which uses some data analysis/ML capabilities on the edge.  |
| Requirements           |  Web system programming skills preferred. |
| Max Number of Students | 3  |
| Project Type           |  MISCADA, L3 |
| Keywords               |   |
### Theme TW-6: Student Cluster Competition
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | The student cluster competition is one of the most prestigious competitions in the HPC area. The goal behind the competition is - for a whole team - to build up a supercomputer from scratch, i.e. wire it, install it, configure it, and run benchmarks. This has to be done on a fair with fixed energy budget and under time pressure. Within the given budget, teams also have to run a suite of benchmark computations and the team that obtains most of the results is the winner. In this project, the students will join the Durham cluster team and work on innovative ideas of super computing that will help their team to win the trophy (and then to participate in the next, international stage of the competition). Ideas comprise the intelligent overclocking/downclocking of system parts based upon an ML/experience database, the containerisation of the machine such that the logical hardware topology follows the compute needs, and the dynamic adaption of compute precision within the code. Students will collaborate with other Durham researchers as well as the UK\'s leading company in supercomputing. Students are also required to be willing to participate in the competition in December, i.e. a lot of work has to be done early throughout term 1.  |
| Reference URLs         | https://www.hpcadvisorycouncil.com/events/student-cluster-competition/ (see previous years)  |
| Anticipated Outcomes   | Successful participation in the cluster competition, i.e. being part of a team that builds a real supercomputer. One novel, gamechanger concept how to run a modern compute centre.  |
| Requirements           |  Linux affinity. HPC interest is advantageous. Interest in hardware. |
| Max Number of Students | 3  |
| Project Type           | MISCADA, L3, L4  |
| Keywords               | HPC, supercomputer, compute architecture  |

## Staff Proposer: Chris Willcocks
### Theme CGW-1: Collaborative Development of an AI/Cyber Security Tactic with NERSOU (North East Regional Special Operations Unit) and the NCA (National Crime Agency)
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | This involves a potentially high-impact but sensitive Cyber Security project, in collaboration with NERSOU and the NCA. The project is to develop an innovative cyber security technology that acts as a tactic, used by NERSOU and the NCA, to prevent serious crime that benefits wider society. Candidates must be interviewed beforehand, to ensure students are comfortable with working in this area, and able to communicate with discretion. Students must be prepared to occasionally travel locally and present their progress to inspectors/sergeants. The project requires excellent skills in Python programming, UNIX, Web Programming, and Computer Networks, alongside moderate skills in Deep Learning and Cloud Deployment. The maximum number of students is stated as zero as this project is unavailable by standard selection. If interested, please instead email to arrange a meeting to discuss: christopher.g.willcocks@durham.ac.uk  |
| Reference URLs         | https://www.nersou.org.uk/ https://www.nationalcrimeagency.gov.uk/  |
| Anticipated Outcomes   | Development, deployment, and quantification of the effectiveness for a new piece of technology with significant potential to benefit society.  |
| Requirements           | L2 Cyber Security and L3 Deep Learning (have taken or be currently undertaking)  |
| Max Number of Students | 0  |
| Project Type           |  L3, L4 |
| Keywords               | Cyber Security, Networks, Tor, Deep Learning, Cloud Computing, UNIX.  |
### Theme CGW-2: Unpaired Image Translation in Medical Imaging, in collaboration with NHS University Hospital of North Durham
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Medical devices vary in terms of cost, availability, and output quality. This research project involves application of state-of-the-art models in unpaired image translation, such as CycleGAN, to translate between medical domains. Examples include translating Ultrasound into fMRI, or translating from noisy low-radiation dosage domains to clean medical phantoms/simulated models/high-radiation dosage imaging. A large part of the challenge of this project will be in identifying and preparing datasets from publicly available sources. This project will involve collaboration and clinical input from the lead radiologist, and surgeons at the NHS University Hospital.  |
| Reference URLs         |  https://junyanz.github.io/CycleGAN/ https://arxiv.org/abs/1505.04597 https://arxiv.org/abs/1905.06902 https://www.sciencedirect.com/science/article/pii/S1361841518308430 |
| Anticipated Outcomes   | Generative model that is able to translate between medical domains within a specific application, improving the quality of the outputs.  |
| Requirements           |  L3 Deep Learning (have taken or currently be undertaking). Students require strong Python programming ability, as a large challenge of this project will be in identifying, parsing and managing the large medical datasets with PyTorch normalised for deep learning. Knowledge of UNIX is required and experience with NCC is recommended. |
| Max Number of Students | 3  |
| Project Type           | L3, L4  |
| Keywords               |  Deep Learning, Generative Models, PyTorch. |
### <span style="color:red;">Theme CGW-3: Learning Intuitive Low Dimensional Manifolds</span>
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | 	Manifold learning is used for nonlinear dimensionality reduction, with methods including Isomap, LLE, Hessian Eigenmapping, Spectral Embedding, MDS, t-SNE, and more recently UMAP. Recent advances in adversarial machine learning has also led to new approaches, such as Adversarial Autoencoders (AAE) and Adversarially Constrained Autoencoder Interpolation (ACAI). Learning intuitive manifolds that capture global structure as well as represent local changes, such as in texture, is a challenging ill-posed problem. The problem is also strongly influenced by the curse of dimensionality and sampling error from the data distribution. Autoencoder-based approaches suffer from limited signal bandwidth through the latent variables, limiting sensitivity to small variations that may be characteristically important of the data distribution.  |
| Reference URLs         | https://arxiv.org/pdf/1802.03426 https://www.youtube.com/watch?v=nq6iPZVUxZU https://johnhw.github.io/umap_primes/index.md.html https://arxiv.org/abs/1511.05644 https://arxiv.org/abs/1807.07543 http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf https://scikit-learn.org/stable/modules/manifold.html  |
| Anticipated Outcomes   | Algorithm or architectural approach to learn intuitive manifolds. Potential to extend to publishable novel contributions in this research area.  |
| Requirements           |  L3 Deep Learning and strong mathematics background (in particular differential geometry and statistics). |
| Max Number of Students |  1 |
| Project Type           | L4  |
| Keywords               |  Manifold Learning, Differential Geometry, Machine Learning. |
### Theme CGW-4: Anomaly Detection in Medical CT Volumes with Geometric and/or Radiodensity Priors
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Analysis of 3D volumetric images from medical CT scans is often expensive in terms of radiologist and surgeon time, and often leads to missed or incorrect diagnosis in difficult cases. Automated identification and detection of anomalous regions may lead to improved clinical diagnosis. There are large publicly available medical CT datasets, such as on the cancer imaging archive, however these are often unlabelled and difficult to process due to large file sizes being unable to fit onto GPU memory. The field of anomaly detection is itself a difficult machine learning problem, relating to estimating the density of the underlying data distribution given a discrete set of observations. Density estimation is itself challenging due to a classic ill-defined bias/variance trade-off problem, where anomaly detection approaches generally arise from the fields of manifold learning or reconstructive approaches with a local measure of surprise. The aim of this project is to design a bespoke 3D anomaly detection architecture for medical CT data, which highlights locally anomalous regions. This is very challenging given the huge amount of variation within healthy human anatomy. Therefore it is proposed to refine the anomalous space based on application-specific geometric priors (knee fractures as faint/thin lines in orthopaedic knee CT) and/or radiodensity priors imposed from the Hounsfield scale, for example an adrenal tumor with a radiodensity of less than 10 Hounsfield Units (HU) is fatty in composition and almost certainly a benign adrenal adenoma. Similarly anomalous fractures occur at the site of bone, which has 300-400 HU (cancellous) or 1800-1900 (cortical) therefore most soft tissue and other information can be immediate discarded.  |
| Reference URLs         | https://medium.com/vitalify-asia/gan-for-unsupervised-anomaly-detection-on-x-ray-images-6b9f678ca57d https://github.com/lkhphuc/Anomaly-XRay-GANs https://arxiv.org/abs/1810.06621  |
| Anticipated Outcomes   | Software to input geometric and/or radiodensity prior information and automatically highlight anomalous regions in medical images.  |
| Requirements           | Students must have taken or be currently undertaking the Deep Learning (L3) sub-module. Students require strong Python programming ability, as a large challenge of this project will be in identifying, parsing and managing the large medical datasets with PyTorch normalised for deep learning while respecting the Hounsfield scale. Knowledge of UNIX is required and experience with NCC is recommended.  |
| Max Number of Students |  1 |
| Project Type           | L3, L4  |
| Keywords               |  Anomaly Detection, CNNs, Density Estimation, Generative Models, GANs, PyTorch. |
### Theme CGW-5: Deep Learning Surface Representations for Protein Docking, in Collaboration with the Department of Physics
| <!-- -->    | <!-- -->    |
|-------------|-------------|
| Description            | Characterizing protein structure at the atomic level is key to understanding illnesses, and crucial to inform the design of new therapies. This project will take input protein conformations (a dataset of thousands of 3D ordered point clouds) and, through deep neural networks, learn a compressed surface representation f:R^m -> R that allows for efficient sampling of the signed distance to the surface, over time. This project does not require expertise in Biochemistry or Physics, but it requires good background in mathematics, especially in differential geometry, learning theory, and statistics.  |
| Reference URLs         |  https://arxiv.org/abs/1910.04543 https://arxiv.org/abs/2002.10099 https://degiacomi.org/software/jabberdock/ |
| Anticipated Outcomes   | A deep neural network architecture that learns a compressed surface representation, allowing for efficient sampling an facilitating improved protein docking performance.  |
| Requirements           |  L3 Deep Learning |
| Max Number of Students |  2 |
| Project Type           | L4  |
| Keywords               | Deep Learning, Differential Geometry, Biophysics, Biochemistry, PyTorch.  |